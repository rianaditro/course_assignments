{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Lists vs Dictionaries**\n",
    "When working on data scraping tasks, it's essential to be familiar with core Python data structures like lists, and dictionaries, as they are key to processing and organizing the scraped data efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://example.com/page-1\n",
      "['https://example.com/page-1', 'https://example.com/page-2', 'https://example.com/page-3', 'https://example.com/page-4', 'https://example.com/page-5']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Create a List of URLs\n",
    "\"\"\"\n",
    "url = \"https://example.com/page-1\"\n",
    "\n",
    "# TODO: From the url, extract the main url\n",
    "print(url)\n",
    "# TODO: Create the list of URLs for the next 5 pages\n",
    "# Expected Output: ['https://example.com/page-1', 'https://example.com/page-2', 'https://example.com/page-3', 'https://example.com/page-4', 'https://example.com/page-5']\n",
    "# Extract the base URL (everything before the page number)\n",
    "base_url = url.rsplit('-', 1)[0]\n",
    "\n",
    "# Create list of URLs for pages 1-5\n",
    "urls = [f\"{base_url}-{i}\" for i in range(1, 6)]\n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The urls have 5 elements\n",
      "['https://example.com/page-6', 'https://example.com/page-7', 'https://example.com/page-8', 'https://example.com/page-9', 'https://example.com/page-10', 'https://example.com/page-1', 'https://example.com/page-2', 'https://example.com/page-3', 'https://example.com/page-4', 'https://example.com/page-5']\n",
      "The urls have 10 elements\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Extend the List of URLs\n",
    "\"\"\"\n",
    "urls = [\"https://example.com/page-1\", \"https://example.com/page-2\", \"https://example.com/page-3\", \"https://example.com/page-4\", \"https://example.com/page-5\"]\n",
    "new_urls = [\"https://example.com/page-6\", \"https://example.com/page-7\", \"https://example.com/page-8\", \"https://example.com/page-9\", \"https://example.com/page-10\"]\n",
    "\n",
    "# TODO: The urls have 5 elements\n",
    "print(f\"The urls have {len(urls)} elements\")\n",
    "# TODO: Add the new_urls to the urls to get 10 elements\n",
    "# TODO: Print the length of urls\n",
    "# Expected Output: 10\n",
    "new_urls.extend(urls)\n",
    "print(new_urls)\n",
    "print(f\"The urls have {len(new_urls)} elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# title1, url1\n",
      "# title2, url2\n",
      "# title3, url3\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Extract Data from Nested Lists\n",
    "\"\"\"\n",
    "data = [[\"title1\", \"url1\"], [\"title2\", \"url2\"], [\"title3\", \"url3\"]]\n",
    "\n",
    "# TODO: Extract the title and url from the data\n",
    "# Expected Output:\n",
    "# title1 url1\n",
    "# title2 url2\n",
    "# title3 url3\n",
    "\n",
    "for item in data:\n",
    "    print(f\"# {item[0]}, {item[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.example2.com', 'https://www.example1.com', 'https://www.example3.com']\n",
      "['https://www.example1.com', 'https://www.example2.com', 'https://www.example3.com']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Remove duplicate elements from a List\n",
    "\"\"\"\n",
    "data = [\"https://www.example1.com\", \"https://www.example1.com\", \"https://www.example2.com\", \"https://www.example2.com\", \"https://www.example3.com\"]\n",
    "\n",
    "# TODO: Remove duplicates from the data\n",
    "# Expected result : \n",
    "# ['https://www.example1.com', 'https://www.example2.com', 'https://www.example3.com']\n",
    "# Method 1: Using set() to remove duplicates\n",
    "unique_data = list(set(data))\n",
    "print(unique_data)\n",
    "\n",
    "# Method 2: Using list comprehension\n",
    "unique_data = list(dict.fromkeys(data))\n",
    "print(unique_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Example Title 1', 'url': 'https://example.com/page-1'}, {'title': 'Example Title 2', 'url': 'https://example.com/page-2'}, {'title': 'Example Title 3', 'url': 'https://example.com/page-3'}, {'title': 'Example Title 4', 'url': 'https://example.com/page-4'}, {'title': 'Example Title 5', 'url': 'https://example.com/page-5'}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Create a Dictionary for Scraped Data\n",
    "\"\"\"\n",
    "urls = [\"https://example.com/page-1\", \"https://example.com/page-2\", \"https://example.com/page-3\", \"https://example.com/page-4\", \"https://example.com/page-5\"]\n",
    "\n",
    "# Function to scrape data\n",
    "def scrape_data(url):\n",
    "    # Extracted data\n",
    "    data = dict()\n",
    "     # Get page number from URL\n",
    "    page_num = url.split('-')[-1]\n",
    "    # TODO: Add the title to the dictionary with value \"Example Title 1\" for page 1\n",
    "    # TODO: Add the url to the dictionary with value \"https://example.com/page-1\" for page 1\n",
    "    # Add title and URL to dictionary\n",
    "    data['title'] = f\"Example Title {page_num}\"\n",
    "    data['url'] = url\n",
    "    return data\n",
    "\n",
    "# TODO: Loop through the urls and call the scrape_data function for each url\n",
    "# TODO: Append the returned data to the scraped_data list\n",
    "# TODO: Print the scraped_data\n",
    "# Expected Output:\n",
    "# [{'title': 'Example Title 1', 'url': 'https://example.com/page-1'}, {'title': 'Example Title 2', 'url': 'https://example.com/page-2'}, {'title': 'Example Title 3', 'url': 'https://example.com/page-3'}, {'title': 'Example Title 4', 'url': 'https://example.com/page-4'}, {'title': 'Example Title 5', 'url': 'https://example.com/page-5'}]\n",
    "# Create list to store all scraped data\n",
    "scraped_data = []\n",
    "# Loop through URLs and collect data\n",
    "for url in urls:\n",
    "    result = scrape_data(url)\n",
    "    scraped_data.append(result)\n",
    "print(scraped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Title 1 https://example.com\n",
      "Example Title 2 https://example.com\n",
      "Example Title 3 https://example.com\n",
      "Example Title 4 https://example.com\n",
      "Example Title 5 https://example.com\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Retrieve Data from a Dictionary\n",
    "\"\"\"\n",
    "data = [{\"title\": \"Example Title 1\", \"url\": \"https://example.com\"},\n",
    "        {\"title\": \"Example Title 2\", \"url\": \"https://example.com\"},\n",
    "        {\"title\": \"Example Title 3\", \"url\": \"https://example.com\"},\n",
    "        {\"title\": \"Example Title 4\", \"url\": \"https://example.com\"},\n",
    "        {\"title\": \"Example Title 5\", \"url\": \"https://example.com\"}]\n",
    "\n",
    "# TODO: Use a for loop to loop through the data\n",
    "# TODO: Use the item[\"title\"] to get the title\n",
    "# TODO: Use the item.get(\"url\") to get the url\n",
    "# TODO: Print the title and url\n",
    "# Expected Output:\n",
    "# Example Title 1 https://example.com\n",
    "# Example Title 2 https://example.com\n",
    "# Example Title 3 https://example.com\n",
    "# Example Title 4 https://example.com\n",
    "# Example Title 5 https://example.com\n",
    "\n",
    "# Loop through each dictionary in the data list\n",
    "for item in data:\n",
    "    title = item[\"title\"]\n",
    "    url = item.get(\"url\")\n",
    "    print(f\"{title} {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Example Title 1', 'url': 'https://example.com/page-1'}, {'title': 'Example Title 2', 'url': 'https://example.com/page-2'}, {'title': 'Example Title 3', 'url': 'https://example.com/page-3'}, {'title': 'Example Title 4', 'url': 'https://example.com/page-4'}, {'title': 'Example Title 5', 'url': 'https://example.com/page-5'}]\n",
      "[{'title': 'Example Title 1', 'url': 'https://example.com/page-1'}, {'title': 'Example Title 2', 'url': 'https://example.com/page-2'}, {'title': 'Example Title 3', 'url': 'https://example.com/page-3'}, {'title': 'Example Title 4', 'url': 'https://example.com/page-4'}, {'title': 'Example Title 5', 'url': 'https://example.com/page-5'}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Create a List of Dictionary from two Lists\n",
    "\"\"\"\n",
    "titles = [\"Example Title 1\", \"Example Title 2\", \"Example Title 3\", \"Example Title 4\", \"Example Title 5\"]\n",
    "urls = [\"https://example.com/page-1\", \"https://example.com/page-2\", \"https://example.com/page-3\", \"https://example.com/page-4\", \"https://example.com/page-5\"]\n",
    "\n",
    "# TODO: Combine the titles and urls into a list of dictionaries\n",
    "# Expected Output:\n",
    "# [{'title': 'Example Title 1', 'url': 'https://example.com/page-1'}, {'title': 'Example Title 2', 'url': 'https://example.com/page-2'}, {'title': 'Example Title 3', 'url': 'https://example.com/page-3'}, {'title': 'Example Title 4', 'url': 'https://example.com/page-4'}, {'title': 'Example Title 5', 'url': 'https://example.com/page-5'}] \n",
    "\n",
    "# Method 1: Using zip() and list comprehension\n",
    "combined_data = [{'title': title, 'url': url} for title, url in zip(titles, urls)]\n",
    "print(combined_data)\n",
    "\n",
    "# Method 2: Using zip() with a for loop\n",
    "combined_data = []\n",
    "for title, url in zip(titles, urls):\n",
    "    combined_data.append({'title': title, 'url': url})\n",
    "print(combined_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['title', 'url', 'tags', 'date']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Identify all keys in a Dictionary\n",
    "\"\"\"\n",
    "data = {\"title\": \"Example Title\", \"url\": \"https://example.com\", \"tags\": [\"tag1\", \"tag2\", \"tag3\"], \"date\": \"2022-01-01\"}\n",
    "\n",
    "# TODO: Use keys() method to get all keys\n",
    "# TODO: Convert the keys to a list\n",
    "# Expected Output: ['title', 'url', 'tags', 'date']\n",
    "\n",
    "keys_list = list(data.keys())\n",
    "print(keys_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# title: Example Title\n",
      "# url: https://example.com\n",
      "# author: John Doe\n",
      "# tags: ['tag1', 'tag2', 'tag3']\n",
      "# views: 1000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Loop through a Dictionary\n",
    "\"\"\"\n",
    "scraped_data = {\n",
    "                \"title\": \"Example Title\",\n",
    "                \"url\": \"https://example.com\",\n",
    "                \"author\": \"John Doe\",\n",
    "                \"tags\": [\"tag1\", \"tag2\", \"tag3\"],\n",
    "                \"views\": 1000\n",
    "            }\n",
    "\n",
    "# TODO: Use .items() method to loop through the dictionary\n",
    "\n",
    "# TODO: Print each key and value\n",
    "# Expected Output:\n",
    "# title: Example Title\n",
    "# url: https://example.com\n",
    "# author: John Doe\n",
    "# tags: ['tag1', 'tag2', 'tag3']\n",
    "# views: 1000\n",
    "# Loop through dictionary items\n",
    "for key, value in scraped_data.items():\n",
    "    print(f\"# {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article with highest views (1500):\n",
      "Title: Top 10 Web Scraping Tools\n",
      "Author: Jane Smith\n",
      "URL: https://example.com/web-scraping-tools\n",
      "\n",
      "Article with most comments (2 comments):\n",
      "Title: How to Learn Python\n",
      "Author: John Doe\n",
      "Comments:\n",
      "- Alice: Great article!\n",
      "- Bob: Very informative.\n",
      "\n",
      "Comment with highest likes (10 likes):\n",
      "Article: Top 10 Web Scraping Tools\n",
      "User: Dave\n",
      "Comment: Awesome list!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Extract Data from a Nested Dictionary\n",
    "\"\"\"\n",
    "scraped_data = [\n",
    "    {\n",
    "        \"category\": \"Programming\",\n",
    "        \"articles\": [\n",
    "            {\n",
    "                \"title\": \"How to Learn Python\",\n",
    "                \"url\": \"https://example.com/learn-python\",\n",
    "                \"author\": \"John Doe\",\n",
    "                \"tags\": [\"Python\", \"Programming\", \"Tutorial\"],\n",
    "                \"views\": 1200,\n",
    "                \"comments\": [\n",
    "                    {\"user\": \"Alice\", \"comment\": \"Great article!\", \"likes\": 5},\n",
    "                    {\"user\": \"Bob\", \"comment\": \"Very informative.\", \"likes\": 2}\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"title\": \"Advanced Python Tips\",\n",
    "                \"url\": \"https://example.com/advanced-python\",\n",
    "                \"author\": \"Jane Smith\",\n",
    "                \"tags\": [\"Python\", \"Advanced\", \"Tips\"],\n",
    "                \"views\": 800,\n",
    "                \"comments\": [\n",
    "                    {\"user\": \"Charlie\", \"comment\": \"Helpful for experts.\", \"likes\": 3}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Web Scraping\",\n",
    "        \"articles\": [\n",
    "            {\n",
    "                \"title\": \"Top 10 Web Scraping Tools\",\n",
    "                \"url\": \"https://example.com/web-scraping-tools\",\n",
    "                \"author\": \"Jane Smith\",\n",
    "                \"tags\": [\"Web Scraping\", \"Tools\", \"Technology\"],\n",
    "                \"views\": 1500,\n",
    "                \"comments\": [\n",
    "                    {\"user\": \"Dave\", \"comment\": \"Awesome list!\", \"likes\": 10}\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"title\": \"Understanding BeautifulSoup\",\n",
    "                \"url\": \"https://example.com/beautifulsoup\",\n",
    "                \"author\": \"Alice Johnson\",\n",
    "                \"tags\": [\"Web Scraping\", \"BeautifulSoup\", \"Python\"],\n",
    "                \"views\": 1100,\n",
    "                \"comments\": [\n",
    "                    {\"user\": \"Eve\", \"comment\": \"Great for beginners.\", \"likes\": 4},\n",
    "                    {\"user\": \"Frank\", \"comment\": \"Clear explanation!\", \"likes\": 6}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"APIs\",\n",
    "        \"articles\": [\n",
    "            {\n",
    "                \"title\": \"Understanding REST APIs\",\n",
    "                \"url\": \"https://example.com/rest-apis\",\n",
    "                \"author\": \"John Doe\",\n",
    "                \"tags\": [\"APIs\", \"REST\", \"Web Development\"],\n",
    "                \"views\": 900,\n",
    "                \"comments\": [\n",
    "                    {\"user\": \"Grace\", \"comment\": \"Very clear overview.\", \"likes\": 7}\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"title\": \"GraphQL vs REST\",\n",
    "                \"url\": \"https://example.com/graphql-vs-rest\",\n",
    "                \"author\": \"Charlie Brown\",\n",
    "                \"tags\": [\"APIs\", \"GraphQL\", \"Comparison\"],\n",
    "                \"views\": 1300,\n",
    "                \"comments\": [\n",
    "                    {\"user\": \"Hannah\", \"comment\": \"Helpful comparison!\", \"likes\": 9}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# TODO: Show the article data with the highest number of views\n",
    "# Initialize variables to track the highest views and corresponding article\n",
    "highest_views = 0\n",
    "article_with_highest_views = None\n",
    "\n",
    "# Loop through each category and its articles\n",
    "for category in scraped_data:\n",
    "    for article in category['articles']:\n",
    "        if article['views'] > highest_views:\n",
    "            highest_views = article['views']\n",
    "            article_with_highest_views = article\n",
    "\n",
    "# Print the article with highest views\n",
    "print(f\"Article with highest views ({highest_views}):\")\n",
    "print(f\"Title: {article_with_highest_views['title']}\")\n",
    "print(f\"Author: {article_with_highest_views['author']}\")\n",
    "print(f\"URL: {article_with_highest_views['url']}\")\n",
    "# TODO: Which article has the highest number of comments\n",
    "# Initialize variables for tracking\n",
    "most_comments = 0\n",
    "article_with_most_comments = None\n",
    "\n",
    "# Loop through each category and its articles\n",
    "for category in scraped_data:\n",
    "    for article in category['articles']:\n",
    "        num_comments = len(article['comments'])\n",
    "        if num_comments > most_comments:\n",
    "            most_comments = num_comments\n",
    "            article_with_most_comments = article\n",
    "\n",
    "# Print the article with most comments\n",
    "print(f\"\\nArticle with most comments ({most_comments} comments):\")\n",
    "print(f\"Title: {article_with_most_comments['title']}\")\n",
    "print(f\"Author: {article_with_most_comments['author']}\")\n",
    "print(f\"Comments:\")\n",
    "for comment in article_with_most_comments['comments']:\n",
    "    print(f\"- {comment['user']}: {comment['comment']}\")\n",
    "# TODO: Which coment has the highest number of likes\n",
    "# Initialize variables for tracking highest likes\n",
    "highest_likes = 0\n",
    "comment_with_highest_likes = None\n",
    "article_title = None\n",
    "\n",
    "# Loop through all categories, articles, and comments\n",
    "for category in scraped_data:\n",
    "    for article in category['articles']:\n",
    "        for comment in article['comments']:\n",
    "            if comment['likes'] > highest_likes:\n",
    "                highest_likes = comment['likes']\n",
    "                comment_with_highest_likes = comment\n",
    "                article_title = article['title']\n",
    "\n",
    "# Print the comment with highest likes\n",
    "print(f\"\\nComment with highest likes ({highest_likes} likes):\")\n",
    "print(f\"Article: {article_title}\")\n",
    "print(f\"User: {comment_with_highest_likes['user']}\")\n",
    "print(f\"Comment: {comment_with_highest_likes['comment']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reflection**\n",
    "What is the difference between using item[\"keys\"] with item.get(\"keys\")? What happens if the key isn't exist?\n",
    "\n",
    "(answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "item[\"keys\"] (Direct Access):\n",
    "\n",
    "- Uses square bracket notation for direct dictionary access\n",
    "- Raises a KeyError exception if the key doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'age'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m item \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJohn\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m])  \u001b[38;5;66;03m# Output: John\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mKeyError\u001b[0m: 'age'"
     ]
    }
   ],
   "source": [
    "item = {\"name\": \"John\"}\n",
    "print(item[\"name\"])  # Output: John\n",
    "print(item[\"age\"])   # Raises KeyError: 'age'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "item.get(\"keys\") (Safe Access):\n",
    "\n",
    "- Uses the get() method for safe dictionary access\n",
    "- Returns None by default if the key doesn't exist\n",
    "- Can specify a default value as second argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John\n",
      "None\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "item = {\"name\": \"John\"}\n",
    "print(item.get(\"name\"))      # Output: John\n",
    "print(item.get(\"age\"))       # Output: None\n",
    "print(item.get(\"age\", 25))   # Output: 25 (using default value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exploration**\n",
    "Python Collections provides specialized container datatypes beyond the standard Python collection types like lists, tuples, sets, and dictionaries. These container types are designed to make certain tasks more efficient and readable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Counter : Counts occurrences of elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'blue': 3, 'red': 2, 'green': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count elements in a list\n",
    "colors = ['red', 'blue', 'red', 'green', 'blue', 'blue']\n",
    "color_count = Counter(colors)\n",
    "print(color_count)  # Output: Counter({'blue': 3, 'red': 2, 'green': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. defaultdict : Dictionary with default value for missing keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'fruits': ['apple']})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Create a dictionary with list as default value\n",
    "grouped_data = defaultdict(list)\n",
    "grouped_data['fruits'].append('apple')  \n",
    "print(grouped_data)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. OrderedDict : Dictionary that remembers insertion order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'first': 1, 'second': 2})\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# Create an ordered dictionary\n",
    "ordered = OrderedDict()\n",
    "ordered['first'] = 1\n",
    "ordered['second'] = 2\n",
    "print(ordered)  # Output: OrderedDict([('first', 1), ('second', 2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. deque : Double-ended queue with fast appends and pops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque(['z', 'a', 'b', 'c', 'd'])\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "# Create a double-ended queue\n",
    "queue = deque(['a', 'b', 'c'])\n",
    "queue.append('d')         # Add to right\n",
    "queue.appendleft('z')     # Add to left\n",
    "print(queue)  # Output: deque(['z', 'a', 'b', 'c', 'd'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. namedtuple : Tuple subclass with named fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "# Create a named tuple class\n",
    "Person = namedtuple('Person', ['name', 'age'])\n",
    "person = Person('John', 30)\n",
    "print(person.name)  # Output: John\n",
    "print(person.age)   # Output: 30"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
