{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Lists vs Dictionaries**\n",
    "When working on data scraping tasks, it's essential to be familiar with core Python data structures like lists, and dictionaries, as they are key to processing and organizing the scraped data efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://example.com/page-1', 'https://example.com/page-2', 'https://example.com/page-3', 'https://example.com/page-4', 'https://example.com/page-5']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Create a List of URLs\n",
    "\"\"\"\n",
    "url = \"https://example.com/page-1\"\n",
    "\n",
    "# TODO: From the url, extract the main url\n",
    "# TODO: Create the list of URLs for the next 5 pages\n",
    "# Expected Output: ['https://example.com/page-1', 'https://example.com/page-2', 'https://example.com/page-3', 'https://example.com/page-4', 'https://example.com/page-5']\n",
    "base_url = url.split('/page-')[0]\n",
    "page_number = int(url.split('/page-')[1])\n",
    "urls = [f\"{base_url}/page-{i}\" for i in range(page_number, page_number + 5)]\n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Extend the List of URLs\n",
    "\"\"\"\n",
    "urls = [\"https://example.com/page-1\", \"https://example.com/page-2\", \"https://example.com/page-3\", \"https://example.com/page-4\", \"https://example.com/page-5\"]\n",
    "new_urls = [\"https://example.com/page-6\", \"https://example.com/page-7\", \"https://example.com/page-8\", \"https://example.com/page-9\", \"https://example.com/page-10\"]\n",
    "\n",
    "# TODO: The urls have 5 elements\n",
    "# TODO: Add the new_urls to the urls to get 10 elements\n",
    "# TODO: Print the length of urls\n",
    "# Expected Output: 10\n",
    "urls.extend(new_urls)\n",
    "print(len(urls))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title1 url1\n",
      "title2 url2\n",
      "title3 url3\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Extract Data from Nested Lists\n",
    "\"\"\"\n",
    "data = [[\"title1\", \"url1\"], [\"title2\", \"url2\"], [\"title3\", \"url3\"]]\n",
    "\n",
    "# TODO: Extract the title and url from the data\n",
    "# Expected Output:\n",
    "# title1 url1\n",
    "# title2 url2\n",
    "# title3 url3\n",
    "for title, url in data:\n",
    "    print(title, url)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.example3.com', 'https://www.example2.com', 'https://www.example1.com']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Remove duplicate elements from a List\n",
    "\"\"\"\n",
    "data = [\"https://www.example1.com\", \"https://www.example1.com\", \"https://www.example2.com\", \"https://www.example2.com\", \"https://www.example3.com\"]\n",
    "\n",
    "# TODO: Remove duplicates from the data\n",
    "# Expected result : \n",
    "# ['https://www.example1.com', 'https://www.example2.com', 'https://www.example3.com']\n",
    "data = list(set(data))\n",
    "print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Example Title 1', 'url': 'https://example.com/page-1'}, {'title': 'Example Title 2', 'url': 'https://example.com/page-2'}, {'title': 'Example Title 3', 'url': 'https://example.com/page-3'}, {'title': 'Example Title 4', 'url': 'https://example.com/page-4'}, {'title': 'Example Title 5', 'url': 'https://example.com/page-5'}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Create a Dictionary for Scraped Data\n",
    "\"\"\"\n",
    "urls = [\"https://example.com/page-1\", \"https://example.com/page-2\", \"https://example.com/page-3\", \"https://example.com/page-4\", \"https://example.com/page-5\"]\n",
    "\n",
    "# Function to scrape data\n",
    "def scrape_data(url):\n",
    "    # Extracted data\n",
    "    data = dict()\n",
    "    # TODO: Add the title to the dictionary with value \"Example Title 1\" for page 1\n",
    "    # TODO: Add the url to the dictionary with value \"https://example.com/page-1\" for page 1    \n",
    "    index = int(url.replace(base_url + '/page-', ''))\n",
    "    data['title'] = f\"Example Title {index}\"\n",
    "    data['url'] = url\n",
    "\n",
    "    return data\n",
    "\n",
    "# TODO: Loop through the urls and call the scrape_data function for each url\n",
    "# TODO: Append the returned data to the scraped_data list\n",
    "# TODO: Print the scraped_data\n",
    "# Expected Output:\n",
    "# [{'title': 'Example Title 1', 'url': 'https://example.com/page-1'}, {'title': 'Example Title 2', 'url': 'https://example.com/page-2'}, {'title': 'Example Title 3', 'url': 'https://example.com/page-3'}, {'title': 'Example Title 4', 'url': 'https://example.com/page-4'}, {'title': 'Example Title 5', 'url': 'https://example.com/page-5'}]\n",
    "scraped_data = []\n",
    "for url in urls:\n",
    "    data = scrape_data(url)\n",
    "    scraped_data.append(data)\n",
    "print(scraped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Title 1 https://example.com\n",
      "Example Title 2 https://example.com\n",
      "Example Title 3 https://example.com\n",
      "Example Title 4 https://example.com\n",
      "Example Title 5 https://example.com\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Retrieve Data from a Dictionary\n",
    "\"\"\"\n",
    "data = [{\"title\": \"Example Title 1\", \"url\": \"https://example.com\"},\n",
    "        {\"title\": \"Example Title 2\", \"url\": \"https://example.com\"},\n",
    "        {\"title\": \"Example Title 3\", \"url\": \"https://example.com\"},\n",
    "        {\"title\": \"Example Title 4\", \"url\": \"https://example.com\"},\n",
    "        {\"title\": \"Example Title 5\", \"url\": \"https://example.com\"}]\n",
    "\n",
    "# TODO: Use a for loop to loop through the data\n",
    "# TODO: Use the item[\"title\"] to get the title\n",
    "# TODO: Use the item.get(\"url\") to get the url\n",
    "# TODO: Print the title and url\n",
    "# Expected Output:\n",
    "# Example Title 1 https://example.com\n",
    "# Example Title 2 https://example.com\n",
    "# Example Title 3 https://example.com\n",
    "# Example Title 4 https://example.com\n",
    "# Example Title 5 https://example.com\n",
    "for item in data:\n",
    "    title = item[\"title\"]\n",
    "    url = item.get(\"url\")\n",
    "    print(title, url)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Example Title 1', 'url': 'https://example.com/page-1'}, {'title': 'Example Title 2', 'url': 'https://example.com/page-2'}, {'title': 'Example Title 3', 'url': 'https://example.com/page-3'}, {'title': 'Example Title 4', 'url': 'https://example.com/page-4'}, {'title': 'Example Title 5', 'url': 'https://example.com/page-5'}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Create a List of Dictionary from two Lists\n",
    "\"\"\"\n",
    "titles = [\"Example Title 1\", \"Example Title 2\", \"Example Title 3\", \"Example Title 4\", \"Example Title 5\"]\n",
    "urls = [\"https://example.com/page-1\", \"https://example.com/page-2\", \"https://example.com/page-3\", \"https://example.com/page-4\", \"https://example.com/page-5\"]\n",
    "\n",
    "# TODO: Combine the titles and urls into a list of dictionaries\n",
    "# Expected Output:\n",
    "# [{'title': 'Example Title 1', 'url': 'https://example.com/page-1'}, {'title': 'Example Title 2', 'url': 'https://example.com/page-2'}, {'title': 'Example Title 3', 'url': 'https://example.com/page-3'}, {'title': 'Example Title 4', 'url': 'https://example.com/page-4'}, {'title': 'Example Title 5', 'url': 'https://example.com/page-5'}] \n",
    "data = []\n",
    "for title, url in zip(titles, urls):\n",
    "    data.append({\"title\": title, \"url\": url})\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['title', 'url', 'tags', 'date']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Identify all keys in a Dictionary\n",
    "\"\"\"\n",
    "data = {\"title\": \"Example Title\", \"url\": \"https://example.com\", \"tags\": [\"tag1\", \"tag2\", \"tag3\"], \"date\": \"2022-01-01\"}\n",
    "\n",
    "# TODO: Use keys() method to get all keys\n",
    "# TODO: Convert the keys to a list\n",
    "# Expected Output: ['title', 'url', 'tags', 'date']\n",
    "keys = list(data.keys())\n",
    "print(keys)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: Example Title\n",
      "url: https://example.com\n",
      "author: John Doe\n",
      "tags: ['tag1', 'tag2', 'tag3']\n",
      "views: 1000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Loop through a Dictionary\n",
    "\"\"\"\n",
    "scraped_data = {\n",
    "                \"title\": \"Example Title\",\n",
    "                \"url\": \"https://example.com\",\n",
    "                \"author\": \"John Doe\",\n",
    "                \"tags\": [\"tag1\", \"tag2\", \"tag3\"],\n",
    "                \"views\": 1000\n",
    "            }\n",
    "\n",
    "# TODO: Use .items() method to loop through the dictionary\n",
    "# TODO: Print each key and value\n",
    "# Expected Output:\n",
    "# title: Example Title\n",
    "# url: https://example.com\n",
    "# author: John Doe\n",
    "# tags: ['tag1', 'tag2', 'tag3']\n",
    "# views: 1000\n",
    "for key, value in scraped_data.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article with highest views: Top 10 Web Scraping Tools\n",
      "Article with highest comments: How to Learn Python\n",
      "Comment with highest likes: Dave - Awesome list!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Extract Data from a Nested Dictionary\n",
    "\"\"\"\n",
    "scraped_data = [\n",
    "    {\n",
    "        \"category\": \"Programming\",\n",
    "        \"articles\": [\n",
    "            {\n",
    "                \"title\": \"How to Learn Python\",\n",
    "                \"url\": \"https://example.com/learn-python\",\n",
    "                \"author\": \"John Doe\",\n",
    "                \"tags\": [\"Python\", \"Programming\", \"Tutorial\"],\n",
    "                \"views\": 1200,\n",
    "                \"comments\": [\n",
    "                    {\"user\": \"Alice\", \"comment\": \"Great article!\", \"likes\": 5},\n",
    "                    {\"user\": \"Bob\", \"comment\": \"Very informative.\", \"likes\": 2}\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"title\": \"Advanced Python Tips\",\n",
    "                \"url\": \"https://example.com/advanced-python\",\n",
    "                \"author\": \"Jane Smith\",\n",
    "                \"tags\": [\"Python\", \"Advanced\", \"Tips\"],\n",
    "                \"views\": 800,\n",
    "                \"comments\": [\n",
    "                    {\"user\": \"Charlie\", \"comment\": \"Helpful for experts.\", \"likes\": 3}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Web Scraping\",\n",
    "        \"articles\": [\n",
    "            {\n",
    "                \"title\": \"Top 10 Web Scraping Tools\",\n",
    "                \"url\": \"https://example.com/web-scraping-tools\",\n",
    "                \"author\": \"Jane Smith\",\n",
    "                \"tags\": [\"Web Scraping\", \"Tools\", \"Technology\"],\n",
    "                \"views\": 1500,\n",
    "                \"comments\": [\n",
    "                    {\"user\": \"Dave\", \"comment\": \"Awesome list!\", \"likes\": 10}\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"title\": \"Understanding BeautifulSoup\",\n",
    "                \"url\": \"https://example.com/beautifulsoup\",\n",
    "                \"author\": \"Alice Johnson\",\n",
    "                \"tags\": [\"Web Scraping\", \"BeautifulSoup\", \"Python\"],\n",
    "                \"views\": 1100,\n",
    "                \"comments\": [\n",
    "                    {\"user\": \"Eve\", \"comment\": \"Great for beginners.\", \"likes\": 4},\n",
    "                    {\"user\": \"Frank\", \"comment\": \"Clear explanation!\", \"likes\": 6}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"APIs\",\n",
    "        \"articles\": [\n",
    "            {\n",
    "                \"title\": \"Understanding REST APIs\",\n",
    "                \"url\": \"https://example.com/rest-apis\",\n",
    "                \"author\": \"John Doe\",\n",
    "                \"tags\": [\"APIs\", \"REST\", \"Web Development\"],\n",
    "                \"views\": 900,\n",
    "                \"comments\": [\n",
    "                    {\"user\": \"Grace\", \"comment\": \"Very clear overview.\", \"likes\": 7}\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"title\": \"GraphQL vs REST\",\n",
    "                \"url\": \"https://example.com/graphql-vs-rest\",\n",
    "                \"author\": \"Charlie Brown\",\n",
    "                \"tags\": [\"APIs\", \"GraphQL\", \"Comparison\"],\n",
    "                \"views\": 1300,\n",
    "                \"comments\": [\n",
    "                    {\"user\": \"Hannah\", \"comment\": \"Helpful comparison!\", \"likes\": 9}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# TODO: Show the article data with the highest number of views\n",
    "# TODO: Which article has the highest number of comments\n",
    "# TODO: Which coment has the highest number of likes\n",
    "# Expected Output:\n",
    "# Article with highest views: How to Learn Python\n",
    "# Article with highest comments: How to Learn Python\n",
    "# Comment with highest likes: Dave - Awesome list!\n",
    "highest_views = 0\n",
    "highest_comments = 0\n",
    "highest_likes = 0\n",
    "highest_views_article = \"\"\n",
    "highest_comments_article = \"\"\n",
    "highest_likes_comment = \"\"\n",
    "highest_likes_user = \"\"\n",
    "for category in scraped_data:\n",
    "    for article in category[\"articles\"]:\n",
    "        if article[\"views\"] > highest_views:\n",
    "            highest_views = article[\"views\"]\n",
    "            highest_views_article = article[\"title\"]\n",
    "        if len(article[\"comments\"]) > highest_comments:\n",
    "            highest_comments = len(article[\"comments\"])\n",
    "            highest_comments_article = article[\"title\"]\n",
    "        for comment in article[\"comments\"]:\n",
    "            if comment[\"likes\"] > highest_likes:\n",
    "                highest_likes = comment[\"likes\"]\n",
    "                highest_likes_comment = comment[\"comment\"]\n",
    "                highest_likes_user = comment[\"user\"]\n",
    "print(f\"Article with highest views: {highest_views_article}\")\n",
    "print(f\"Article with highest comments: {highest_comments_article}\")\n",
    "print(f\"Comment with highest likes: {highest_likes_user} - {highest_likes_comment}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reflection**\n",
    "What is the difference between using item[\"keys\"] with item.get(\"keys\")? What happens if the key isn't exist?\n",
    "\n",
    "(answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER HERE\n",
    "\n",
    "item['keys'] digunakan hanya key nya sudah yakin ada, sedangkan item.get('keys') lebih flexible dimana jika tidak ada akan mengembalikan none atau defailt nilai jika diberikan misal item.get('keys', 'defKeys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exploration**\n",
    "Python Collections provides specialized container datatypes beyond the standard Python collection types like lists, tuples, sets, and dictionaries. These container types are designed to make certain tasks more efficient and readable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
