{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **X API**\n",
    "The X API can be used to programmatically retrieve and analyze X data, as well as build for the conversation on X.\n",
    "\n",
    "Over the years, the X API has grown by adding additional levels of access for developers to be able to scale their access to enhance and research the public conversation.\n",
    "\n",
    "Read carefully the documentation here https://docs.x.com/x-api/introduction\n",
    "\n",
    "To fully understand what the API does, you have to answer the following questions:\n",
    "1. What does this API do, and what problems does it solve?\n",
    "2. What authentication methods does the API support (e.g., API keys, OAuth 2.0)?\n",
    "3. What are the parameters we need to pass?\n",
    "4. How do you obtain the necessary credentials?\n",
    "5. What is the pricing model of the API?\n",
    "6. What are the access levels and limitations?\n",
    "7. How many requests can you make in a given time period?\n",
    "8. What are the data formats and response structures?\n",
    "9. What kind of projects can you build with this API?\n",
    "10. Does the API offer official or third-party libraries for your programming language?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this guide we will learn how to get the recent post.\n",
    "If you are using postman, you can follow https://docs.x.com/x-api/posts/search/quickstart/recent-search\n",
    "\n",
    "If you are using python, follow this https://docs.x.com/x-api/posts/recent-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited. Waiting 1 seconds...\n",
      "Rate limited. Waiting 2 seconds...\n",
      "Rate limited. Waiting 4 seconds...\n",
      "Rate limited. Waiting 8 seconds...\n",
      "Rate limited. Waiting 16 seconds...\n",
      "Max retries reached. Please try again later.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Get the recent post from X\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# This endpoint returns posts from the last 7 days that match a search query\n",
    "url = \"https://api.x.com/2/tweets/search/recent\"\n",
    "\n",
    "# Authorization by Bearer Token\n",
    "headers = {\"Authorization\": \"Bearer AAAAAAAAAAAAAAAAAAAAABb7zgEAAAAAzA%2BoyKCFlOxcVC%2F4ru43DcXcjIA%3DGaOypInPohZPPo423mceve3h20Dt6uq9V3bKDnCCt45Uv1XkWh\"}\n",
    "\n",
    "# Query parameters\n",
    "querystring = {\"query\":\"donald trump\",\n",
    "               \"max_results\":\"10\"}\n",
    "\n",
    "\n",
    "# TODO: Go to your dashboard and get your Bearer Token\n",
    "# TODO: Replace YOUR_QUERY with your search query\n",
    "# TODO: Get the response and check the status code\n",
    "# TODO: Analyze the response, what data is returned?\n",
    "\n",
    "wait_time = 1  # Initial wait time in seconds\n",
    "max_retries = 5\n",
    "retry_count = 0\n",
    "\n",
    "while retry_count < max_retries:\n",
    "    response = requests.get(url, headers=headers, params=querystring)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        print(\"\\nResponse Data Analysis:\")\n",
    "        print(f\"Number of tweets: {len(data.get('data', []))}\")\n",
    "        print(\"\\nSample tweet data:\")\n",
    "        for tweet in data.get('data', [])[:2]:\n",
    "            print(f\"\\nTweet ID: {tweet['id']}\")\n",
    "            print(f\"Text: {tweet['text']}\")\n",
    "            print(\"---\")\n",
    "        break\n",
    "    elif response.status_code == 429:\n",
    "        print(f\"Rate limited. Waiting {wait_time} seconds...\")\n",
    "        time.sleep(wait_time)\n",
    "        wait_time *= 2  \n",
    "        retry_count += 1\n",
    "    else:\n",
    "        print(f\"Error: {response.text}\")\n",
    "        break\n",
    "\n",
    "if retry_count == max_retries:\n",
    "    print(\"Max retries reached. Please try again later.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Objective: Understanding response data\n",
    "\"\"\"\n",
    "# TODO: From the previous request, print the response text\n",
    "# TODO: Parse the data into more readable format and print the data\n",
    "# TODO: Clean the data and print it\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Print raw response text\n",
    "print(\"Raw Response:\")\n",
    "print(json.dumps(response.json(), indent=2))\n",
    "\n",
    "# Parse and format the data\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    \n",
    "    # Clean and format the data\n",
    "    cleaned_tweets = []\n",
    "    for tweet in data.get('data', []):\n",
    "        cleaned_tweet = {\n",
    "            'id': tweet['id'],\n",
    "            'text': tweet['text'].replace('\\n', ' ').strip(),\n",
    "            'created_at': datetime.strptime(tweet['created_at'], \n",
    "                                          '%Y-%m-%dT%H:%M:%S.%fZ').strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'author_id': tweet['author_id'],\n",
    "            'metrics': {\n",
    "                'retweets': tweet['public_metrics']['retweet_count'],\n",
    "                'likes': tweet['public_metrics']['like_count'],\n",
    "                'replies': tweet['public_metrics']['reply_count']\n",
    "            }\n",
    "        }\n",
    "        cleaned_tweets.append(cleaned_tweet)\n",
    "    \n",
    "    # Print formatted data\n",
    "    print(\"\\nCleaned and Formatted Data:\")\n",
    "    for tweet in cleaned_tweets:\n",
    "        print(\"\\nTweet Details:\")\n",
    "        print(f\"ID: {tweet['id']}\")\n",
    "        print(f\"Created: {tweet['created_at']}\")\n",
    "        print(f\"Text: {tweet['text']}\")\n",
    "        print(f\"Metrics: {tweet['metrics']}\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited. Waiting 1 seconds...\n",
      "Rate limited. Waiting 2 seconds...\n",
      "Rate limited. Waiting 4 seconds...\n",
      "Rate limited. Waiting 8 seconds...\n",
      "Rate limited. Waiting 16 seconds...\n",
      "Max retries reached. Please try again later.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Build a custom query for more specific data\n",
    "\"\"\"\n",
    "# TODO: Build a custom query and send a new request by using https://developer.x.com/apitools/\n",
    "# TODO: Experiment with different query parameters and see what data is returned\n",
    "\n",
    "# Custom query with specific search criteria\n",
    "import requests\n",
    "import time\n",
    "url = \"https://api.x.com/2/tweets/search/recent\"\n",
    "headers = {\"Authorization\": \"Bearer AAAAAAAAAAAAAAAAAAAAABb7zgEAAAAAzA%2BoyKCFlOxcVC%2F4ru43DcXcjIA%3DGaOypInPohZPPo423mceve3h20Dt6uq9V3bKDnCCt45Uv1XkWh\"}\n",
    "\n",
    "# Search parameters\n",
    "querystring = {\n",
    "    \"query\": \"#python min_retweets:100 min_faves:50 -is:reply lang:en\",\n",
    "    \"max_results\": \"10\",\n",
    "    \"tweet.fields\": \"created_at,public_metrics,referenced_tweets\",\n",
    "    \"expansions\": \"author_id\",\n",
    "    \"user.fields\": \"username,verified,description\"\n",
    "}\n",
    "\n",
    "# Send request with retry logic\n",
    "wait_time = 1\n",
    "max_retries = 5\n",
    "retry_count = 0\n",
    "\n",
    "while retry_count < max_retries:\n",
    "    response = requests.get(url, headers=headers, params=querystring)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        users = {u['id']: u for u in data.get('includes', {}).get('users', [])}\n",
    "        \n",
    "        print(f\"\\nFound {len(data.get('data', []))} popular Python tweets:\")\n",
    "        for tweet in data.get('data', []):\n",
    "            author = users.get(tweet['author_id'], {})\n",
    "            metrics = tweet['public_metrics']\n",
    "            \n",
    "            print(f\"\\n@{author.get('username', 'unknown')}:\")\n",
    "            print(f\"Tweet: {tweet['text']}\")\n",
    "            # print(f\"Retweets: {metrics['retweet_count']}\")\n",
    "            print(f\"Likes: {metrics['like_count']}\")\n",
    "            print(f\"Created: {tweet['created_at']}\")\n",
    "            print(\"-\" * 50)\n",
    "        break\n",
    "        \n",
    "    elif response.status_code == 429:\n",
    "        print(f\"Rate limited. Waiting {wait_time} seconds...\")\n",
    "        time.sleep(wait_time)\n",
    "        wait_time *= 2\n",
    "        retry_count += 1\n",
    "    else:\n",
    "        print(f\"Error: {response.text}\")\n",
    "        break\n",
    "\n",
    "if retry_count == max_retries:\n",
    "    print(\"Max retries reached. Please try again later.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First request status code: 200\n",
      "\n",
      "Second request status code: 429\n",
      "\n",
      "Response content:\n",
      "{'title': 'Too Many Requests', 'detail': 'Too Many Requests', 'type': 'about:blank', 'status': 429}\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Understanding rate limit on API requests\n",
    "\"\"\"\n",
    "# TODO: Send another request and check the status code\n",
    "# TODO: Did you get blocked? if so, why? explain it!\n",
    "\n",
    "\"\"\" \n",
    "Expected Output:\n",
    "{'title': 'Too Many Requests',\n",
    " 'detail': 'Too Many Requests',\n",
    " 'type': 'about:blank',\n",
    " 'status': 429}\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "url = \"https://api.x.com/2/tweets/search/recent\"\n",
    "headers = {\"Authorization\": \"Bearer AAAAAAAAAAAAAAAAAAAAABb7zgEAAAAAzA%2BoyKCFlOxcVC%2F4ru43DcXcjIA%3DGaOypInPohZPPo423mceve3h20Dt6uq9V3bKDnCCt45Uv1XkWh\"}\n",
    "querystring = {\"query\": \"python\", \"max_results\": \"10\"}\n",
    "\n",
    "response1 = requests.get(url, headers=headers, params=querystring)\n",
    "print(\"First request status code:\", response1.status_code)\n",
    "\n",
    "response2 = requests.get(url, headers=headers, params=querystring)\n",
    "print(\"\\nSecond request status code:\", response2.status_code)\n",
    "print(\"\\nResponse content:\")\n",
    "print(response2.json())\n",
    "\n",
    "#I got blocked with a 429 status code (\"Too Many Requests\"). This happened because:\n",
    "# We made two requests in rapid succession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed. Status code: 429\n",
      "Waiting 1 seconds before retry...\n",
      "Request failed. Status code: 429\n",
      "Waiting 2 seconds before retry...\n",
      "Request failed. Status code: 429\n",
      "Waiting 4 seconds before retry...\n",
      "Request failed. Status code: 429\n",
      "Waiting 8 seconds before retry...\n",
      "Request failed. Status code: 429\n",
      "Waiting 16 seconds before retry...\n",
      "Request failed. Status code: 429\n",
      "Waiting 32 seconds before retry...\n",
      "Request failed. Status code: 429\n",
      "Waiting 64 seconds before retry...\n",
      "Request failed. Status code: 429\n",
      "Waiting 128 seconds before retry...\n",
      "Request failed. Status code: 429\n",
      "Waiting 256 seconds before retry...\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Bypassing unknown rate limit.\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Send another request to https://api.x.com/2/tweets/search/recent make sure its failed\n",
    "# TODO: Once the request is failed, loop it until the status code is 200 and add waiting time between each request\n",
    "# TODO: For every failed request, double the waiting time\n",
    "# TODO: Once the status code is 200, print the response and the waiting time\n",
    "# TODO: What is the rate limit?\n",
    "\n",
    "import requests, time\n",
    "\n",
    "url = \"https://api.x.com/2/tweets/search/recent\"\n",
    "\n",
    "headers = {\"Authorization\": \"Bearer AAAAAAAAAAAAAAAAAAAAABb7zgEAAAAAzA%2BoyKCFlOxcVC%2F4ru43DcXcjIA%3DGaOypInPohZPPo423mceve3h20Dt6uq9V3bKDnCCt45Uv1XkWh\"}\n",
    "querystring = {\"query\": \"python\", \"max_results\": \"10\"}\n",
    "\n",
    "wait_time = 1  \n",
    "success = False\n",
    "total_wait_time = 0\n",
    "\n",
    "# Loop until successful response\n",
    "while not success:\n",
    "    # Send request\n",
    "    response = requests.get(url, headers=headers, params=querystring)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        # Success - print response and total wait time\n",
    "        print(f\"\\nSuccess after waiting {total_wait_time} seconds!\")\n",
    "        print(\"\\nResponse data:\")\n",
    "        print(json.dumps(response.json(), indent=2))\n",
    "        success = True\n",
    "    else:\n",
    "        # Failed request - wait and double the wait time\n",
    "        print(f\"Request failed. Status code: {response.status_code}\")\n",
    "        print(f\"Waiting {wait_time} seconds before retry...\")\n",
    "        time.sleep(wait_time)\n",
    "        total_wait_time += wait_time\n",
    "        wait_time *= 2  # Double the wait time\n",
    "\n",
    "print(f\"\\nRate limit appears to be approximately {total_wait_time} seconds between requests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: {\"client_id\":\"30341910\",\"detail\":\"When authenticating requests to the Twitter API v2 endpoints, you must use keys and tokens from a Twitter developer App that is attached to a Project. You can create a project via the developer portal.\",\"registration_url\":\"https://developer.twitter.com/en/docs/projects/overview\",\"title\":\"Client Forbidden\",\"required_enrollment\":\"Appropriate Level of API Access\",\"reason\":\"client-not-enrolled\",\"type\":\"https://api.twitter.com/2/problems/client-forbidden\"}\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Using another endpoint\n",
    "\"\"\"\n",
    "# TODO: Try to use Users endpoint, for example get the list of Users that are being followed by the provided User ID\n",
    "\n",
    "# Get list of followed users for a specific user ID\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Users endpoint for following list\n",
    "user_id = \"2244994945\"  # Example user ID\n",
    "url = f\"https://api.x.com/2/users/{user_id}/following\"\n",
    "\n",
    "# Authorization header\n",
    "headers = {\"Authorization\": \"Bearer AAAAAAAAAAAAAAAAAAAAABb7zgEAAAAAzA%2BoyKCFlOxcVC%2F4ru43DcXcjIA%3DGaOypInPohZPPo423mceve3h20Dt6uq9V3bKDnCCt45Uv1XkWh\"}\n",
    "\n",
    "# Query parameters\n",
    "params = {\n",
    "    \"max_results\": 10,\n",
    "    \"user.fields\": \"username,name,description,public_metrics\"\n",
    "}\n",
    "\n",
    "# Send request with retry logic\n",
    "wait_time = 1\n",
    "max_retries = 5\n",
    "retry_count = 0\n",
    "\n",
    "while retry_count < max_retries:\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        print(f\"\\nFound {len(data.get('data', []))} followed users:\")\n",
    "        \n",
    "        for user in data.get('data', []):\n",
    "            print(f\"\\nUsername: @{user['username']}\")\n",
    "            print(f\"Name: {user['name']}\")\n",
    "            print(f\"Description: {user.get('description', 'No description')}\")\n",
    "            print(f\"Metrics: {user.get('public_metrics', {})}\")\n",
    "            print(\"-\" * 50)\n",
    "        break\n",
    "        \n",
    "    elif response.status_code == 429:\n",
    "        print(f\"Rate limited. Waiting {wait_time} seconds...\")\n",
    "        time.sleep(wait_time)\n",
    "        wait_time *= 2\n",
    "        retry_count += 1\n",
    "    else:\n",
    "        print(f\"Error: {response.text}\")\n",
    "        break\n",
    "\n",
    "if retry_count == max_retries:\n",
    "    print(\"Max retries reached. Please try again later.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reflection**\n",
    "Why there should be any rate limit?\n",
    "\n",
    "Rate limits are essential in APIs for several important reasons:\n",
    "\n",
    "1. Server Resource Management\n",
    "   \n",
    "   - Prevents server overload\n",
    "   - Ensures fair distribution of resources\n",
    "   - Maintains system stability and performance\n",
    "2. Cost Control\n",
    "   \n",
    "   - Helps manage infrastructure costs\n",
    "   - Enables tiered pricing models\n",
    "   - Controls bandwidth usage\n",
    "3. Security\n",
    "   \n",
    "   - Prevents abuse and DDoS attacks\n",
    "   - Limits scraping and data harvesting\n",
    "   - Protects against brute force attempts\n",
    "4. Service Quality\n",
    "   \n",
    "   - Ensures consistent service for all users\n",
    "   - Maintains response time reliability\n",
    "   - Prevents degradation of service quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exploration**\n",
    "- Expand the current X post scraping to create a sentiment analysis\n",
    "- Explore another tools and libraries to simplify scraping process here https://docs.x.com/x-api/tools-and-libraries/overview#python\n",
    "- Explore about another publicly available API (Facebook, LinkedIn, Zillow, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Here's an example of how to add sentiment analysis to the X post scraping using NLTK's VADER sentiment analyzer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize VADER sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# X API setup\n",
    "url = \"https://api.x.com/2/tweets/search/recent\"\n",
    "headers = {\"Authorization\": \"Bearer AAAAAAAAAAAAAAAAAAAAABb7zgEAAAAAzA%2BoyKCFlOxcVC%2F4ru43DcXcjIA%3DGaOypInPohZPPo423mceve3h20Dt6uq9V3bKDnCCt45Uv1XkWh\"}\n",
    "\n",
    "# Search parameters\n",
    "querystring = {\n",
    "    \"query\": \"python programming\",\n",
    "    \"max_results\": \"100\",\n",
    "    \"tweet.fields\": \"created_at,public_metrics\"\n",
    "}\n",
    "\n",
    "# Get tweets and analyze sentiment\n",
    "response = requests.get(url, headers=headers, params=querystring)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    tweets_data = []\n",
    "    data = response.json()\n",
    "    \n",
    "    for tweet in data.get('data', []):\n",
    "        # Get sentiment scores\n",
    "        sentiment = sia.polarity_scores(tweet['text'])\n",
    "        \n",
    "        # Create tweet dictionary with sentiment\n",
    "        tweet_dict = {\n",
    "            'created_at': tweet['created_at'],\n",
    "            'text': tweet['text'],\n",
    "            'retweets': tweet['public_metrics']['retweet_count'],\n",
    "            'likes': tweet['public_metrics']['like_count'],\n",
    "            'compound_sentiment': sentiment['compound'],\n",
    "            'positive_score': sentiment['pos'],\n",
    "            'negative_score': sentiment['neg'],\n",
    "            'neutral_score': sentiment['neu']\n",
    "        }\n",
    "        tweets_data.append(tweet_dict)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(tweets_data)\n",
    "    \n",
    "    # Basic sentiment analysis\n",
    "    print(\"\\nSentiment Analysis Results:\")\n",
    "    print(f\"Average sentiment score: {df['compound_sentiment'].mean():.3f}\")\n",
    "    print(f\"Positive tweets: {len(df[df['compound_sentiment'] > 0])} ({len(df[df['compound_sentiment'] > 0])/len(df)*100:.1f}%)\")\n",
    "    print(f\"Negative tweets: {len(df[df['compound_sentiment'] < 0])} ({len(df[df['compound_sentiment'] < 0])/len(df)*100:.1f}%)\")\n",
    "    print(f\"Neutral tweets: {len(df[df['compound_sentiment'] == 0])} ({len(df[df['compound_sentiment'] == 0])/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    # Display most positive and negative tweets\n",
    "    print(\"\\nMost Positive Tweet:\")\n",
    "    most_positive = df.loc[df['compound_sentiment'].idxmax()]\n",
    "    print(f\"Text: {most_positive['text']}\")\n",
    "    print(f\"Sentiment Score: {most_positive['compound_sentiment']:.3f}\")\n",
    "    \n",
    "    print(\"\\nMost Negative Tweet:\")\n",
    "    most_negative = df.loc[df['compound_sentiment'].idxmin()]\n",
    "    print(f\"Text: {most_negative['text']}\")\n",
    "    print(f\"Sentiment Score: {most_negative['compound_sentiment']:.3f}\")\n",
    "    \n",
    "    # Create visualization\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(df['compound_sentiment'], bins=20)\n",
    "    plt.title('Distribution of Sentiment Scores')\n",
    "    plt.xlabel('Sentiment Score')\n",
    "    plt.ylabel('Number of Tweets')\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(f\"Error: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Here's an example using Tweepy, a popular Python library for X API:\n",
    "\n",
    "Install tweepy and pandas libraries using pip:\n",
    "\n",
    "#pip install tweepy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Authentication credentials\n",
    "bearer_token = \"AAAAAAAAAAAAAAAAAAAAABb7zgEAAAAAzA%2BoyKCFlOxcVC%2F4ru43DcXcjIA%3DGaOypInPohZPPo423mceve3h20Dt6uq9V3bKDnCCt45Uv1XkWh\"\n",
    "\n",
    "# Create client instance\n",
    "client = tweepy.Client(bearer_token=bearer_token)\n",
    "\n",
    "# Search tweets with Tweepy\n",
    "query = \"python programming -is:retweet lang:en\"\n",
    "tweets = client.search_recent_tweets(\n",
    "    query=query,\n",
    "    max_results=100,\n",
    "    tweet_fields=['created_at', 'public_metrics'],\n",
    "    user_fields=['username', 'name'],\n",
    "    expansions=['author_id']\n",
    ")\n",
    "\n",
    "# Process tweets data\n",
    "if tweets.data:\n",
    "    # Create user dictionary for easy lookup\n",
    "    users = {user.id: user for user in tweets.includes['users']}\n",
    "    \n",
    "    # Prepare data for DataFrame\n",
    "    tweets_list = []\n",
    "    for tweet in tweets.data:\n",
    "        tweets_list.append({\n",
    "            'created_at': tweet.created_at,\n",
    "            'text': tweet.text,\n",
    "            'author': users[tweet.author_id].username,\n",
    "            'retweets': tweet.public_metrics['retweet_count'],\n",
    "            'likes': tweet.public_metrics['like_count'],\n",
    "            'replies': tweet.public_metrics['reply_count']\n",
    "        })\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(tweets_list)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nRecent Python Programming Tweets:\")\n",
    "    print(f\"Total tweets collected: {len(df)}\")\n",
    "    print(\"\\nMost engaged tweets:\")\n",
    "    print(df.nlargest(5, 'likes')[['author', 'text', 'likes', 'retweets']])\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv('python_tweets.csv', index=False)\n",
    "    print(\"\\nData saved to python_tweets.csv\")\n",
    "\n",
    "else:\n",
    "    print(\"No tweets found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Here's an example using the GitHub API, which is publicly available and has generous rate limits for basic usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# GitHub API endpoint for searching repositories\n",
    "url = \"https://api.github.com/search/repositories\"\n",
    "\n",
    "# Search parameters\n",
    "params = {\n",
    "    \"q\": \"language:python stars:>1000\",\n",
    "    \"sort\": \"stars\",\n",
    "    \"order\": \"desc\",\n",
    "    \"per_page\": 20\n",
    "}\n",
    "\n",
    "# Send request\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    repos = []\n",
    "    \n",
    "    for repo in data['items']:\n",
    "        repo_data = {\n",
    "            'name': repo['name'],\n",
    "            'owner': repo['owner']['login'],\n",
    "            'stars': repo['stargazers_count'],\n",
    "            'forks': repo['forks_count'],\n",
    "            'language': repo['language'],\n",
    "            'description': repo['description'],\n",
    "            'created_at': datetime.strptime(repo['created_at'], '%Y-%m-%dT%H:%M:%SZ').strftime('%Y-%m-%d'),\n",
    "            'url': repo['html_url']\n",
    "        }\n",
    "        repos.append(repo_data)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(repos)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nTop Python Repositories on GitHub:\")\n",
    "    print(f\"Total repositories found: {data['total_count']}\")\n",
    "    print(\"\\nTop 5 repositories by stars:\")\n",
    "    print(df[['name', 'owner', 'stars', 'forks']].head())\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv('top_python_repos.csv', index=False)\n",
    "    print(\"\\nData saved to top_python_repos.csv\")\n",
    "    \n",
    "    # Get rate limit info\n",
    "    rate_limit = requests.get('https://api.github.com/rate_limit').json()\n",
    "    print(f\"\\nAPI Rate Limit Remaining: {rate_limit['resources']['search']['remaining']}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(response.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
