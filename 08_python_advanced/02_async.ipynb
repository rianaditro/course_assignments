{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Asynchronous Web Scraping**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocking vs Non-Blocking code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Blocking Code Example\n",
    "\n",
    "In blocking code, each task waits for the previous one to finish before starting.\n",
    "\n",
    "```python\n",
    "# Blocking code example with multiple tasks\n",
    "import time\n",
    "\n",
    "# Simulate a blocking task\n",
    "def read_file(file_name):\n",
    "    print(f\"Reading file: {file_name}\")\n",
    "    time.sleep(2)  # Simulate a time delay for reading a file (2 seconds)\n",
    "    print(f\"Finished reading {file_name}\")\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Simulate multiple blocking tasks\n",
    "    read_file(\"file1.txt\")\n",
    "    read_file(\"file2.txt\")\n",
    "    read_file(\"file3.txt\")\n",
    "    \n",
    "    print(f\"All tasks finished in {time.time() - start_time} seconds.\")\n",
    "\n",
    "main()\n",
    "```\n",
    "---\n",
    "\n",
    "#### 2. Non-blocking Code Example\n",
    "\n",
    "In non-blocking code, the program can start a new task without waiting for the previous one to finish. This is achieved using asynchronous programming.\n",
    "\n",
    "```python\n",
    "import aiofiles\n",
    "import asyncio\n",
    "\n",
    "# Non-blocking task using asyncio\n",
    "async def read_file(file_name):\n",
    "    print(f\"Reading file: {file_name}\")\n",
    "    await asyncio.sleep(2)  # Simulate a time delay without blocking\n",
    "    print(f\"Finished reading {file_name}\")\n",
    "\n",
    "# Main execution\n",
    "async def main():\n",
    "    start_time = asyncio.get_event_loop().time()\n",
    "    \n",
    "    # Start multiple tasks concurrently\n",
    "    tasks = [\n",
    "        read_file(\"file1.txt\"),\n",
    "        read_file(\"file2.txt\"),\n",
    "        read_file(\"file3.txt\")\n",
    "    ]\n",
    "    \n",
    "    # Run all tasks concurrently\n",
    "    await asyncio.gather(*tasks)\n",
    "    \n",
    "    print(f\"All tasks finished in {asyncio.get_event_loop().time() - start_time} seconds.\")\n",
    "\n",
    "# Run the async program\n",
    "asyncio.run(main())\n",
    "```\n",
    "---\n",
    "**Situation:**  \n",
    "You have 10 kilograms of dirty laundry, and you went to a self-service laundry. The machines can each hold up to 3 kilograms of clothes, and each machine takes 1 hour to finish a load. If you use just one machine, it will take 4 hours to finish all your laundry. How can you speed up the process?\n",
    "\n",
    "**Situation:** You have a date in one hour, and you want to impress your crush with a fresh haircut. However, you also need to do laundry because you donâ€™t have any clean clothes to wear for work tomorrow. How would you handle this situation?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Asynchronous web scraping** allows you to send multiple HTTP requests concurrently without blocking the execution of the program. This is ideal for I/O-bound tasks like scraping many web pages, as it enables the program to process multiple requests at once, reducing total scraping time.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "- **Event Loop**: Manages asynchronous tasks, allowing one task to run while others wait.\n",
    "- **Non-blocking I/O**: HTTP requests don't block the program; it continues to send more requests or process other tasks while waiting for responses.\n",
    "- **Coroutines**: Functions defined with `async def` that can be paused and resumed.\n",
    "- **`await`**: Pauses a coroutine until a result is available, such as the response from an HTTP request.\n",
    "\n",
    "### Example Code\n",
    "\n",
    "```python\n",
    "import aiohttp\n",
    "import asyncio\n",
    "\n",
    "async def fetch(url):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get(url) as response:\n",
    "            return await response.text()\n",
    "\n",
    "async def main():\n",
    "    urls = [\"http://example.com/page1\", \"http://example.com/page2\"]\n",
    "    tasks = [fetch(url) for url in urls]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    for result in results:\n",
    "        print(f\"Fetched {len(result)} characters\")\n",
    "\n",
    "asyncio.run(main())\n",
    "```\n",
    "\n",
    "### Advantages\n",
    "\n",
    "1. **Efficiency**: Scrapes multiple pages concurrently, reducing total time.\n",
    "2. **Low Resource Usage**: Uses a single thread, consuming less memory and CPU.\n",
    "3. **Scalability**: Handles large volumes of data without the overhead of multithreading.\n",
    "\n",
    "### Considerations\n",
    "\n",
    "- **Rate Limiting**: Respect website rate limits to avoid getting blocked.\n",
    "- **Error Handling**: Ensure proper handling for failed requests and timeouts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "Objective: Defining an Async Function\n",
    "\"\"\"\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "\n",
    "def greet():\n",
    "    time.sleep(1)\n",
    "    print(\"Hello, World!\")\n",
    "\n",
    "async def async_greet():\n",
    "    # await asyncio.sleep(1)\n",
    "    print(\"Hello, World!\")\n",
    "\n",
    "print(type(greet))\n",
    "# TODO: Print the type of async_greet()\n",
    "print(type(async_greet))\n",
    "\n",
    "print(type(greet()))\n",
    "# TODO: Print the type of returned value of async_greet()\n",
    "print(type(async_greet()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "Objective: Executing async function\n",
    "\"\"\"\n",
    "import asyncio\n",
    "\n",
    "\n",
    "async def add_numbers(a, b):\n",
    "    return a + b\n",
    "\n",
    "add_numbers(1, 2)\n",
    "asyncio.run(add_numbers(1, 2))\n",
    "\n",
    "# TODO: Try to execute add_numbers like a normal function\n",
    "# TODO: Try to execute add_numbers using asyncio.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "Objective: Executing async function\n",
    "\"\"\"\n",
    "import asyncio\n",
    "\n",
    "\n",
    "async def add_numbers(a, b):\n",
    "    return a + b\n",
    "\n",
    "def main():\n",
    "    result = None\n",
    "    # TODO: Change result value by executing add_numbers\n",
    "\n",
    "    print(result)\n",
    "\n",
    "# TODO: Execute main() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "Objective: Executing async function\n",
    "\"\"\"\n",
    "import asyncio\n",
    "\n",
    "\n",
    "async def add_numbers(a, b):\n",
    "    return a + b\n",
    "\n",
    "async def main():\n",
    "    result = None\n",
    "    # TODO: Change result value by await add_numbers\n",
    "\n",
    "    print(result)\n",
    "\n",
    "# TODO: Execute main() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "Objective: Error Handling in Async Functions\n",
    "\"\"\"\n",
    "async def divide_numbers(a, b):\n",
    "    if b == 0:\n",
    "        raise ValueError(\"Cannot divide by zero!\")\n",
    "    return a / b\n",
    "\n",
    "# TODO: Create main() function to execute divide_numbers(10, 0) asynchronously\n",
    "# TODO: Add error handling if b is zero\n",
    "# TODO: Execute main() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "Objective: Running Multiple Tasks\n",
    "\"\"\"\n",
    "import asyncio\n",
    "\n",
    "\n",
    "async def task_1():\n",
    "    print(\"Task 1 started...\")\n",
    "    await asyncio.sleep(2)\n",
    "    print(\"Task 1 completed!\")\n",
    "    return \"Result from Task 1\"\n",
    "\n",
    "# TODO: Create 2 more function like above\n",
    "# TODO: Create main function to execute all task function asynchronously\n",
    "# TODO: Execute main function\n",
    "# TODO: Analyze the flow execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "Objective: Running Multiple Tasks Concurrently\n",
    "\"\"\"\n",
    "# TODO: Change the main function using asyncio.gather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "Objective: Another way to gather many tasks at once\n",
    "Using *args\n",
    "\"\"\"\n",
    "# TODO: Improve the previous code using *args instead of calling one by one function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "Objective: Using asyncio.create_task()\n",
    "\"\"\"\n",
    "import asyncio\n",
    "\n",
    "\n",
    "async def main():\n",
    "    # Create tasks\n",
    "    t1 = asyncio.create_task(task_1())\n",
    "    # TODO: Create task for Task 2\n",
    "    # TODO: Create task for Task 3\n",
    "    \n",
    "    await t1  # Wait for Task 1 to finish\n",
    "    # TODO: Wait for Task 2 to finish\n",
    "    # TODO: Wait for Task 3 to finish\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "Objective: Combining create_task() and gather()\n",
    "\"\"\"\n",
    "import asyncio\n",
    "\n",
    "\n",
    "# Simulated web scraping task\n",
    "async def scrape_page(url):\n",
    "    print(f\"Starting {url}\")\n",
    "    await asyncio.sleep(1)  # Simulate network delay\n",
    "    print(f\"Scraped: {url}\")\n",
    "    return {\"url\": url, \"content\": f\"Dummy content from {url}\"}\n",
    "\n",
    "# Main function\n",
    "async def main():\n",
    "    urls = [\n",
    "        \"http://example.com\",\n",
    "        \"http://example.org\",\n",
    "        \"http://example.net\"\n",
    "    ]\n",
    "    \n",
    "    # Simulate creating tasks for scraping pages\n",
    "    tasks = []\n",
    "    # TODO: Create a list of task by combining scrape_page and urls list\n",
    "    \n",
    "    # Wait for all tasks to complete and gather results\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    # TODO: print the result here\n",
    "\n",
    "# TODO: Run the main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "Objective: Using asyncio.as_completed for Immediate Results\n",
    "\"\"\"\n",
    "# TODO: Import necessary package\n",
    "# TODO: Create a task function that accept 2 parameters: task name, delay time\n",
    "# TODO: Create a main function to create a list of task\n",
    "# TODO: Loop coroutine object inside asyncio.as_completed(list of task)\n",
    "# TODO: Wait the coroutine object to get the result and print it\n",
    "# TODO: Execute the main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "Objective: Simulating web scraping process\n",
    "\"\"\"\n",
    "import asyncio\n",
    "\n",
    "async def fetch_data(url):\n",
    "    await asyncio.sleep(1)  # Simulate fetch\n",
    "    print(f\"Fetched: {url}\")\n",
    "    return f\"Data from {url}\"\n",
    "\n",
    "async def process_data(data):\n",
    "    await asyncio.sleep(0.5)  # Simulate processing\n",
    "    print(f\"Processed: {data}\")\n",
    "    return f\"Processed {data}\"\n",
    "\n",
    "async def save_data(data):\n",
    "    await asyncio.sleep(0.5)  # Simulate saving\n",
    "    print(f\"Saved: {data}\")\n",
    "\n",
    "async def main():\n",
    "    urls = [\"http://example.com\", \"http://example.org\", \"http://example.net\"]\n",
    "    \n",
    "    # TODO: Fetch all data concurrently\n",
    "    # TODO: Process data concurrently\n",
    "    # TODO: Save all data concurrently\n",
    "\n",
    "# TODO: Run the workflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTTPX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "httpx is a modern Python library designed for making HTTP requests. It supports both synchronous and asynchronous programming and offers advanced features like HTTP/2 and connection pooling. Itâ€™s often described as an async-friendly alternative to requests with a similar API.\n",
    "\n",
    "---\n",
    "\n",
    "```bash\n",
    "pip install httpx\n",
    "```\n",
    "---\n",
    "\n",
    "**Basic Usage**\n",
    "**Synchronous Request**\n",
    "```python\n",
    "import httpx\n",
    "\n",
    "response = httpx.get('https://example.com')\n",
    "print(response.status_code)\n",
    "print(response.text)\n",
    "```\n",
    "---\n",
    "\n",
    "### **When to Use `httpx`**\n",
    "- **Web Scraping**: Make multiple requests concurrently with async support.\n",
    "- **APIs**: Communicate with RESTful or GraphQL APIs using efficient HTTP/2.\n",
    "- **Proxies**: Handle requests via proxy servers with ease.\n",
    "- **Modern HTTP Features**: Use advanced features like HTTP/2 and custom middleware.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "Objective: Sending a simple HTTP request using httpx\n",
    "\"\"\"\n",
    "import httpx\n",
    "\n",
    "r = httpx.get('https://httpbin.org/get')\n",
    "# TODO: Try to manipulate the r object above as you are using requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "Objective: Sending HTTP request using httpx client\n",
    "httpx.Client() is what you can use instead of requests.Session()\n",
    "\"\"\"\n",
    "import httpx\n",
    "import time\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Send the first request\n",
    "response_1 = httpx.get(\"https://httpbin.org/cookies/set?cookie_name=cookie_value\", follow_redirects=True)\n",
    "print(\"First Request (Set Cookie):\", response_1.json())\n",
    "\n",
    "# Send a second request to check cookies\n",
    "response_2 = httpx.get(\"https://httpbin.org/cookies\")\n",
    "print(\"Second Request (No Session):\", response_2.json())\n",
    "\n",
    "# TODO: Send a third request to check cookies\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Total execution time {end_time - start_time:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "Objective: Sending HTTP request using httpx client\n",
    "httpx.Client() is what you can use instead of requests.Session()\n",
    "\"\"\"\n",
    "# TODO: Improve code above by using httpx client\n",
    "# TODO: Analyze the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "Objective: Make asynchronous requests, Using AsyncClient.\n",
    "\"\"\"\n",
    "async with httpx.AsyncClient() as client:\n",
    "    response_1 = await client.get(\"https://httpbin.org/get\")\n",
    "    response_2 = await client.get(\"https://httpbin.org/get\")\n",
    "    # TODO: Add another response object from the same site\n",
    "    # TODO: Print all response status code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "Objective: Simulating sending a list of URLs\n",
    "\"\"\"\n",
    "import httpx\n",
    "import asyncio\n",
    "\n",
    "\n",
    "# List of URLs to scrape (use a test URL or public API)\n",
    "urls = [\"https://httpbin.org/get\"] * 100  # Sending 100 requests to the same URL\n",
    "\n",
    "# Function to send requests concurrently\n",
    "async def fetch(url, client):\n",
    "    print(f\"Sending request to {url}\")\n",
    "    response = await client.get(url)\n",
    "    return response.status_code  # Return the status code to track success\n",
    "\n",
    "# Main function to send all requests concurrently\n",
    "async def send_requests():\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        \n",
    "        # TODO: Use asyncio.gather to send requests concurrently      \n",
    "\n",
    "# TODO: Run the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "Objective: Monitoring progress as each task completed\n",
    "\"\"\"\n",
    "# TODO: Improve previous code to monitor progress using asyncio.as_completed()\n",
    "# TODO: Add a counter to count how many request already send"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "Objective: Limiting Concurrent Requests using Semaphore to avoid overloading the server\n",
    "\"\"\"\n",
    "# TODO: improve previous code by limiting to max 10 requests using asyncio.Semaphore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "Objective: Implement asynchronous in your web scraping\n",
    "\"\"\"\n",
    "# TODO: Create a new branch from your previous web scraping project\n",
    "# TODO: Implement asynchronous using httpx.AsyncClient\n",
    "# TODO: Push and put the github link here for grading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reflection**\n",
    "By using asynchronous, we can send multiple request at once. By doing that, what do you think will effect on the server side?\n",
    "\n",
    "(answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exploration**\n",
    "Explore how you can optimize the scraping execution time while still maintaining control over the quantity of request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course_assignments-W1NPJChe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
