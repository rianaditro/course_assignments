{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ThreadPoolExecutor for Web Scraping**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is ThreadPoolExecutor?\n",
    "`ThreadPoolExecutor` is a Python class in the `concurrent.futures` module that allows you to manage a pool of threads efficiently. It simplifies multithreading by allowing you to run multiple tasks concurrently, making it ideal for I/O-bound tasks like web scraping.\n",
    "\n",
    "---\n",
    "\n",
    "### Why Use ThreadPoolExecutor in Web Scraping?\n",
    "When web scraping, most of the time is spent waiting for server responses (I/O). Using `ThreadPoolExecutor` enables you to:\n",
    "- Scrape multiple pages concurrently.\n",
    "- Reduce overall execution time.\n",
    "- Use system resources more efficiently.\n",
    "\n",
    "---\n",
    "\n",
    "### Basic Example\n",
    "Hereâ€™s a simple example of using `ThreadPoolExecutor` to scrape multiple URLs:\n",
    "\n",
    "```python\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "\n",
    "def scrape_page(url):\n",
    "    print(f\"Scraping: {url}\")\n",
    "    time.sleep(2)  # Simulates a delay for I/O-bound tasks\n",
    "    return f\"Data from {url}\"\n",
    "\n",
    "urls = [f\"https://example.com/page{i}\" for i in range(1, 6)]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=3) as executor:  # 3 worker threads\n",
    "    results = list(executor.map(scrape_page, urls))\n",
    "\n",
    "print(\"Scraping completed!\")\n",
    "```\n",
    "- **`max_workers=3`**: Creates 3 threads to scrape URLs concurrently.\n",
    "- **`executor.map()`**: Maps the `scrape_page` function to each URL in the list.\n",
    "\n",
    "---\n",
    "\n",
    "### Benefits of Using ThreadPoolExecutor\n",
    "- **Concurrency**: Reduces execution time for I/O-bound tasks.\n",
    "- **Simple API**: Easy to use compared to manually managing threads.\n",
    "- **Scalability**: Handles many tasks efficiently by reusing threads.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Objective: Compare time execution based on basic loop\n",
    "\"\"\"\n",
    "import time\n",
    "\n",
    "\n",
    "# Simulating an I/O-bound scraping with time.sleep()\n",
    "def io_bound_scraping(scraping_id):\n",
    "    print(f\"scraping {scraping_id} started.\")\n",
    "    time.sleep(2)  # Simulate I/O operation\n",
    "    print(f\"scraping {scraping_id} completed.\")\n",
    "\n",
    "# Using basic loop\n",
    "def main():\n",
    "    # TODO: Fill main function to run io_bound_scraping 5 times\n",
    "    # TODO: (Optional) Estimate the time execution\n",
    "    pass\n",
    "        \n",
    "# Call the main function to run the scrapings\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Objective: Compare time execution based on the number of workers\n",
    "\"\"\"\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Simulating an I/O-bound scraping with time.sleep()\n",
    "def io_bound_scraping(scraping_id):\n",
    "    print(f\"scraping {scraping_id} started.\")\n",
    "    time.sleep(2)  # Simulate I/O operation\n",
    "    print(f\"scraping {scraping_id} completed.\")\n",
    "\n",
    "# Using ThreadPoolExecutor with map for faster execution\n",
    "def main():\n",
    "    # TODO: Creating a ThreadPoolExecutor with 1 threads\n",
    "    with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "        # Use map to run the scrapings concurrently\n",
    "        executor.map(io_bound_scraping, range(1,5))\n",
    "\n",
    "# Call the main function to run the scrapings\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Objective: Compare time execution based on the number of workers\n",
    "\"\"\"\n",
    "# TODO: Recreate previous code with the 2 workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Objective: Compare time execution based on the number of workers\n",
    "\"\"\"\n",
    "# TODO: Recreate previous code with the 4 workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Objective: Compare time execution based on the number of workers\n",
    "\"\"\"\n",
    "# TODO: Recreate previous code with the 500 workers for 1000\n",
    "# TODO: Analyze how your program manage to execute 500 workers at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Objective: Concurrently run function with 2 parameters or more\n",
    "\"\"\"\n",
    "# TODO: Import necessary package\n",
    "# TODO: Create a function to simulate I/O bound task with 2 parameters: task_id and delay time\n",
    "# TODO: Create list of task_id and delay time\n",
    "# TODO: Run your function with multi-threading by mapping your function with all the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Homework Assignment: Improve previous code. \n",
    "Instead of creating a list of delay time, combine the list of task_id with a constant value of delay time\n",
    "using lambda\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Objective: Implement multi-threading in web scraping\n",
    "\"\"\"\n",
    "# TODO: Implement multi-threading on your bookstoscrape project inside new branch\n",
    "# TODO: Put github url here for grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Objective: Implement multi-threading in web scraping\n",
    "\"\"\"\n",
    "# TODO: Find any news site that you like: Tribun, Detik, BBC, nytimes, etc\n",
    "# TODO: Extract data from the site in CSV\n",
    "# TODO: Push on github and put the link here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reflection**\n",
    "Monitor your resources usage while executing multi-threading, what do you think?\n",
    "\n",
    "(answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exploration**\n",
    "While Multi-threading is like adding \"more engine\", there is a better approach for improve scraping time. Find out about asynchronous concept and be prepared for the next class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course_assignments-W1NPJChe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
