{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Introduction to Python Logging**\n",
    "\n",
    "The logging module in Python provides a flexible framework for emitting log messages from your code. Logs are essential for understanding and debugging your program, especially in production environments or when you're working with complex systems like web scraping.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Why Use Logging?**\n",
    "1. **Debugging:** Helps in tracking program execution without cluttering the code with `print()` statements.\n",
    "2. **Persistence:** Logs can be saved to a file, enabling analysis after the program finishes.\n",
    "3. **Control:** You can set logging levels to filter messages based on their importance.\n",
    "4. **Structured Output:** With proper configuration, logs can include timestamps, severity levels, and more.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Basic Concepts in Logging**\n",
    "1. **Loggers:** The main entry point for logging. You can think of them as entities that emit log messages.\n",
    "2. **Handlers:** Define where the log messages go (console, file, etc.).\n",
    "3. **Levels:** Determine the severity of a log message. Common levels are:\n",
    "   - `DEBUG`: Detailed information for diagnosing problems.\n",
    "   - `INFO`: Confirmation that things are working as expected.\n",
    "   - `WARNING`: An indication of something unexpected or an issue that isn’t critical yet.\n",
    "   - `ERROR`: A serious problem that prevents the program from continuing.\n",
    "   - `CRITICAL`: A very serious error, often indicating a program crash.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Basic Logging Example**\n",
    "\n",
    "Here’s how to get started with Python's logging module:\n",
    "\n",
    "```python\n",
    "import logging\n",
    "\n",
    "# Set up a basic logger\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,  # Set the minimum logging level\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'  # Define the log message format\n",
    ")\n",
    "\n",
    "# Example log messages\n",
    "logging.debug(\"This is a debug message. Used for detailed diagnostic output.\")\n",
    "logging.info(\"This is an info message. Indicates the program is running as expected.\")\n",
    "logging.warning(\"This is a warning message. Something unexpected happened.\")\n",
    "logging.error(\"This is an error message. A problem occurred.\")\n",
    "logging.critical(\"This is a critical message. A serious error happened.\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **Output Explanation**\n",
    "When you run the code, you'll see output like this:\n",
    "\n",
    "```\n",
    "2024-12-23 14:23:01,123 - DEBUG - This is a debug message. Used for detailed diagnostic output.\n",
    "2024-12-23 14:23:01,124 - INFO - This is an info message. Indicates the program is running as expected.\n",
    "2024-12-23 14:23:01,125 - WARNING - This is a warning message. Something unexpected happened.\n",
    "2024-12-23 14:23:01,126 - ERROR - This is an error message. A problem occurred.\n",
    "2024-12-23 14:23:01,127 - CRITICAL - This is a critical message. A serious error happened.\n",
    "```\n",
    "\n",
    "- **Timestamp:** Indicates when the log was recorded.\n",
    "- **Log Level:** Shows the severity of the log message.\n",
    "- **Message:** The custom message provided.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Key Functions**\n",
    "1. **`logging.basicConfig()`**: Sets up the configuration for logging.\n",
    "2. **Logging methods:** These emit messages with a severity level:\n",
    "   - `logging.debug()`\n",
    "   - `logging.info()`\n",
    "   - `logging.warning()`\n",
    "   - `logging.error()`\n",
    "   - `logging.critical()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "Scraping completed successfully.\n",
      "Scraping page 2\n",
      "Scraping completed successfully.\n",
      "Scraping page 3\n",
      "Scraping completed successfully.\n",
      "Scraping page 4\n",
      "Scraping completed successfully.\n",
      "Scraping page 5\n",
      "Scraping completed successfully.\n",
      "Scraping page 6\n",
      "Scraping completed successfully.\n",
      "Scraping page 7\n",
      "Scraping completed successfully.\n",
      "Scraping page 8\n",
      "Scraping completed successfully.\n",
      "Scraping page 9\n",
      "Scraping completed successfully.\n",
      "Scraping page 10\n",
      "Scraping completed successfully.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Example of scraping process\n",
    "\"\"\"\n",
    "def start_scraping():\n",
    "    # Scraping page 1 to 10\n",
    "    for i in range(1, 11):\n",
    "        print(f\"Scraping page {i}\")\n",
    "        time.sleep(1)\n",
    "        # Getting page response\n",
    "        print(\"Scraping completed successfully.\")\n",
    "\n",
    "start_scraping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Scraping page 1\n",
      "INFO:root:Scraping completed successfully.\n",
      "INFO:root:Scraping page 2\n",
      "INFO:root:Scraping completed successfully.\n",
      "INFO:root:Scraping page 3\n",
      "INFO:root:Scraping completed successfully.\n",
      "INFO:root:Scraping page 4\n",
      "INFO:root:Scraping completed successfully.\n",
      "INFO:root:Scraping page 5\n",
      "INFO:root:Scraping completed successfully.\n",
      "INFO:root:Scraping page 6\n",
      "INFO:root:Scraping completed successfully.\n",
      "INFO:root:Scraping page 7\n",
      "INFO:root:Scraping completed successfully.\n",
      "INFO:root:Scraping page 8\n",
      "INFO:root:Scraping completed successfully.\n",
      "INFO:root:Scraping page 9\n",
      "INFO:root:Scraping completed successfully.\n",
      "INFO:root:Scraping page 10\n",
      "INFO:root:Scraping completed successfully.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Understand the basics of Python's logging module and why it's important. \n",
    "Logging helps you monitor your program's behavior and debug issues without relying on print statements.\n",
    "\"\"\"\n",
    "\n",
    "# TODO:\n",
    "# 1. Set up a basic logger that logs messages at the INFO level.\n",
    "# 2. Replace the start_scraping print statement with logging message.\n",
    "# 3. Log the following messages with info level:\n",
    "#    - \"Scraping page \" following by the page number\n",
    "#    - \"Scraping completed successfully.\"\n",
    "\n",
    "import logging\n",
    "\n",
    "# Create a file handler\n",
    "file_handler = logging.FileHandler('scraper.log')\n",
    "\n",
    "# Create a formatter and add it to the file handler\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "# Add the file handler to the logger\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "\n",
    "def start_scraping():\n",
    "    # Scraping page 1 to 10\n",
    "    for i in range(1, 11):\n",
    "        logging.info(f\"Scraping page {i}\")\n",
    "        time.sleep(1)   \n",
    "        # Getting page response\n",
    "        logging.info(\"Scraping completed successfully.\")\n",
    "\n",
    "start_scraping()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Scraping failed.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Setup different logs level\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Setup a logger that only log error messages\n",
    "\n",
    "\n",
    "\n",
    "def scraping_with_error_response():\n",
    "    response_code = [200, 200, 200, 200, 200, 404, 503]\n",
    "\n",
    "    # Scraping page 1 to 10\n",
    "    for i in range(1,11):\n",
    "        # TODO: Add log message for tracking page number\n",
    "        logging.info(f\"Scraping page {i}\")\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "        # Getting page response\n",
    "        response = random.choice(response_code)\n",
    "        \n",
    "        if response == 200:   \n",
    "            # TODO: Add log message for valid response\n",
    "            logging.info(\"Scraping completed successfully.\")\n",
    "\n",
    "        else:\n",
    "            # TODO: Add log message for invalid response\n",
    "            logging.error(\"Scraping failed.\")\n",
    "\n",
    "\n",
    "scraping_with_error_response()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Scraping page 1\n",
      "INFO:root:Scraping completed successfully.\n",
      "INFO:root:Scraping page 2\n",
      "INFO:root:Scraping completed successfully.\n",
      "INFO:root:Scraping page 3\n",
      "INFO:root:Scraping completed successfully.\n",
      "INFO:root:Scraping page 4\n",
      "INFO:root:Scraping completed successfully.\n",
      "INFO:root:Scraping page 5\n",
      "INFO:root:Scraping completed successfully.\n",
      "INFO:root:Scraping page 6\n",
      "INFO:root:Scraping completed successfully.\n",
      "INFO:root:Scraping page 7\n",
      "INFO:root:Scraping completed successfully.\n",
      "INFO:root:Scraping page 8\n",
      "ERROR:root:Scraping failed.\n",
      "INFO:root:Scraping page 9\n",
      "INFO:root:Scraping completed successfully.\n",
      "INFO:root:Scraping page 10\n",
      "ERROR:root:Scraping failed.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Learn to configure logging to log messages to a file for persistent records. \n",
    "This is useful for analyzing scraping sessions or debugging after the program runs.\n",
    "\"\"\"\n",
    "\n",
    "# TODO:\n",
    "# 1. Configure logging to log messages at the DEBUG level to a file named `scraper.log`.\n",
    "# 2. Add timestamps to the log messages.\n",
    "# 3. Use previous function for this task\n",
    "\n",
    "import logging\n",
    "\n",
    "# Create a file handler\n",
    "file_handler = logging.FileHandler('scraper.log')\n",
    "\n",
    "# Set the logging level to DEBUG\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "# Create a formatter with timestamps\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Add the formatter to the file handler\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "\n",
    "# Add the file handler to the logger\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "\n",
    "scraping_with_error_response()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Scraping started\n",
      "DEBUG:root:Processing URL: https://www.example.com\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): www.example.com:443\n",
      "DEBUG:urllib3.connectionpool:https://www.example.com:443 \"GET / HTTP/1.1\" 200 648\n",
      "INFO:root:Scraped 1 links from https://www.example.com\n",
      "DEBUG:root:Processing URL: https://www.google.com\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): www.google.com:443\n",
      "DEBUG:urllib3.connectionpool:https://www.google.com:443 \"GET / HTTP/1.1\" 200 None\n",
      "INFO:root:Scraped 19 links from https://www.google.com\n",
      "DEBUG:root:Processing URL: https://www.invali\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): www.invali:443\n",
      "ERROR:root:Request exception for https://www.invali: HTTPSConnectionPool(host='www.invali', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002B306806F60>: Failed to resolve 'www.invali' ([Errno 11003] getaddrinfo failed)\"))\n",
      "DEBUG:root:Processing URL: https://www.stackoverflow.com\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): www.stackoverflow.com:443\n",
      "DEBUG:urllib3.connectionpool:https://www.stackoverflow.com:443 \"GET / HTTP/1.1\" 302 None\n",
      "DEBUG:urllib3.connectionpool:https://www.stackoverflow.com:443 \"GET /questions HTTP/1.1\" 301 None\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): stackoverflow.com:443\n",
      "DEBUG:urllib3.connectionpool:https://stackoverflow.com:443 \"GET /questions HTTP/1.1\" 200 None\n",
      "DEBUG:charset_normalizer:Encoding detection: utf_8 is most likely the one.\n",
      "INFO:root:Scraped 469 links from https://www.stackoverflow.com\n",
      "INFO:root:Scraping ended\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Apply logging to a full scraping workflow and use different logging levels for various stages.\n",
    "This will help you monitor and troubleshoot scraping operations more effectively.\n",
    "\"\"\"\n",
    "\n",
    "# TODO:\n",
    "# 1. Write a script that:\n",
    "#    - Logs INFO when scraping starts.\n",
    "#    - Logs DEBUG for each URL being processed.\n",
    "#    - Logs ERROR if a request fails.\n",
    "#    - Logs INFO when scraping ends.\n",
    "# 2. Scrape data from multiple URLs, including one invalid URL to test the error logging.\n",
    "\n",
    "import logging\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='scraper.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def scrape_url(url):\n",
    "    try:\n",
    "        # Log DEBUG for each URL being processed\n",
    "        logging.debug(f'Processing URL: {url}')\n",
    "\n",
    "        # Send a GET request to the URL\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            # Parse the HTML content using BeautifulSoup\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "            # Scrape data from the HTML content (for example, extract all links)\n",
    "            links = soup.find_all('a')\n",
    "\n",
    "            # Log INFO for the scraped data\n",
    "            logging.info(f'Scraped {len(links)} links from {url}')\n",
    "        else:\n",
    "            # Log ERROR if the request fails\n",
    "            logging.error(f'Request failed for {url}: {response.status_code}')\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # Log ERROR if a request exception occurs\n",
    "        logging.error(f'Request exception for {url}: {e}')\n",
    "\n",
    "def main():\n",
    "    # Log INFO when scraping starts\n",
    "    logging.info('Scraping started')\n",
    "\n",
    "    # Scrape data from multiple URLs\n",
    "    urls = [\n",
    "        'https://www.example.com',\n",
    "        'https://www.google.com',\n",
    "        'https://www.invali',  # Invalid URL to test error logging\n",
    "        'https://www.stackoverflow.com'\n",
    "    ]\n",
    "\n",
    "    for url in urls:\n",
    "        scrape_url(url)\n",
    "\n",
    "    # Log INFO when scraping ends\n",
    "    logging.info('Scraping ended')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Objective: Explore advanced logging by using custom handlers to log messages to multiple destinations. \n",
    "This technique improves flexibility in handling log output.\n",
    "\"\"\"\n",
    "import logging\n",
    "# Create handlers\n",
    "console_handler = logging.StreamHandler() # This will shows log message in the console\n",
    "console_handler.setLevel(logging.DEBUG)\n",
    "\n",
    "# TODO: \n",
    "# 1. Create another handler for storing log in a file using logging.FileHandler('error.log')\n",
    "# 2. Set the level to DEBUG\n",
    "file_handler_error = logging.FileHandler('error.log')\n",
    "file_handler_error.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create formatter\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Attach formatter to handlers\n",
    "console_handler.setFormatter(formatter)\n",
    "# TODO: Add formatter to the file handler\n",
    "file_handler_error.setFormatter(formatter)\n",
    "\n",
    "\n",
    "# Create logger and attach handlers\n",
    "logger = logging.getLogger('ScraperLogger')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(console_handler) # Attach stream handler into the logger object\n",
    "# TODO: Attach the file handler into the logger object\n",
    "logger.addHandler(file_handler_error)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-09 22:45:34,228 - __main__ - ERROR - Error for https://books.toscrape.com/catalogue/category/books_1/page-80.html: 404 Client Error: Not Found for url: https://books.toscrape.com/catalogue/category/books_1/page-80.html\n",
      "2025-02-09 22:45:34,228 - __main__ - ERROR - Error for https://books.toscrape.com/catalogue/category/books_1/page-80.html: 404 Client Error: Not Found for url: https://books.toscrape.com/catalogue/category/books_1/page-80.html\n",
      "2025-02-09 22:45:34,228 - __main__ - ERROR - Error for https://books.toscrape.com/catalogue/category/books_1/page-80.html: 404 Client Error: Not Found for url: https://books.toscrape.com/catalogue/category/books_1/page-80.html\n",
      "2025-02-09 22:45:34,228 - __main__ - ERROR - Error for https://books.toscrape.com/catalogue/category/books_1/page-80.html: 404 Client Error: Not Found for url: https://books.toscrape.com/catalogue/category/books_1/page-80.html\n",
      "2025-02-09 22:45:34,228 - __main__ - ERROR - Error for https://books.toscrape.com/catalogue/category/books_1/page-80.html: 404 Client Error: Not Found for url: https://books.toscrape.com/catalogue/category/books_1/page-80.html\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Handling failed requests using logging\n",
    "\"\"\"\n",
    "# TODO:\n",
    "# 1. Create a function that loop through number and get the random response,\n",
    "# just like previous code but modify it as you like\n",
    "# 2. Handle stream log in the console and the error log in a file\n",
    "# 3. Provide a file that contains all of failed URL so you can retry again\n",
    "# 4. Automate the process (optional)\n",
    "\n",
    "import logging\n",
    "import random\n",
    "import requests\n",
    "\n",
    "# Create a logger\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Create a file handler for error logs\n",
    "error_handler = logging.FileHandler('error.log')\n",
    "error_handler.setLevel(logging.ERROR)\n",
    "\n",
    "# Create a console handler for stream logs\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.INFO)\n",
    "\n",
    "# Create a formatter\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Add the formatter to the handlers\n",
    "error_handler.setFormatter(formatter)\n",
    "console_handler.setFormatter(formatter)\n",
    "\n",
    "# Add the handlers to the logger\n",
    "logger.addHandler(error_handler)\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "def get_random_response():\n",
    "    numbers = [1, 2, 3, 4,80]  # replace with your numbers\n",
    "    failed_urls = []\n",
    "\n",
    "    for num in numbers:\n",
    "        url = f\"https://books.toscrape.com/catalogue/category/books_1/page-{num}.html\"  # replace with your URL\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "            logger.info(f\"Successful response for {url}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logger.error(f\"Error for {url}: {e}\")\n",
    "            failed_urls.append(url)\n",
    "\n",
    "    return failed_urls\n",
    "\n",
    "def save_failed_urls(failed_urls):\n",
    "    with open('failed_urls.txt', 'w') as f:\n",
    "        for url in failed_urls:\n",
    "            f.write(url + '\\n')\n",
    "\n",
    "def main():\n",
    "    failed_urls = get_random_response()\n",
    "    save_failed_urls(failed_urls)\n",
    "\n",
    "    if failed_urls:\n",
    "        logger.info(\"Failed URLs saved to failed_urls.txt\")\n",
    "    else:\n",
    "        logger.info(\"No failed URLs\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reflection**\n",
    "In what situation logging will help you a lot?\n",
    "\n",
    "(answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exploration**\n",
    "Explore advanced log and monitoring tools like:\n",
    "- Loguru\n",
    "- Loggly\n",
    "- Datadog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
