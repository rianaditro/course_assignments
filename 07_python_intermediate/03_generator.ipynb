{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Introduction to `yield` in Python**\n",
    "\n",
    "The `yield` keyword in Python is used to create **generators**, which are a type of iterable that allows you to produce values **lazily**, one at a time, instead of returning all at once like in a list.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Features of `yield`:**\n",
    "\n",
    "1. **State Retention:**\n",
    "   - Unlike `return`, which exits a function completely, `yield` pauses the function and retains its state. The function can be resumed from where it left off.\n",
    "\n",
    "2. **Efficient Memory Usage:**\n",
    "   - Because generators produce items one at a time, they are more memory-efficient than creating and storing all items in memory at once.\n",
    "\n",
    "3. **Simplifies Iterator Creation:**\n",
    "   - Generators eliminate the need for implementing `__iter__()` and `__next__()` methods manually.\n",
    "\n",
    "4. **Use Cases:**\n",
    "   - Generators are ideal for handling large data streams, infinite sequences, or any scenario where you don't need all the data at once.\n",
    "\n",
    "---\n",
    "\n",
    "### **How `yield` Works:**\n",
    "\n",
    "#### **1. Creating a Generator Function:**\n",
    "   - Any function that contains a `yield` statement automatically becomes a generator function.\n",
    "   - Instead of returning a single value, the function generates a series of values, pausing after each `yield`.\n",
    "\n",
    "#### Example:\n",
    "```python\n",
    "def count_up_to(n):\n",
    "    count = 1\n",
    "    while count <= n:\n",
    "        yield count\n",
    "        count += 1\n",
    "\n",
    "# Using the generator\n",
    "for num in count_up_to(5):\n",
    "    print(num)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "```\n",
    "1\n",
    "2\n",
    "3\n",
    "4\n",
    "5\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "- The function `count_up_to` pauses at each `yield` and resumes when the next value is requested.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Comparing `yield` vs `return`:**\n",
    "- **`return`**: Ends the function and sends a single value.\n",
    "- **`yield`**: Pauses the function and can return multiple values over time.\n",
    "\n",
    "```python\n",
    "def using_return():\n",
    "    return [1, 2, 3]  # Returns all values at once\n",
    "\n",
    "def using_yield():\n",
    "    yield 1\n",
    "    yield 2\n",
    "    yield 3  # Yields values one at a time\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **When to Use `yield`?**\n",
    "\n",
    "1. **Large Datasets:**\n",
    "   - When processing a dataset that is too large to fit in memory, like reading a massive file line by line.\n",
    "   \n",
    "   Example:\n",
    "   ```python\n",
    "   def read_file(file_name):\n",
    "       with open(file_name) as file:\n",
    "           for line in file:\n",
    "               yield line.strip()\n",
    "   ```\n",
    "\n",
    "2. **Infinite Sequences:**\n",
    "   - When you need to generate a potentially infinite series, such as Fibonacci numbers or prime numbers.\n",
    "   \n",
    "   Example:\n",
    "   ```python\n",
    "   def infinite_fibonacci():\n",
    "       a, b = 0, 1\n",
    "       while True:\n",
    "           yield a\n",
    "           a, b = b, a + b\n",
    "   ```\n",
    "\n",
    "3. **Pipelines:**\n",
    "   - When chaining multiple processing steps together, using generators avoids creating intermediate lists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'color'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 18\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# print(\"End of function\")\u001b[39;00m\n\u001b[0;32m     12\u001b[0m response_api \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     13\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitem\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLaptop\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m     14\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitem\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSmart Watch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m     15\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitem\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCamera\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m     16\u001b[0m ]\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28mprint\u001b[39m(start_scraping(response_api))\n",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m, in \u001b[0;36mstart_scraping\u001b[1;34m(response_api)\u001b[0m\n\u001b[0;32m      4\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m response_api:\n\u001b[1;32m----> 7\u001b[0m     color \u001b[38;5;241m=\u001b[39m i[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;66;03m# This will trigger error\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(color)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[1;31mKeyError\u001b[0m: 'color'"
     ]
    }
   ],
   "source": [
    "# Example of data lost using return\n",
    "\n",
    "def start_scraping(response_api):\n",
    "    results = []\n",
    "\n",
    "    for i in response_api:\n",
    "        color = i[\"color\"] # This will trigger error\n",
    "        results.append(color)\n",
    "    return results\n",
    "    # print(\"End of function\")\n",
    "\n",
    "response_api = [\n",
    "    {\"ID\": 1, \"item\": \"Laptop\", \"color\": \"black\"},\n",
    "    {\"ID\": 2, \"item\": \"Smart Watch\", \"color\": \"green\"},\n",
    "    {\"ID\": 3, \"item\": \"Camera\"},\n",
    "]\n",
    "\n",
    "print(start_scraping(response_api))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black\n",
      "green\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'color'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Create a generator object\u001b[39;00m\n\u001b[0;32m     16\u001b[0m results \u001b[38;5;241m=\u001b[39m start_scraping(response_api)\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m, in \u001b[0;36mstart_scraping\u001b[1;34m(response_api)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart_scraping\u001b[39m(response_api):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m response_api:\n\u001b[1;32m----> 5\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m i[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'color'"
     ]
    }
   ],
   "source": [
    "# Example of data retrieved with yield\n",
    "\n",
    "def start_scraping(response_api):\n",
    "    for i in response_api:\n",
    "        yield i[\"color\"] # This will trigger error\n",
    "        # print(\"End of function\")\n",
    "\n",
    "# Dummy data\n",
    "response_api = [\n",
    "    {\"ID\": 1, \"item\": \"Laptop\", \"color\": \"black\"},\n",
    "    {\"ID\": 2, \"item\": \"Smart Watch\", \"color\": \"green\"},\n",
    "    {\"ID\": 3, \"item\": \"Camera\"},\n",
    "]\n",
    "\n",
    "# Create a generator object\n",
    "results = start_scraping(response_api)\n",
    "\n",
    "for i in results:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8856\n",
      "192\n"
     ]
    }
   ],
   "source": [
    "# Compare the size of a list and a generator\n",
    "import sys\n",
    "\n",
    "example_list = [i for i in range(1000)]\n",
    "example_generator = (i for i in range(1000))\n",
    "\n",
    "print(sys.getsizeof(example_list))\n",
    "print(sys.getsizeof(example_generator))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversed list: [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n",
      "\n",
      "Printing each item:\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Understanding the difference between a funtion and a generator\n",
    "\"\"\"\n",
    "list_data = [i for i in range(10)]\n",
    "\n",
    "# TODO: \n",
    "# 1. Create a function that reverse a list manually, without reverse method\n",
    "# 2. Execute your function using list_data as the input parameter\n",
    "# 3. Check your function by printing them\n",
    "# 4. Print all of the item using loop\n",
    "\n",
    "def reverse_list(input_list):\n",
    "    reversed_list = []\n",
    "    for i in range(len(input_list) - 1, -1, -1):\n",
    "        reversed_list.append(input_list[i])\n",
    "    return reversed_list\n",
    "\n",
    "# Execute function with list_data\n",
    "reversed_data = reverse_list(list_data)\n",
    "\n",
    "# Print the reversed list\n",
    "print(\"Reversed list:\", reversed_data)\n",
    "\n",
    "# Print items using loop\n",
    "print(\"\\nPrinting each item:\")\n",
    "for item in reversed_data:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator object: <generator object reverse_list_generator at 0x000002C46F1D7AE0>\n",
      "\n",
      "Printing each item:\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n",
      "\n",
      "Key differences between function and generator:\n",
      "1. Memory usage: Generator creates items one at a time\n",
      "2. State: Generator maintains state between yields\n",
      "3. Output: Generator returns an iterator instead of a list\n",
      "4. Execution: Generator pauses at each yield\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Understanding the difference between a funtion and a generator\n",
    "\"\"\"\n",
    "# TODO: \n",
    "# 1. Re-create previous function using yield\n",
    "# 2. Execute your function using list_data as the input parameter\n",
    "# 3. Check your function by printing them\n",
    "# 4. Print all of the item using loop\n",
    "# 5. Analyze the difference between them\n",
    "\n",
    "def reverse_list_generator(input_list):\n",
    "    for i in range(len(input_list) - 1, -1, -1):\n",
    "        yield input_list[i]\n",
    "\n",
    "# Execute generator with list_data\n",
    "reversed_gen = reverse_list_generator(list_data)\n",
    "\n",
    "# Print the generator object\n",
    "print(\"Generator object:\", reversed_gen)\n",
    "\n",
    "# Print all items using loop\n",
    "print(\"\\nPrinting each item:\")\n",
    "for item in reversed_gen:\n",
    "    print(item)\n",
    "\n",
    "# Analysis of differences:\n",
    "print(\"\\nKey differences between function and generator:\")\n",
    "print(\"1. Memory usage: Generator creates items one at a time\")\n",
    "print(\"2. State: Generator maintains state between yields\")\n",
    "print(\"3. Output: Generator returns an iterator instead of a list\")\n",
    "print(\"4. Execution: Generator pauses at each yield\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'books_urls.csv' with 1000000 dynamic URLs has been created.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Execute this cell and take a look at csv file before continue\n",
    "import csv\n",
    "\n",
    "def create_csv(file_name, base_url, num_entries):\n",
    "    with open(file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        # Write header\n",
    "        writer.writerow([\"ID\", \"URL\"])\n",
    "        \n",
    "        # Write rows with dynamically generated URLs\n",
    "        for i in range(1, num_entries + 1):\n",
    "            # Replace \"page-20.html\" with the current ID\n",
    "            dynamic_url = base_url + f\"/catalogue/page-{i}.html\"\n",
    "            writer.writerow([i, dynamic_url])\n",
    "    \n",
    "    print(f\"CSV file '{file_name}' with {num_entries} dynamic URLs has been created.\")\n",
    "\n",
    "create_csv(\n",
    "    file_name=\"books_urls.csv\",\n",
    "    base_url=\"https://books.toscrape.com\",\n",
    "    num_entries=1000000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting https://books.toscrape.com/catalogue/page-1.html\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\u001b[38;5;241m.\u001b[39mstatus_code  \u001b[38;5;66;03m# Send a GET request and get the status code\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Raise an exception to intentionally halt the program (for testing purposes)\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Compare the speed of scraping execution from huge file of csv\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "def read_urls_from_csv(file_path):\n",
    "    \"\"\"\n",
    "    Reads a CSV file and returns a list of URLs found in the 'URL' column.\n",
    "    \"\"\"\n",
    "    urls = []  # Initialize an empty list to store URLs\n",
    "    with open(file_path, mode='r') as file:\n",
    "        # Create a CSV reader object to parse the CSV file\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        \n",
    "        # Iterate through each row in the CSV file\n",
    "        for row in csv_reader:\n",
    "            # Append the value in the 'URL' column to the urls list\n",
    "            urls.append(row[\"URL\"])\n",
    "    \n",
    "    return urls  # Return the list of URLs\n",
    "\n",
    "# Read the URLs from the CSV file into the data_csv list\n",
    "data_csv = read_urls_from_csv('books_urls.csv')\n",
    "\n",
    "# Iterate through each URL in the list\n",
    "for url in data_csv:\n",
    "    print(f\"Getting {url}\")  # Print a message indicating the URL being fetched\n",
    "    response = requests.get(url).status_code  # Send a GET request and get the status code\n",
    "    \n",
    "    # Raise an exception to intentionally halt the program (for testing purposes)\n",
    "    raise\n",
    "\n",
    "# TODO: Take a look at how long it takes before raising error\n",
    "\n",
    "# 6.7 Seconds before raising erorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular function load time: 3.09 seconds\n",
      "Generator initialization time: 0.00 seconds\n",
      "Getting https://books.toscrape.com/catalogue/page-1.html\n",
      "Time elapsed: 1.91 seconds\n",
      "\n",
      "Insights on execution time differences:\n",
      "1. Regular function took 3.09s to load all URLs\n",
      "2. Generator took only 0.00s to initialize\n",
      "3. Generator starts processing immediately without loading entire file\n",
      "4. Memory usage is significantly lower with generator\n",
      "5. Generator allows processing to begin before reading entire file\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Compare the speed of scraping execution from huge file of csv\n",
    "\"\"\"\n",
    "# TODO:\n",
    "# 1. Re-create previous function by using yield\n",
    "# 2. Compare the time execution and give your insight\n",
    "\n",
    "import requests\n",
    "import csv\n",
    "import time\n",
    "\n",
    "def read_urls_generator(file_path):\n",
    "    \"\"\"\n",
    "    Generator function that yields URLs one at a time from the CSV file\n",
    "    \"\"\"\n",
    "    with open(file_path, mode='r') as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        for row in csv_reader:\n",
    "            yield row[\"URL\"]\n",
    "\n",
    "# Test regular function timing\n",
    "start_time = time.time()\n",
    "data_csv = read_urls_from_csv('books_urls.csv')\n",
    "regular_load_time = time.time() - start_time\n",
    "print(f\"Regular function load time: {regular_load_time:.2f} seconds\")\n",
    "\n",
    "# Test generator timing\n",
    "start_time = time.time()\n",
    "urls_gen = read_urls_generator('books_urls.csv')\n",
    "gen_init_time = time.time() - start_time\n",
    "print(f\"Generator initialization time: {gen_init_time:.2f} seconds\")\n",
    "\n",
    "# Test URL fetching with generator\n",
    "start_time = time.time()\n",
    "for url in urls_gen:\n",
    "    print(f\"Getting {url}\")\n",
    "    response = requests.get(url).status_code\n",
    "    print(f\"Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "    break  # Stop after first URL for testing\n",
    "\n",
    "print(\"\\nInsights on execution time differences:\")\n",
    "print(f\"1. Regular function took {regular_load_time:.2f}s to load all URLs\")\n",
    "print(f\"2. Generator took only {gen_init_time:.2f}s to initialize\")\n",
    "print(\"3. Generator starts processing immediately without loading entire file\")\n",
    "print(\"4. Memory usage is significantly lower with generator\")\n",
    "print(\"5. Generator allows processing to begin before reading entire file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping: https://books.toscrape.com/catalogue/page-1.html\n",
      "Scraping: https://books.toscrape.com/catalogue/page-10.html\n",
      "Scraping: https://books.toscrape.com/catalogue/page-200.html\n",
      "Scraping: https://books.toscrape.com/catalogue/page-20.html\n",
      "https://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html\n",
      "https://books.toscrape.com/catalogue/tipping-the-velvet_999/index.html\n",
      "https://books.toscrape.com/catalogue/soumission_998/index.html\n",
      "https://books.toscrape.com/catalogue/sharp-objects_997/index.html\n",
      "https://books.toscrape.com/catalogue/sapiens-a-brief-history-of-humankind_996/index.html\n",
      "https://books.toscrape.com/catalogue/the-requiem-red_995/index.html\n",
      "https://books.toscrape.com/catalogue/the-dirty-little-secrets-of-getting-your-dream-job_994/index.html\n",
      "https://books.toscrape.com/catalogue/the-coming-woman-a-novel-based-on-the-life-of-the-infamous-feminist-victoria-woodhull_993/index.html\n",
      "https://books.toscrape.com/catalogue/the-boys-in-the-boat-nine-americans-and-their-epic-quest-for-gold-at-the-1936-berlin-olympics_992/index.html\n",
      "https://books.toscrape.com/catalogue/the-black-maria_991/index.html\n",
      "https://books.toscrape.com/catalogue/starving-hearts-triangular-trade-trilogy-1_990/index.html\n",
      "https://books.toscrape.com/catalogue/shakespeares-sonnets_989/index.html\n",
      "https://books.toscrape.com/catalogue/set-me-free_988/index.html\n",
      "https://books.toscrape.com/catalogue/scott-pilgrims-precious-little-life-scott-pilgrim-1_987/index.html\n",
      "https://books.toscrape.com/catalogue/rip-it-up-and-start-again_986/index.html\n",
      "https://books.toscrape.com/catalogue/our-band-could-be-your-life-scenes-from-the-american-indie-underground-1981-1991_985/index.html\n",
      "https://books.toscrape.com/catalogue/olio_984/index.html\n",
      "https://books.toscrape.com/catalogue/mesaerion-the-best-science-fiction-stories-1800-1849_983/index.html\n",
      "https://books.toscrape.com/catalogue/libertarianism-for-beginners_982/index.html\n",
      "https://books.toscrape.com/catalogue/its-only-the-himalayas_981/index.html\n",
      "https://books.toscrape.com/catalogue/modern-romance_820/index.html\n",
      "https://books.toscrape.com/catalogue/miss-peregrines-home-for-peculiar-children-miss-peregrines-peculiar-children-1_819/index.html\n",
      "https://books.toscrape.com/catalogue/louisa-the-extraordinary-life-of-mrs-adams_818/index.html\n",
      "https://books.toscrape.com/catalogue/little-red_817/index.html\n",
      "https://books.toscrape.com/catalogue/library-of-souls-miss-peregrines-peculiar-children-3_816/index.html\n",
      "https://books.toscrape.com/catalogue/large-print-heart-of-the-pride_815/index.html\n",
      "https://books.toscrape.com/catalogue/i-had-a-nice-time-and-other-lies-how-to-find-love-sht-like-that_814/index.html\n",
      "https://books.toscrape.com/catalogue/hollow-city-miss-peregrines-peculiar-children-2_813/index.html\n",
      "https://books.toscrape.com/catalogue/grumbles_812/index.html\n",
      "https://books.toscrape.com/catalogue/full-moon-over-noahs-ark-an-odyssey-to-mount-ararat-and-beyond_811/index.html\n",
      "https://books.toscrape.com/catalogue/frostbite-vampire-academy-2_810/index.html\n",
      "https://books.toscrape.com/catalogue/follow-you-home_809/index.html\n",
      "https://books.toscrape.com/catalogue/first-steps-for-new-christians-print-edition_808/index.html\n",
      "https://books.toscrape.com/catalogue/finders-keepers-bill-hodges-trilogy-2_807/index.html\n",
      "https://books.toscrape.com/catalogue/fables-vol-1-legends-in-exile-fables-1_806/index.html\n",
      "https://books.toscrape.com/catalogue/eureka-trivia-60_805/index.html\n",
      "https://books.toscrape.com/catalogue/drive-the-surprising-truth-about-what-motivates-us_804/index.html\n",
      "https://books.toscrape.com/catalogue/done-rubbed-out-reightman-bailey-1_803/index.html\n",
      "https://books.toscrape.com/catalogue/doing-it-over-most-likely-to-1_802/index.html\n",
      "https://books.toscrape.com/catalogue/deliciously-ella-every-day-quick-and-easy-recipes-for-gluten-free-snacks-packed-lunches-and-simple-meals_801/index.html\n",
      "https://books.toscrape.com/catalogue/hide-away-eve-duncan-20_620/index.html\n",
      "https://books.toscrape.com/catalogue/furiously-happy-a-funny-book-about-horrible-things_619/index.html\n",
      "https://books.toscrape.com/catalogue/everyday-italian-125-simple-and-delicious-recipes_618/index.html\n",
      "https://books.toscrape.com/catalogue/equal-is-unfair-americas-misguided-fight-against-income-inequality_617/index.html\n",
      "https://books.toscrape.com/catalogue/eleanor-park_616/index.html\n",
      "https://books.toscrape.com/catalogue/dirty-dive-bar-1_615/index.html\n",
      "https://books.toscrape.com/catalogue/can-you-keep-a-secret-fear-street-relaunch-4_614/index.html\n",
      "https://books.toscrape.com/catalogue/boar-island-anna-pigeon-19_613/index.html\n",
      "https://books.toscrape.com/catalogue/a-paris-apartment_612/index.html\n",
      "https://books.toscrape.com/catalogue/a-la-mode-120-recipes-in-60-pairings-pies-tarts-cakes-crisps-and-more-topped-with-ice-cream-gelato-frozen-custard-and-more_611/index.html\n",
      "https://books.toscrape.com/catalogue/troublemaker-surviving-hollywood-and-scientology_610/index.html\n",
      "https://books.toscrape.com/catalogue/the-widow_609/index.html\n",
      "https://books.toscrape.com/catalogue/the-sleep-revolution-transforming-your-life-one-night-at-a-time_608/index.html\n",
      "https://books.toscrape.com/catalogue/the-improbability-of-love_607/index.html\n",
      "https://books.toscrape.com/catalogue/the-art-of-startup-fundraising_606/index.html\n",
      "https://books.toscrape.com/catalogue/take-me-home-tonight-rock-star-romance-3_605/index.html\n",
      "https://books.toscrape.com/catalogue/sleeping-giants-themis-files-1_604/index.html\n",
      "https://books.toscrape.com/catalogue/setting-the-world-on-fire-the-brief-astonishing-life-of-st-catherine-of-siena_603/index.html\n",
      "https://books.toscrape.com/catalogue/playing-with-fire_602/index.html\n",
      "https://books.toscrape.com/catalogue/off-the-hook-fishing-for-trouble-1_601/index.html\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Using yield for scraping\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# Scrape product data from a list of URLs\n",
    "def scrape_product_urls(urls):\n",
    "    \"\"\"\n",
    "    Scrape product URLs from a list of pages.\n",
    "    \"\"\"\n",
    "    all_product_urls = []\n",
    "    for url in urls:\n",
    "        print(f\"Scraping: {url}\")\n",
    "\n",
    "        # TODO: \n",
    "        # 1. Get the html response of the page url\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        products = soup.find_all('article', class_='product_pod')\n",
    "        \n",
    "        # 2. Extract the items url into all_product_urls\n",
    "        for product in products:\n",
    "            # Get the link from h3 > a tag\n",
    "            link = product.h3.a['href']\n",
    "            # Convert relative URL to absolute URL\n",
    "            if not link.startswith('http'):\n",
    "                link = 'https://books.toscrape.com/catalogue/' + link\n",
    "            all_product_urls.append(link)\n",
    "\n",
    "    return all_product_urls\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    page_urls = [\n",
    "        \"https://books.toscrape.com/catalogue/page-1.html\",\n",
    "        \"https://books.toscrape.com/catalogue/page-10.html\",\n",
    "        \"https://books.toscrape.com/catalogue/page-200.html\",\n",
    "        \"https://books.toscrape.com/catalogue/page-20.html\"\n",
    "    ]\n",
    "    product_items = scrape_product_urls(page_urls)\n",
    "\n",
    "    # Print the extracted product URLs\n",
    "    for item in product_items:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping: https://books.toscrape.com/catalogue/page-1.html\n",
      "https://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html\n",
      "https://books.toscrape.com/catalogue/tipping-the-velvet_999/index.html\n",
      "https://books.toscrape.com/catalogue/soumission_998/index.html\n",
      "https://books.toscrape.com/catalogue/sharp-objects_997/index.html\n",
      "https://books.toscrape.com/catalogue/sapiens-a-brief-history-of-humankind_996/index.html\n",
      "https://books.toscrape.com/catalogue/the-requiem-red_995/index.html\n",
      "https://books.toscrape.com/catalogue/the-dirty-little-secrets-of-getting-your-dream-job_994/index.html\n",
      "https://books.toscrape.com/catalogue/the-coming-woman-a-novel-based-on-the-life-of-the-infamous-feminist-victoria-woodhull_993/index.html\n",
      "https://books.toscrape.com/catalogue/the-boys-in-the-boat-nine-americans-and-their-epic-quest-for-gold-at-the-1936-berlin-olympics_992/index.html\n",
      "https://books.toscrape.com/catalogue/the-black-maria_991/index.html\n",
      "https://books.toscrape.com/catalogue/starving-hearts-triangular-trade-trilogy-1_990/index.html\n",
      "https://books.toscrape.com/catalogue/shakespeares-sonnets_989/index.html\n",
      "https://books.toscrape.com/catalogue/set-me-free_988/index.html\n",
      "https://books.toscrape.com/catalogue/scott-pilgrims-precious-little-life-scott-pilgrim-1_987/index.html\n",
      "https://books.toscrape.com/catalogue/rip-it-up-and-start-again_986/index.html\n",
      "https://books.toscrape.com/catalogue/our-band-could-be-your-life-scenes-from-the-american-indie-underground-1981-1991_985/index.html\n",
      "https://books.toscrape.com/catalogue/olio_984/index.html\n",
      "https://books.toscrape.com/catalogue/mesaerion-the-best-science-fiction-stories-1800-1849_983/index.html\n",
      "https://books.toscrape.com/catalogue/libertarianism-for-beginners_982/index.html\n",
      "https://books.toscrape.com/catalogue/its-only-the-himalayas_981/index.html\n",
      "Scraping: https://books.toscrape.com/catalogue/page-10.html\n",
      "https://books.toscrape.com/catalogue/modern-romance_820/index.html\n",
      "https://books.toscrape.com/catalogue/miss-peregrines-home-for-peculiar-children-miss-peregrines-peculiar-children-1_819/index.html\n",
      "https://books.toscrape.com/catalogue/louisa-the-extraordinary-life-of-mrs-adams_818/index.html\n",
      "https://books.toscrape.com/catalogue/little-red_817/index.html\n",
      "https://books.toscrape.com/catalogue/library-of-souls-miss-peregrines-peculiar-children-3_816/index.html\n",
      "https://books.toscrape.com/catalogue/large-print-heart-of-the-pride_815/index.html\n",
      "https://books.toscrape.com/catalogue/i-had-a-nice-time-and-other-lies-how-to-find-love-sht-like-that_814/index.html\n",
      "https://books.toscrape.com/catalogue/hollow-city-miss-peregrines-peculiar-children-2_813/index.html\n",
      "https://books.toscrape.com/catalogue/grumbles_812/index.html\n",
      "https://books.toscrape.com/catalogue/full-moon-over-noahs-ark-an-odyssey-to-mount-ararat-and-beyond_811/index.html\n",
      "https://books.toscrape.com/catalogue/frostbite-vampire-academy-2_810/index.html\n",
      "https://books.toscrape.com/catalogue/follow-you-home_809/index.html\n",
      "https://books.toscrape.com/catalogue/first-steps-for-new-christians-print-edition_808/index.html\n",
      "https://books.toscrape.com/catalogue/finders-keepers-bill-hodges-trilogy-2_807/index.html\n",
      "https://books.toscrape.com/catalogue/fables-vol-1-legends-in-exile-fables-1_806/index.html\n",
      "https://books.toscrape.com/catalogue/eureka-trivia-60_805/index.html\n",
      "https://books.toscrape.com/catalogue/drive-the-surprising-truth-about-what-motivates-us_804/index.html\n",
      "https://books.toscrape.com/catalogue/done-rubbed-out-reightman-bailey-1_803/index.html\n",
      "https://books.toscrape.com/catalogue/doing-it-over-most-likely-to-1_802/index.html\n",
      "https://books.toscrape.com/catalogue/deliciously-ella-every-day-quick-and-easy-recipes-for-gluten-free-snacks-packed-lunches-and-simple-meals_801/index.html\n",
      "Scraping: https://books.toscrape.com/catalogue/page-200.html\n",
      "Scraping: https://books.toscrape.com/catalogue/page-20.html\n",
      "https://books.toscrape.com/catalogue/hide-away-eve-duncan-20_620/index.html\n",
      "https://books.toscrape.com/catalogue/furiously-happy-a-funny-book-about-horrible-things_619/index.html\n",
      "https://books.toscrape.com/catalogue/everyday-italian-125-simple-and-delicious-recipes_618/index.html\n",
      "https://books.toscrape.com/catalogue/equal-is-unfair-americas-misguided-fight-against-income-inequality_617/index.html\n",
      "https://books.toscrape.com/catalogue/eleanor-park_616/index.html\n",
      "https://books.toscrape.com/catalogue/dirty-dive-bar-1_615/index.html\n",
      "https://books.toscrape.com/catalogue/can-you-keep-a-secret-fear-street-relaunch-4_614/index.html\n",
      "https://books.toscrape.com/catalogue/boar-island-anna-pigeon-19_613/index.html\n",
      "https://books.toscrape.com/catalogue/a-paris-apartment_612/index.html\n",
      "https://books.toscrape.com/catalogue/a-la-mode-120-recipes-in-60-pairings-pies-tarts-cakes-crisps-and-more-topped-with-ice-cream-gelato-frozen-custard-and-more_611/index.html\n",
      "https://books.toscrape.com/catalogue/troublemaker-surviving-hollywood-and-scientology_610/index.html\n",
      "https://books.toscrape.com/catalogue/the-widow_609/index.html\n",
      "https://books.toscrape.com/catalogue/the-sleep-revolution-transforming-your-life-one-night-at-a-time_608/index.html\n",
      "https://books.toscrape.com/catalogue/the-improbability-of-love_607/index.html\n",
      "https://books.toscrape.com/catalogue/the-art-of-startup-fundraising_606/index.html\n",
      "https://books.toscrape.com/catalogue/take-me-home-tonight-rock-star-romance-3_605/index.html\n",
      "https://books.toscrape.com/catalogue/sleeping-giants-themis-files-1_604/index.html\n",
      "https://books.toscrape.com/catalogue/setting-the-world-on-fire-the-brief-astonishing-life-of-st-catherine-of-siena_603/index.html\n",
      "https://books.toscrape.com/catalogue/playing-with-fire_602/index.html\n",
      "https://books.toscrape.com/catalogue/off-the-hook-fishing-for-trouble-1_601/index.html\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Using yield for scraping\n",
    "\"\"\"\n",
    "# TODO: \n",
    "# 1. Update previous code by using yield\n",
    "\n",
    "def scrape_product_urls(urls):\n",
    "    \"\"\"\n",
    "    Generator function that yields product URLs from a list of pages.\n",
    "    \"\"\"\n",
    "    for url in urls:\n",
    "        print(f\"Scraping: {url}\")\n",
    "\n",
    "        # Get HTML response\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Find all product links\n",
    "        products = soup.find_all('article', class_='product_pod')\n",
    "        \n",
    "        # Yield each product URL\n",
    "        for product in products:\n",
    "            link = product.h3.a['href']\n",
    "            if not link.startswith('http'):\n",
    "                link = 'https://books.toscrape.com/catalogue/' + link\n",
    "            yield link\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    page_urls = [\n",
    "        \"https://books.toscrape.com/catalogue/page-1.html\",\n",
    "        \"https://books.toscrape.com/catalogue/page-10.html\",\n",
    "        \"https://books.toscrape.com/catalogue/page-200.html\",\n",
    "        \"https://books.toscrape.com/catalogue/page-20.html\"\n",
    "    ]\n",
    "    \n",
    "    # Create generator object\n",
    "    product_urls = scrape_product_urls(page_urls)\n",
    "\n",
    "    # Print URLs as they are generated\n",
    "    for url in product_urls:\n",
    "        print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping: https://books.toscrape.com/catalogue/page-1.html\n",
      "https://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html\n",
      "https://books.toscrape.com/catalogue/tipping-the-velvet_999/index.html\n",
      "https://books.toscrape.com/catalogue/soumission_998/index.html\n",
      "https://books.toscrape.com/catalogue/sharp-objects_997/index.html\n",
      "https://books.toscrape.com/catalogue/sapiens-a-brief-history-of-humankind_996/index.html\n",
      "https://books.toscrape.com/catalogue/the-requiem-red_995/index.html\n",
      "https://books.toscrape.com/catalogue/the-dirty-little-secrets-of-getting-your-dream-job_994/index.html\n",
      "https://books.toscrape.com/catalogue/the-coming-woman-a-novel-based-on-the-life-of-the-infamous-feminist-victoria-woodhull_993/index.html\n",
      "https://books.toscrape.com/catalogue/the-boys-in-the-boat-nine-americans-and-their-epic-quest-for-gold-at-the-1936-berlin-olympics_992/index.html\n",
      "https://books.toscrape.com/catalogue/the-black-maria_991/index.html\n",
      "https://books.toscrape.com/catalogue/starving-hearts-triangular-trade-trilogy-1_990/index.html\n",
      "https://books.toscrape.com/catalogue/shakespeares-sonnets_989/index.html\n",
      "https://books.toscrape.com/catalogue/set-me-free_988/index.html\n",
      "https://books.toscrape.com/catalogue/scott-pilgrims-precious-little-life-scott-pilgrim-1_987/index.html\n",
      "https://books.toscrape.com/catalogue/rip-it-up-and-start-again_986/index.html\n",
      "https://books.toscrape.com/catalogue/our-band-could-be-your-life-scenes-from-the-american-indie-underground-1981-1991_985/index.html\n",
      "https://books.toscrape.com/catalogue/olio_984/index.html\n",
      "https://books.toscrape.com/catalogue/mesaerion-the-best-science-fiction-stories-1800-1849_983/index.html\n",
      "https://books.toscrape.com/catalogue/libertarianism-for-beginners_982/index.html\n",
      "https://books.toscrape.com/catalogue/its-only-the-himalayas_981/index.html\n",
      "Scraping: https://books.toscrape.com/catalogue/page-10.html\n",
      "https://books.toscrape.com/catalogue/modern-romance_820/index.html\n",
      "https://books.toscrape.com/catalogue/miss-peregrines-home-for-peculiar-children-miss-peregrines-peculiar-children-1_819/index.html\n",
      "https://books.toscrape.com/catalogue/louisa-the-extraordinary-life-of-mrs-adams_818/index.html\n",
      "https://books.toscrape.com/catalogue/little-red_817/index.html\n",
      "https://books.toscrape.com/catalogue/library-of-souls-miss-peregrines-peculiar-children-3_816/index.html\n",
      "https://books.toscrape.com/catalogue/large-print-heart-of-the-pride_815/index.html\n",
      "https://books.toscrape.com/catalogue/i-had-a-nice-time-and-other-lies-how-to-find-love-sht-like-that_814/index.html\n",
      "https://books.toscrape.com/catalogue/hollow-city-miss-peregrines-peculiar-children-2_813/index.html\n",
      "https://books.toscrape.com/catalogue/grumbles_812/index.html\n",
      "https://books.toscrape.com/catalogue/full-moon-over-noahs-ark-an-odyssey-to-mount-ararat-and-beyond_811/index.html\n",
      "https://books.toscrape.com/catalogue/frostbite-vampire-academy-2_810/index.html\n",
      "https://books.toscrape.com/catalogue/follow-you-home_809/index.html\n",
      "https://books.toscrape.com/catalogue/first-steps-for-new-christians-print-edition_808/index.html\n",
      "https://books.toscrape.com/catalogue/finders-keepers-bill-hodges-trilogy-2_807/index.html\n",
      "https://books.toscrape.com/catalogue/fables-vol-1-legends-in-exile-fables-1_806/index.html\n",
      "https://books.toscrape.com/catalogue/eureka-trivia-60_805/index.html\n",
      "https://books.toscrape.com/catalogue/drive-the-surprising-truth-about-what-motivates-us_804/index.html\n",
      "https://books.toscrape.com/catalogue/done-rubbed-out-reightman-bailey-1_803/index.html\n",
      "https://books.toscrape.com/catalogue/doing-it-over-most-likely-to-1_802/index.html\n",
      "https://books.toscrape.com/catalogue/deliciously-ella-every-day-quick-and-easy-recipes-for-gluten-free-snacks-packed-lunches-and-simple-meals_801/index.html\n",
      "Scraping: https://books.toscrape.com/catalogue/page-200.html\n",
      "Scraping: https://books.toscrape.com/catalogue/page-20.html\n",
      "https://books.toscrape.com/catalogue/hide-away-eve-duncan-20_620/index.html\n",
      "https://books.toscrape.com/catalogue/furiously-happy-a-funny-book-about-horrible-things_619/index.html\n",
      "https://books.toscrape.com/catalogue/everyday-italian-125-simple-and-delicious-recipes_618/index.html\n",
      "https://books.toscrape.com/catalogue/equal-is-unfair-americas-misguided-fight-against-income-inequality_617/index.html\n",
      "https://books.toscrape.com/catalogue/eleanor-park_616/index.html\n",
      "https://books.toscrape.com/catalogue/dirty-dive-bar-1_615/index.html\n",
      "https://books.toscrape.com/catalogue/can-you-keep-a-secret-fear-street-relaunch-4_614/index.html\n",
      "https://books.toscrape.com/catalogue/boar-island-anna-pigeon-19_613/index.html\n",
      "https://books.toscrape.com/catalogue/a-paris-apartment_612/index.html\n",
      "https://books.toscrape.com/catalogue/a-la-mode-120-recipes-in-60-pairings-pies-tarts-cakes-crisps-and-more-topped-with-ice-cream-gelato-frozen-custard-and-more_611/index.html\n",
      "https://books.toscrape.com/catalogue/troublemaker-surviving-hollywood-and-scientology_610/index.html\n",
      "https://books.toscrape.com/catalogue/the-widow_609/index.html\n",
      "https://books.toscrape.com/catalogue/the-sleep-revolution-transforming-your-life-one-night-at-a-time_608/index.html\n",
      "https://books.toscrape.com/catalogue/the-improbability-of-love_607/index.html\n",
      "https://books.toscrape.com/catalogue/the-art-of-startup-fundraising_606/index.html\n",
      "https://books.toscrape.com/catalogue/take-me-home-tonight-rock-star-romance-3_605/index.html\n",
      "https://books.toscrape.com/catalogue/sleeping-giants-themis-files-1_604/index.html\n",
      "https://books.toscrape.com/catalogue/setting-the-world-on-fire-the-brief-astonishing-life-of-st-catherine-of-siena_603/index.html\n",
      "https://books.toscrape.com/catalogue/playing-with-fire_602/index.html\n",
      "https://books.toscrape.com/catalogue/off-the-hook-fishing-for-trouble-1_601/index.html\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Using yield for scraping\n",
    "\"\"\"\n",
    "# TODO:\n",
    "# 1. From your last assignment, update your code by using yield\n",
    "# 2. Create a new branch and push into github\n",
    "# 3. Put the URL here\n",
    "\n",
    "def scrape_product_urls(urls):\n",
    "    \"\"\"\n",
    "    Generator function that yields product URLs one at a time from a list of pages.\n",
    "    \"\"\"\n",
    "    for url in urls:\n",
    "        print(f\"Scraping: {url}\")\n",
    "        \n",
    "        # Get HTML response\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Find all product links and yield them one by one\n",
    "        products = soup.find_all('article', class_='product_pod')\n",
    "        for product in products:\n",
    "            link = product.h3.a['href']\n",
    "            if not link.startswith('http'):\n",
    "                link = 'https://books.toscrape.com/catalogue/' + link\n",
    "            yield link\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    page_urls = [\n",
    "        \"https://books.toscrape.com/catalogue/page-1.html\",\n",
    "        \"https://books.toscrape.com/catalogue/page-10.html\",\n",
    "        \"https://books.toscrape.com/catalogue/page-200.html\",\n",
    "        \"https://books.toscrape.com/catalogue/page-20.html\"\n",
    "    ]\n",
    "    \n",
    "    # Create generator object\n",
    "    for item in scrape_product_urls(page_urls):\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reflection**\n",
    "If you have a lot of memory, do you think you still need a generator? Give me your reason!\n",
    "\n",
    "(answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, generators are still valuable even with abundant memory for several important reasons:\n",
    "\n",
    "1. Code Readability and Design\n",
    "   \n",
    "   - Generators provide a cleaner, more intuitive way to work with sequences\n",
    "   - They make the code's intent clearer by explicitly showing the iteration pattern\n",
    "2. Processing Efficiency\n",
    "   \n",
    "   - Generators start processing immediately without waiting to load all data\n",
    "   - This reduces latency for the first results, especially important in web applications\n",
    "   - Better CPU utilization since you're processing one item at a time\n",
    "3. Resource Management\n",
    "   \n",
    "   - Even with lots of memory, efficient resource usage is good practice\n",
    "   - Servers often handle multiple concurrent processes/users\n",
    "   - Memory saved can be used for other operations or caching\n",
    "4. Scalability\n",
    "   \n",
    "   - Code written with generators scales better as data grows\n",
    "   - No need to rewrite code if data size increases beyond memory\n",
    "   - Future-proofs your applications\n",
    "5. Stream Processing\n",
    "   \n",
    "   - Generators are ideal for real-time data streams\n",
    "   - Perfect for processing live data feeds or continuous inputs\n",
    "   - Better suited for pipeline operations\n",
    "6. Error Handling\n",
    "   \n",
    "   - Easier to handle errors on individual items\n",
    "   - Doesn't lose all progress if one item fails\n",
    "   - Can continue processing remaining items\n",
    "Therefore, generators remain valuable for their design benefits and processing patterns, not just memory efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exploration**\n",
    "In Python, generators and iterators are both essential tools for working with sequences of data. However, we only covers the generators topic here. Explore about the iterators!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an exploration of Python iterators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding Iterators in Python\n",
    "\n",
    "# 1. Basic Iterator Example\n",
    "class NumberIterator:\n",
    "    def __init__(self, limit):\n",
    "        self.limit = limit\n",
    "        self.counter = 0\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.counter < self.limit:\n",
    "            self.counter += 1\n",
    "            return self.counter - 1\n",
    "        raise StopIteration\n",
    "\n",
    "# Using the iterator\n",
    "numbers = NumberIterator(5)\n",
    "for num in numbers:\n",
    "    print(num)  # Outputs: 0, 1, 2, 3, 4\n",
    "\n",
    "# 2. Custom String Iterator\n",
    "class ReverseString:\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        self.index = len(text)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.index > 0:\n",
    "            self.index -= 1\n",
    "            return self.text[self.index]\n",
    "        raise StopIteration\n",
    "\n",
    "# Using string iterator\n",
    "text = ReverseString(\"Hello\")\n",
    "for char in text:\n",
    "    print(char)  # Outputs: o, l, l, e, H\n",
    "\n",
    "# 3. Built-in Iterator Example\n",
    "my_list = [1, 2, 3]\n",
    "iterator = iter(my_list)\n",
    "print(next(iterator))  # 1\n",
    "print(next(iterator))  # 2\n",
    "print(next(iterator))  # 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key points about iterators:\n",
    "\n",
    "1. Protocol\n",
    "   \n",
    "   - Iterators must implement __iter__() and __next__()\n",
    "   - __iter__() returns the iterator object\n",
    "   - __next__() returns the next value or raises StopIteration\n",
    "2. Differences from Generators\n",
    "   \n",
    "   - Iterators are classes with explicit methods\n",
    "   - More complex to write than generators\n",
    "   - Offer more control over iteration behavior\n",
    "   - Can maintain more complex state\n",
    "3. Use Cases\n",
    "   \n",
    "   - Custom iteration patterns\n",
    "   - Complex object traversal\n",
    "   - Memory-efficient sequence processing\n",
    "   - Implementation of container objects\n",
    "4. Advantages\n",
    "   \n",
    "   - Fine-grained control over iteration\n",
    "   - Can implement complex iteration logic\n",
    "   - Reusable iteration behavior\n",
    "   - State preservation between iterations\n",
    "5. Common Applications\n",
    "   \n",
    "   - Custom collection types\n",
    "   - Database cursors\n",
    "   - File readers\n",
    "   - Network data streams"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
