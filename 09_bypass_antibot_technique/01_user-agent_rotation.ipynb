{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **What is a User-Agent?**\n",
    "\n",
    "The User-Agent (UA) is a string sent by a client (like a web browser or a bot) to identify itself to the server. It tells the server about the clientâ€™s operating system, browser, and device. For example, when you access a website via a browser like Chrome or Firefox, the browser sends a User-Agent string with each request to the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import httpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request {'Date': 'Thu, 10 Apr 2025 01:25:09 GMT', 'Content-Type': 'application/json', 'Content-Length': '305', 'Connection': 'keep-alive', 'Server': 'gunicorn/19.9.0', 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Credentials': 'true'}\n",
      "httpx Headers({'date': 'Thu, 10 Apr 2025 01:25:10 GMT', 'content-type': 'application/json', 'content-length': '302', 'connection': 'keep-alive', 'server': 'gunicorn/19.9.0', 'access-control-allow-origin': '*', 'access-control-allow-credentials': 'true'})\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Understanding Request Headers\n",
    "\"\"\"\n",
    "# TODO: Send request to https://httpbin.org/get using requests and httpx\n",
    "# TODO: Get the request headers from both responses\n",
    "# TODO: Compare the request headers and understand the difference\n",
    "\n",
    "req = requests.get('https://httpbin.org/get')\n",
    "r = httpx.get('https://httpbin.org/get')\n",
    "\n",
    "print(\"request\", req.headers)\n",
    "print(\"httpx\", r.headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36', 'Accept-Encoding': 'gzip, deflate, br', 'Accept': '*/*', 'Connection': 'keep-alive'}\n",
      "Original Headers:\n",
      "{'Date': 'Thu, 10 Apr 2025 01:25:21 GMT', 'Content-Type': 'application/json', 'Content-Length': '402', 'Connection': 'keep-alive', 'Server': 'gunicorn/19.9.0', 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Credentials': 'true'}\n",
      "\n",
      "Modified Headers:\n",
      "{'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36', 'Accept-Encoding': 'gzip, deflate, br', 'Accept': '*/*', 'Connection': 'keep-alive'}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Modify request headers\n",
    "\"\"\"\n",
    "# TODO: Send request to https://httpbin.org/get using requests\n",
    "# TODO: Get the request headers from the response\n",
    "\n",
    "r = requests.get('https://httpbin.org/get')\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Accept': '*/*',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Connection': 'keep-alive'\n",
    "}\n",
    "\n",
    "# TODO: Send new request using modified headers by passing headers params in get method\n",
    "# TODO: Get the request headers from the response\n",
    "# TODO: Compare the request headers and understand the difference\n",
    "# TODO: Experiment with different headers and share your thoughts\n",
    "\n",
    "# Send the request with modified headers\n",
    "r = requests.get('https://httpbin.org/get', headers=headers)\n",
    "\n",
    "# Get the request headers from the response\n",
    "print(r.request.headers)\n",
    "\n",
    "# Compare the request headers with the original headers\n",
    "original_headers = r.headers\n",
    "print(\"Original Headers:\")\n",
    "print(original_headers)\n",
    "print(\"\\nModified Headers:\")\n",
    "print(r.request.headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without custom header 400\n",
      "with custom headers 200\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Bypassing User-Agent Blocking\n",
    "\"\"\"\n",
    "# TODO: Send request to https://gamefaqs.gamespot.com/news using requests with and without custom headers\n",
    "# TODO: Compare the response, which one is blocked and which one is not\n",
    "r = requests.get('https://gamefaqs.gamespot.com/news')\n",
    "print(\"without custom header\",r.status_code)\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Accept': '*/*',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Connection': 'keep-alive'\n",
    "}\n",
    "\n",
    "rNew = requests.get('https://gamefaqs.gamespot.com/news', headers=headers)\n",
    "print(\"with custom headers\",rNew.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:92.0) Gecko/20100101 Firefox/92.0\n",
      "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\n",
      "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:50.0) Gecko/20100101 Firefox/50.0\n",
      "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36\n",
      "Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:92.0) Gecko/20100101 Firefox/92.0\n",
      "Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:92.0) Gecko/20100101 Firefox/92.0\n",
      "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\n",
      "Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:92.0) Gecko/20100101 Firefox/92.0\n",
      "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\n",
      "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Understanding User-Agent Rotation\n",
    "If all person you've met today using same shirts, what do you think?\n",
    "\"\"\"\n",
    "# List of common User-Agent strings\n",
    "user_agents = [\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:50.0) Gecko/20100101 Firefox/50.0',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:92.0) Gecko/20100101 Firefox/92.0'\n",
    "]\n",
    "\n",
    "# TODO: Send request to https://httpbin.org/get using random User-Agent from the list\n",
    "# TODO: Get the response and print the used User-Agent\n",
    "# TODO: Try to execute it again, is the User-Agent still the same?\n",
    "# TODO: Try to loop to send up to 10 request, using different User-Agent from the list and print each user agents used\n",
    "\n",
    "import random\n",
    "for i in range(10):\n",
    "    headers = {\n",
    "        'User-Agent': user_agents[random.randint(0, len(user_agents) - 1)]\n",
    "    }\n",
    "    r = requests.get('https://httpbin.org/get', headers=headers)\n",
    "    print(r.json()['headers']['User-Agent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mozilla/5.0 (iPhone; CPU iPhone OS 18_3_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.3 Mobile/15E148 Safari/604.1\n",
      "Mozilla/5.0 (iPhone; CPU iPhone OS 18_3_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.3 Mobile/15E148 Safari/604.1\n",
      "Mozilla/5.0 (X11; Linux x86_64; rv:125.0) Gecko/20100101 Firefox/125.0\n",
      "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.3 Safari/605.1.15\n",
      "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36\n",
      "Mozilla/5.0 (Linux; Android 10; K) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Mobile Safari/537.36\n",
      "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36\n",
      "Mozilla/5.0 (iPhone; CPU iPhone OS 18_3_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.3 Mobile/15E148 Safari/604.1\n",
      "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36\n",
      "Mozilla/5.0 (iPhone; CPU iPhone OS 18_3_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.3 Mobile/15E148 Safari/604.1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Using fake user-agent library\n",
    "\"\"\"\n",
    "# TODO: Install fake_useragent using pip\n",
    "# TODO: Create a UserAgent object\n",
    "# TODO: To get a random User-Agent, use ua.random\n",
    "# TODO: Send request to https://httpbin.org/get using random User-Agent from the fake_useragent\n",
    "# TODO: Get the response and print the used User-Agent\n",
    "# TODO: Try to execute it again, is the User-Agent still the same?\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "uAgent = UserAgent()\n",
    "\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    headers = {\n",
    "    'User-Agent': uAgent.random\n",
    "    }\n",
    "    r = requests.get('https://httpbin.org/get', headers=headers)\n",
    "    print(r.json()['headers']['User-Agent'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request succeeded with status code: 200\n",
      "Data saved to settlements.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Improve web scraping by using fake_useragent and logging\n",
    "\"\"\"\n",
    "# TODO: Visit https://www.cmegroup.com/markets/energy/crude-oil/light-sweet-crude.settlements.html\n",
    "# TODO: Try sending request to that site without custom header\n",
    "# TODO: If you failed, use random User-Agent using fake_useragent\n",
    "# TODO: Extract the data table and save it to a json file\n",
    "\n",
    "import logging\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "import pandas as pd\n",
    "from curl_cffi import requests\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "uAgent = UserAgent()\n",
    "timeout = 60  # Increased timeout to 60 seconds\n",
    "max_retries = 3  # Maximum number of retries\n",
    "url = 'https://www.cmegroup.com/CmeWS/mvc/Settlements/Futures/Settlements/425/FUT?strategy=DEFAULT&tradeDate=04/08/2025&pageSize=500&isProtected&_t=1744252567504'\n",
    "\n",
    "for attempt in range(max_retries):\n",
    "    try:\n",
    "        headers = { 'User-Agent': uAgent.random } # Random User-Agent from fake_useragent\n",
    "        r = requests.get(url, headers=headers, timeout=timeout, impersonate=\"chrome110\")  # Set timeout for the request\n",
    "        r.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "        break  # If the request is successful, break out of the loop\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "        if attempt < max_retries - 1:\n",
    "            time.sleep(10)  # Wait for 10 seconds before retrying\n",
    "        else:\n",
    "            logging.error(\"Max retries reached. Request failed.\")\n",
    "            exit()  # Exit the script if all retries fail\n",
    "\n",
    "if r.status_code == 200:\n",
    "    print(\"Request succeeded with status code:\", r.status_code)\n",
    "    data = r.json()\n",
    "    # Extract the data table from the response\n",
    "    df = pd.DataFrame(data['settlements'])\n",
    "    # Save the data to a JSON file\n",
    "    df.to_json('settlements.json', orient='records', lines=True)\n",
    "    print(\"Data saved to settlements.json\")\n",
    "\n",
    "    \n",
    "  \n",
    "else:\n",
    "    print(\"Request failed with status code:\", r.status_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Proxy Rotation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A proxy acts as an intermediary server between your scraping script (client) and the target website (server). When you send a request through a proxy, the request is routed through the proxy server, which then forwards the request to the destination website. The website sees the request coming from the proxyâ€™s IP address instead of your actual IP address. This makes proxies particularly useful in web scraping, as they help with anonymity, bypassing rate limits, and preventing IP bans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending request 1. Status code: 403\n",
      "Sending request 2. Status code: 403\n",
      "Sending request 3. Status code: 403\n",
      "Sending request 4. Status code: 403\n",
      "Sending request 5. Status code: 403\n",
      "Sending request 6. Status code: 403\n",
      "Sending request 7. Status code: 403\n",
      "Sending request 8. Status code: 403\n",
      "Sending request 9. Status code: 403\n",
      "Sending request 10. Status code: 403\n",
      "Sending request 11. Status code: 403\n",
      "Sending request 12. Status code: 403\n",
      "Sending request 13. Status code: 403\n",
      "Sending request 14. Status code: 403\n",
      "Sending request 15. Status code: 403\n",
      "Sending request 16. Status code: 403\n",
      "Sending request 17. Status code: 403\n",
      "Sending request 18. Status code: 403\n",
      "Sending request 19. Status code: 403\n",
      "Sending request 20. Status code: 403\n",
      "Sending request 21. Status code: 403\n",
      "Sending request 22. Status code: 403\n",
      "Sending request 23. Status code: 403\n",
      "Sending request 24. Status code: 403\n",
      "Sending request 25. Status code: 403\n",
      "Sending request 26. Status code: 403\n",
      "Sending request 27. Status code: 403\n",
      "Sending request 28. Status code: 403\n",
      "Sending request 29. Status code: 403\n",
      "Sending request 30. Status code: 403\n",
      "Sending request 31. Status code: 403\n",
      "Sending request 32. Status code: 403\n",
      "Sending request 33. Status code: 403\n",
      "Sending request 34. Status code: 403\n",
      "Sending request 35. Status code: 403\n",
      "Sending request 36. Status code: 403\n",
      "Sending request 37. Status code: 403\n",
      "Sending request 38. Status code: 403\n",
      "Sending request 39. Status code: 403\n",
      "Sending request 40. Status code: 403\n",
      "Sending request 41. Status code: 403\n",
      "Sending request 42. Status code: 403\n",
      "Sending request 43. Status code: 403\n",
      "Sending request 44. Status code: 403\n",
      "Sending request 45. Status code: 403\n",
      "Sending request 46. Status code: 403\n",
      "Sending request 47. Status code: 403\n",
      "Sending request 48. Status code: 403\n",
      "Sending request 49. Status code: 403\n",
      "Sending request 50. Status code: 403\n",
      "Sending request 51. Status code: 403\n",
      "Sending request 52. Status code: 403\n",
      "Sending request 53. Status code: 403\n",
      "Sending request 54. Status code: 403\n",
      "Sending request 55. Status code: 403\n",
      "Sending request 56. Status code: 403\n",
      "Sending request 57. Status code: 403\n",
      "Sending request 58. Status code: 403\n",
      "Sending request 59. Status code: 403\n",
      "Sending request 60. Status code: 403\n",
      "Sending request 61. Status code: 403\n",
      "Sending request 62. Status code: 403\n",
      "Sending request 63. Status code: 403\n",
      "Sending request 64. Status code: 403\n",
      "Sending request 65. Status code: 403\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Understanding rate limits\n",
    "\"\"\"\n",
    "# TODO: Execute this cell\n",
    "\n",
    "url = \"https://api.github.com/users/octocat\"\n",
    "\n",
    "for i in range(1, 66):\n",
    "    response = requests.get(url)\n",
    "    print(f\"Sending request {i}. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proxy 51.44.176.151:20202 works! Response: {\n",
      "  \"origin\": \"185.199.228.220\"\n",
      "}\n",
      "\n",
      "Proxy 3.104.88.178:80 works! Response: {\n",
      "  \"origin\": \"86.38.234.176\"\n",
      "}\n",
      "\n",
      "Proxy 43.159.152.105:13001 works! Response: {\n",
      "  \"origin\": \"173.211.0.148\"\n",
      "}\n",
      "\n",
      "Proxy 170.106.135.2:13001 works! Response: {\n",
      "  \"origin\": \"86.38.234.176\"\n",
      "}\n",
      "\n",
      "Proxy 32.223.6.94:80 works! Response: {\n",
      "  \"origin\": \"86.38.234.176\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Understanding Proxy\n",
    "\"\"\"\n",
    "import requests\n",
    "\n",
    "# Open the proxies.txt file\n",
    "with open('proxies.txt', 'r') as file:\n",
    "    proxy_list = file.readlines()  # Read all lines into a list\n",
    "\n",
    "# Iterate over proxies\n",
    "for proxy in proxy_list:\n",
    "    proxy = proxy.strip()  # Remove leading/trailing whitespace\n",
    "    \n",
    "    # If authentication is needed\n",
    "    if \"@\" in proxy:\n",
    "        proxies = {\n",
    "            \"http\": f\"http://{proxy}\",\n",
    "            \"https\": f\"https://{proxy}\"\n",
    "        }\n",
    "    else:\n",
    "        # If only IP:Port\n",
    "        proxies = {\n",
    "            \"http\": f\"http://{proxy}\",\n",
    "            \"https\": f\"https://{proxy}\"\n",
    "        }\n",
    "    \n",
    "\n",
    "    #USE .ENV FILE FOR SENSITIVE DATA\n",
    "    import os\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    HTTP = os.getenv(\"HTTP\")\n",
    "    HTTPS = os.getenv(\"HTTPS\")\n",
    "\n",
    "    # Make a request using webshare.io proxy\n",
    "    webshare_Proxy = {\n",
    "      \"http\":HTTP,\n",
    "      \"https\": HTTPS\n",
    "    } \n",
    "    try:\n",
    "        response = requests.get(\"https://httpbin.org/ip\", proxies=webshare_Proxy, timeout=30)\n",
    "        print(f\"Proxy {proxy} works! Response: {response.text}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Proxy {proxy} failed. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request succeeded with status code: 200\n",
      "Data saved to settlements.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Improve web scraping by using fake_useragent and logging\n",
    "\"\"\"\n",
    "# TODO: Visit https://www.cmegroup.com/markets/energy/crude-oil/light-sweet-crude.settlements.html\n",
    "# TODO: Try sending request to that site without custom header\n",
    "# TODO: If you failed, use random User-Agent using fake_useragent\n",
    "# TODO: Extract the data table and save it to a json file\n",
    "\n",
    "import logging\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "import pandas as pd\n",
    "from curl_cffi import requests\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "uAgent = UserAgent()\n",
    "timeout = 60  # Increased timeout to 60 seconds\n",
    "max_retries = 3  # Maximum number of retries\n",
    "url = 'https://www.cmegroup.com/CmeWS/mvc/Settlements/Futures/Settlements/425/FUT?strategy=DEFAULT&tradeDate=04/08/2025&pageSize=500&isProtected&_t=1744252567504'\n",
    "\n",
    "for attempt in range(max_retries):\n",
    "    try:\n",
    "        headers = { 'User-Agent': uAgent.random } # Random User-Agent from fake_useragent\n",
    "        r = requests.get(url, headers=headers, timeout=timeout, impersonate=\"chrome110\")  # Set timeout for the request\n",
    "        r.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "        break  # If the request is successful, break out of the loop\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "        if attempt < max_retries - 1:\n",
    "            time.sleep(10)  # Wait for 10 seconds before retrying\n",
    "        else:\n",
    "            logging.error(\"Max retries reached. Request failed.\")\n",
    "            exit()  # Exit the script if all retries fail\n",
    "\n",
    "if r.status_code == 200:\n",
    "    print(\"Request succeeded with status code:\", r.status_code)\n",
    "    data = r.json()\n",
    "    # Extract the data table from the response\n",
    "    df = pd.DataFrame(data['settlements'])\n",
    "    # Save the data to a JSON file\n",
    "    df.to_json('settlements.json', orient='records', lines=True)\n",
    "    print(\"Data saved to settlements.json\")\n",
    "\n",
    "    \n",
    "  \n",
    "else:\n",
    "    print(\"Request failed with status code:\", r.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Objective: Finding free proxies\n",
    "\"\"\"\n",
    "# TODO: Do a google search for free proxies and share your thoughts\n",
    "# i am usually using webshare.io for free proxy. you will get 10 free proxies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "809\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Using free proxies\n",
    "\"\"\"\n",
    "\n",
    "proxy_url = \"https://api.proxyscrape.com/v4/free-proxy-list/get?request=display_proxies&proxy_format=protocolipport&format=text\"\n",
    "\n",
    "proxy_list = requests.get(proxy_url).text # Get the proxy list\n",
    "proxy_list = proxy_list.strip().split('\\r\\n') # Split the proxy list\n",
    "proxy_list = [proxy for proxy in proxy_list if 'http' in proxy] # Filter http only\n",
    "print(len(proxy_list))\n",
    "\n",
    "url = \"https://api.github.com/users/octocat\"\n",
    "\n",
    "# TODO: Trigger blocking by sending 60 or more request to the URL\n",
    "\n",
    "# TODO: Once we hit the rate limit, we need to use a proxy\n",
    "# TODO: A free proxy may not always work, use looping to find a working proxy (response.status_code == 200)\n",
    "# TODO: Once the request is successful, print the proxy used and exit the loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending request 1. Status code: 200\n",
      "Sending request 2. Status code: 200\n",
      "Sending request 3. Status code: 200\n",
      "Sending request 4. Status code: 200\n",
      "Sending request 5. Status code: 200\n",
      "Sending request 6. Status code: 200\n",
      "Sending request 7. Status code: 200\n",
      "Sending request 8. Status code: 200\n",
      "Sending request 9. Status code: 200\n",
      "Sending request 10. Status code: 200\n",
      "Sending request 11. Status code: 200\n",
      "Sending request 12. Status code: 200\n",
      "Sending request 13. Status code: 200\n",
      "Sending request 14. Status code: 200\n",
      "Sending request 15. Status code: 200\n",
      "Sending request 16. Status code: 200\n",
      "Sending request 17. Status code: 200\n",
      "Sending request 18. Status code: 200\n",
      "Sending request 19. Status code: 200\n",
      "Sending request 20. Status code: 200\n",
      "Sending request 21. Status code: 200\n",
      "Sending request 22. Status code: 200\n",
      "Sending request 23. Status code: 200\n",
      "Sending request 24. Status code: 200\n",
      "Sending request 25. Status code: 200\n",
      "Sending request 26. Status code: 200\n",
      "Sending request 27. Status code: 200\n",
      "Sending request 28. Status code: 200\n",
      "Sending request 29. Status code: 200\n",
      "Sending request 30. Status code: 200\n",
      "Sending request 31. Status code: 200\n",
      "Sending request 32. Status code: 200\n",
      "Sending request 33. Status code: 200\n",
      "Sending request 34. Status code: 200\n",
      "Sending request 35. Status code: 200\n",
      "Sending request 36. Status code: 200\n",
      "Sending request 37. Status code: 200\n",
      "Sending request 38. Status code: 200\n",
      "Sending request 39. Status code: 200\n",
      "Sending request 40. Status code: 200\n",
      "Sending request 41. Status code: 200\n",
      "Sending request 42. Status code: 200\n",
      "Sending request 43. Status code: 200\n",
      "Sending request 44. Status code: 200\n",
      "Sending request 45. Status code: 200\n",
      "Sending request 46. Status code: 200\n",
      "Sending request 47. Status code: 200\n",
      "Sending request 48. Status code: 200\n",
      "Sending request 49. Status code: 200\n",
      "Sending request 50. Status code: 200\n",
      "Sending request 51. Status code: 200\n",
      "Sending request 52. Status code: 200\n",
      "Sending request 53. Status code: 200\n",
      "Sending request 54. Status code: 200\n",
      "Sending request 55. Status code: 200\n",
      "Sending request 56. Status code: 200\n",
      "Sending request 57. Status code: 200\n",
      "Sending request 58. Status code: 200\n",
      "Sending request 59. Status code: 200\n",
      "Sending request 60. Status code: 200\n",
      "Sending request 61. Status code: 403\n",
      "Sending request 62. Status code: 403\n",
      "Sending request 63. Status code: 403\n",
      "Sending request 64. Status code: 403\n",
      "Sending request 65. Status code: 403\n"
     ]
    }
   ],
   "source": [
    "url = \"https://api.github.com/users/octocat\"\n",
    "\n",
    "# TODO: Trigger blocking by sending 60 or more request to the URL\n",
    "for i in range(1, 66):\n",
    "    response = requests.get(url)\n",
    "    print(f\"Sending request {i}. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending request 1. Status code: 200\n",
      "Proxy http://15.235.53.20:28003 works! Response: {\"login\":\"octocat\",\"id\":583231,\"node_id\":\"MDQ6VXNlcjU4MzIzMQ==\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/583231?v=4\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/octocat\",\"html_url\":\"https://github.com/octocat\",\"followers_url\":\"https://api.github.com/users/octocat/followers\",\"following_url\":\"https://api.github.com/users/octocat/following{/other_user}\",\"gists_url\":\"https://api.github.com/users/octocat/gists{/gist_id}\",\"starred_url\":\"https://api.github.com/users/octocat/starred{/owner}{/repo}\",\"subscriptions_url\":\"https://api.github.com/users/octocat/subscriptions\",\"organizations_url\":\"https://api.github.com/users/octocat/orgs\",\"repos_url\":\"https://api.github.com/users/octocat/repos\",\"events_url\":\"https://api.github.com/users/octocat/events{/privacy}\",\"received_events_url\":\"https://api.github.com/users/octocat/received_events\",\"type\":\"User\",\"user_view_type\":\"public\",\"site_admin\":false,\"name\":\"The Octocat\",\"company\":\"@github\",\"blog\":\"https://github.blog\",\"location\":\"San Francisco\",\"email\":null,\"hireable\":null,\"bio\":null,\"twitter_username\":null,\"public_repos\":8,\"public_gists\":8,\"followers\":17567,\"following\":9,\"created_at\":\"2011-01-25T18:44:36Z\",\"updated_at\":\"2025-03-22T11:26:21Z\"}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Once we hit the rate limit, we need to use a proxy\n",
    "# TODO: A free proxy may not always work, use looping to find a working proxy (response.status_code == 200)\n",
    "# TODO: Once the request is successful, print the proxy used and exit the loop\n",
    "url = \"https://api.github.com/users/octocat\"\n",
    "for i in range(1, 66):\n",
    "    response = requests.get(url, proxies=webshare_Proxy)\n",
    "    print(f\"Sending request {i}. Status code: {response.status_code}\")\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Proxy {proxy} works! Response: {response.text}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reflection**\n",
    "What user-agent that typically get blocked? Can you mention it?\n",
    "\n",
    "1. Web Scraping Bots\n",
    "- Python-urllib/3.9\n",
    "- Scrapy/2.5\n",
    "- Java/1.8.0_181\n",
    "- curl/7.64.1\n",
    "- wget/1.20.3\n",
    "\n",
    "2. Malicious or Suspicious Bots\n",
    "- AhrefsBot\n",
    "- MJ12bot\n",
    "- SemrushBot\n",
    "- DotBot\n",
    "- BLEXBot\n",
    "\n",
    "3. Outdated Browsers\n",
    "- Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1)\n",
    "- Mozilla/5.0 (Windows NT 5.1; rv:1.9.2.3) Gecko/20100401 Firefox/3.6.3\n",
    "\n",
    "4. Generic or Empty User-Agents\n",
    "- Mozilla/5.0 (compatible; GenericBot/1.0)\n",
    "- - (empty user-agent string)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exploration**\n",
    "There are a lot of proxy providers out there. Do a research on at least 3 of them and compare it.\n",
    "\n",
    "https://medium.com/@rjrizani_66086/analysis-of-recommended-free-proxy-providers-for-web-scraping-776ff914ef6c    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
