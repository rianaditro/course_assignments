{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Export Data with Pandas**\n",
    "Pandas is a powerful and user-friendly Python library that is widely used for data manipulation and analysis. It helps you work with structured data (like spreadsheets or databases) efficiently and intuitively. For someone who isn’t a programmer, you can think of Pandas as a versatile tool for organizing and processing data—similar to using a digital spreadsheet (like Excel) but with the added capability of handling large datasets programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "Practice Exercise: Pandas Basics\n",
    "Library to install pandas, numpy, openpyxl.\n",
    "\n",
    "Complete each function below by following the TODO instructions. \n",
    "Each function includes the objective of the task and the expected output.\n",
    "\n",
    "Use Pandas official documentation for reference.\n",
    "https://pandas.pydata.org/docs/user_guide/index.html\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame:\n",
      "       name  age      city\n",
      "0  John Doe   25  New York\n",
      "1     Nadia   31    London\n",
      "2    Serena   23     Paris\n",
      "3     Tessa   17     Tokyo\n",
      "4       Una   23    Sydney\n",
      "\n",
      "DataFrame Type: <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Convert data list into a Pandas DataFrame\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "name = [\"John Doe\", \"Nadia\", \"Serena\", \"Tessa\", \"Una\"]\n",
    "age = [25, 31, 23, 17, 23]\n",
    "city = [\"New York\", \"London\", \"Paris\", \"Tokyo\", \"Sydney\"]\n",
    "\n",
    "# TODO: Pair the list into a dictionary\n",
    "# TODO: Create a dataframe from the dictionary\n",
    "# TODO: Validate the dataframe output and the object type\n",
    "\n",
    "# Create dictionary from lists\n",
    "data_dict = {\n",
    "    'name': name,\n",
    "    'age': age, \n",
    "    'city': city\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data_dict)\n",
    "\n",
    "# Validate output\n",
    "print(\"DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nDataFrame Type:\", type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame:\n",
      "       name  age      city\n",
      "0  John Doe   25  New York\n",
      "1     Nadia   31    London\n",
      "2    Serena   23     Paris\n",
      "3     Tessa   17     Tokyo\n",
      "4       Una   23    Sydney\n",
      "\n",
      "DataFrame Type: <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Convert data dictionaries into a Pandas DataFrame\n",
    "\"\"\"\n",
    "dict_1 = {\"name\": \"John Doe\", \"age\": 25, \"city\": \"New York\"}\n",
    "dict_2 = {\"name\": \"Nadia\", \"age\": 31, \"city\": \"London\"}\n",
    "dict_3 = {\"name\": \"Serena\", \"age\": 23, \"city\": \"Paris\"}\n",
    "dict_4 = {\"name\": \"Tessa\", \"age\": 17, \"city\": \"Tokyo\"}\n",
    "dict_5 = {\"name\": \"Una\", \"age\": 23, \"city\": \"Sydney\"}\n",
    "\n",
    "# TODO: Pair the dictionary into a list\n",
    "# TODO: Create a dataframe from the list\n",
    "# TODO: Validate the dataframe output and the object type\n",
    "\n",
    "dict_1 = {\"name\": \"John Doe\", \"age\": 25, \"city\": \"New York\"}\n",
    "dict_2 = {\"name\": \"Nadia\", \"age\": 31, \"city\": \"London\"}\n",
    "dict_3 = {\"name\": \"Serena\", \"age\": 23, \"city\": \"Paris\"}\n",
    "dict_4 = {\"name\": \"Tessa\", \"age\": 17, \"city\": \"Tokyo\"}\n",
    "dict_5 = {\"name\": \"Una\", \"age\": 23, \"city\": \"Sydney\"}\n",
    "\n",
    "# Create list of dictionaries\n",
    "data_list = [dict_1, dict_2, dict_3, dict_4, dict_5]\n",
    "\n",
    "# Create DataFrame from list of dictionaries\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Validate output\n",
    "print(\"DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nDataFrame Type:\", type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated DataFrame with new column:\n",
      "       name  age      city  is_married\n",
      "0  John Doe   25  New York        True\n",
      "1     Nadia   31    London       False\n",
      "2    Serena   23     Paris        True\n",
      "3     Tessa   17     Tokyo       False\n",
      "4       Una   23    Sydney       False\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Adding new columns to a Pandas DataFrame\n",
    "\"\"\"\n",
    "# TODO: Assign the new list into a dataframe column name that not exist yet\n",
    "# TODO: Validate the dataframe output\n",
    "\n",
    "# Create new column data\n",
    "is_married = [True, False, True, False, False]\n",
    "\n",
    "# Add new column to existing DataFrame\n",
    "df['is_married'] = is_married\n",
    "\n",
    "# Validate output\n",
    "print(\"Updated DataFrame with new column:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated DataFrame with new row:\n",
      "       name  age      city  is_married\n",
      "0  John Doe   25  New York        True\n",
      "1     Nadia   31    London       False\n",
      "2    Serena   23     Paris        True\n",
      "3     Tessa   17     Tokyo       False\n",
      "4       Una   23    Sydney       False\n",
      "5  Victoria   30  New York        True\n",
      "6  Victoria   30  New York        True\n",
      "7  Victoria   30  New York        True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Adding new rows to a Pandas DataFrame\n",
    "\"\"\"\n",
    "new_row = {\"name\": \"Victoria\", \"age\": 30, \"city\": \"New York\", \"is_married\": True}\n",
    "\n",
    "# TODO: Create a dataframe from the dictionary\n",
    "# TODO: Concatenate previous dataframe with new dataframe and ignore index\n",
    "# TODO: Validate the dataframe output\n",
    "\n",
    "import pandas as pd\n",
    "# Create DataFrame from the new row\n",
    "new_df = pd.DataFrame([new_row])\n",
    "\n",
    "# Concatenate with previous DataFrame and reset index\n",
    "df = pd.concat([df, new_df], ignore_index=True)\n",
    "\n",
    "# Validate output\n",
    "print(\"Updated DataFrame with new row:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with renamed columns:\n",
      "  full_name  years_old  location  marital_status\n",
      "0  John Doe         25  New York            True\n",
      "1     Nadia         31    London           False\n",
      "2    Serena         23     Paris            True\n",
      "3     Tessa         17     Tokyo           False\n",
      "4       Una         23    Sydney           False\n",
      "5  Victoria         30  New York            True\n",
      "6  Victoria         30  New York            True\n",
      "7  Victoria         30  New York            True\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Renaming columns\n",
    "\"\"\"\n",
    "# TODO: Create a dictionary of {old column: new column} in columns variable\n",
    "# TODO: Use .rename(columns=columns) and assign columns variable as parameter\n",
    "# TODO: Check the new renamed dataframe\n",
    "\n",
    "# Create dictionary for column renaming\n",
    "columns = {\n",
    "    'name': 'full_name',\n",
    "    'age': 'years_old',\n",
    "    'city': 'location',\n",
    "    'is_married': 'marital_status'\n",
    "}\n",
    "\n",
    "# Rename columns\n",
    "df = df.rename(columns=columns)\n",
    "\n",
    "# Check renamed DataFrame\n",
    "print(\"DataFrame with renamed columns:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Objective: Export as CSV\n",
    "\"\"\"\n",
    "# TODO: Use .to_csv(filename) to export as csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been exported to people_data.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Export as Excel without index\n",
    "\"\"\"\n",
    "# TODO: Use .to_excel(filename, index=False) to export as excel file without index\n",
    "# Export DataFrame to CSV\n",
    "df.to_csv('people_data.csv', index=False)\n",
    "print(\"Data has been exported to people_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reflection**\n",
    "Is there any difference in data represented as a csv or an excel using Pandas?\n",
    "\n",
    "(answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, there are several key differences between CSV and Excel files when using Pandas:\n",
    "\n",
    "1. File Format\n",
    "   \n",
    "   - CSV (Comma-Separated Values) is a simple text file format\n",
    "   - Excel (.xlsx) is a binary format that can contain multiple sheets and formatting\n",
    "2. Data Types\n",
    "   \n",
    "   - CSV stores everything as text, requiring type conversion when reading\n",
    "   - Excel preserves data types, formulas, and formatting\n",
    "3. Features\n",
    "   \n",
    "   - CSV:\n",
    "     - Simple and lightweight\n",
    "     - Universal compatibility\n",
    "     - Better for version control\n",
    "     - Faster to read/write for large datasets\n",
    "   - Excel:\n",
    "     - Supports multiple sheets\n",
    "     - Maintains formatting (colors, fonts, borders)\n",
    "     - Can store formulas\n",
    "     - Has cell merging and other advanced features\n",
    "4. Storage Size\n",
    "   \n",
    "   - CSV files are typically smaller\n",
    "   - Excel files are larger due to additional metadata and features\n",
    "5. Processing Speed\n",
    "   \n",
    "   - CSV files generally load faster in Pandas\n",
    "   - Excel files take longer to process due to additional features\n",
    "For simple data storage and transfer, CSV is often preferred. For complex data presentation with formatting and multiple sheets, Excel is more suitable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exploration**\n",
    "Pandas has .read_html() methods that dirrectly reading HTML content or even a URL. Can we replace the need of Requests+BeautifulSoup by just using pandas.read_html()?\n",
    "Try by scraping https://www.scrapingcourse.com/table-parsing using requests to get the HTML and pandas to extract the HTML content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a comparison of both approaches:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rudic\\AppData\\Local\\Temp\\ipykernel_18688\\1164815749.py:11: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(html_content)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tables found: 1\n",
      "\n",
      "First table using requests + pandas:\n",
      "    Product ID                 Name       Category    Price In Stock\n",
      "0            1               Laptop    Electronics  $999.99      Yes\n",
      "1            2           Smartphone    Electronics  $599.99      Yes\n",
      "2            3           Headphones          Audio  $149.99       No\n",
      "3            4         Coffee Maker     Appliances   $79.99      Yes\n",
      "4            5        Running Shoes         Sports   $89.99      Yes\n",
      "5            6          Smart Watch    Electronics  $249.99      Yes\n",
      "6            7              Blender     Appliances   $39.99       No\n",
      "7            8             Yoga Mat         Sports   $29.99      Yes\n",
      "8            9       Wireless Mouse    Electronics   $24.99      Yes\n",
      "9           10            Desk Lamp           Home   $34.99      Yes\n",
      "10          11     Portable Speaker          Audio   $79.99       No\n",
      "11          12  Electric Toothbrush  Personal Care   $49.99      Yes\n",
      "12          13             Backpack    Accessories   $59.99      Yes\n",
      "13          14         Air Purifier           Home  $129.99       No\n",
      "14          15       Gaming Console    Electronics  $399.99      Yes\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(tables[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Approach 2: Direct URL with pandas.read_html()\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m tables_direct \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_html(url)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFirst table using pandas directly:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(tables_direct[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\rudic\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:1240\u001b[0m, in \u001b[0;36mread_html\u001b[1;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend, storage_options)\u001b[0m\n\u001b[0;32m   1224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m   1225\u001b[0m     [\n\u001b[0;32m   1226\u001b[0m         is_file_like(io),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1230\u001b[0m     ]\n\u001b[0;32m   1231\u001b[0m ):\n\u001b[0;32m   1232\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing literal html to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread_html\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1234\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. To read from a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1237\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1238\u001b[0m     )\n\u001b[1;32m-> 1240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parse(\n\u001b[0;32m   1241\u001b[0m     flavor\u001b[38;5;241m=\u001b[39mflavor,\n\u001b[0;32m   1242\u001b[0m     io\u001b[38;5;241m=\u001b[39mio,\n\u001b[0;32m   1243\u001b[0m     match\u001b[38;5;241m=\u001b[39mmatch,\n\u001b[0;32m   1244\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   1245\u001b[0m     index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[0;32m   1246\u001b[0m     skiprows\u001b[38;5;241m=\u001b[39mskiprows,\n\u001b[0;32m   1247\u001b[0m     parse_dates\u001b[38;5;241m=\u001b[39mparse_dates,\n\u001b[0;32m   1248\u001b[0m     thousands\u001b[38;5;241m=\u001b[39mthousands,\n\u001b[0;32m   1249\u001b[0m     attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1250\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   1251\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   1252\u001b[0m     converters\u001b[38;5;241m=\u001b[39mconverters,\n\u001b[0;32m   1253\u001b[0m     na_values\u001b[38;5;241m=\u001b[39mna_values,\n\u001b[0;32m   1254\u001b[0m     keep_default_na\u001b[38;5;241m=\u001b[39mkeep_default_na,\n\u001b[0;32m   1255\u001b[0m     displayed_only\u001b[38;5;241m=\u001b[39mdisplayed_only,\n\u001b[0;32m   1256\u001b[0m     extract_links\u001b[38;5;241m=\u001b[39mextract_links,\n\u001b[0;32m   1257\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1258\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   1259\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\rudic\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:983\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m    972\u001b[0m p \u001b[38;5;241m=\u001b[39m parser(\n\u001b[0;32m    973\u001b[0m     io,\n\u001b[0;32m    974\u001b[0m     compiled_match,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    979\u001b[0m     storage_options,\n\u001b[0;32m    980\u001b[0m )\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 983\u001b[0m     tables \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mparse_tables()\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m caught:\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;66;03m# if `io` is an io-like object, check if it's seekable\u001b[39;00m\n\u001b[0;32m    986\u001b[0m     \u001b[38;5;66;03m# and try to rewind it before trying the next parser\u001b[39;00m\n\u001b[0;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(io, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseekable\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m io\u001b[38;5;241m.\u001b[39mseekable():\n",
      "File \u001b[1;32mc:\\Users\\rudic\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:249\u001b[0m, in \u001b[0;36m_HtmlFrameParser.parse_tables\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_tables\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    242\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;124;03m    Parse and return all tables from the DOM.\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;124;03m    list of parsed (header, body, footer) tuples from tables.\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 249\u001b[0m     tables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_tables(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_doc(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrs)\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_thead_tbody_tfoot(table) \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables)\n",
      "File \u001b[1;32mc:\\Users\\rudic\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:806\u001b[0m, in \u001b[0;36m_LxmlFrameParser._build_doc\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    804\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    805\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 806\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(r, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_content\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\rudic\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:785\u001b[0m, in \u001b[0;36m_LxmlFrameParser._build_doc\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    783\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_url(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mio):\n\u001b[1;32m--> 785\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    786\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mio, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options\n\u001b[0;32m    787\u001b[0m         ) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    788\u001b[0m             r \u001b[38;5;241m=\u001b[39m parse(f\u001b[38;5;241m.\u001b[39mhandle, parser\u001b[38;5;241m=\u001b[39mparser)\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# try to parse the input in the simplest way\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rudic\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:728\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    725\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[1;32m--> 728\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m _get_filepath_or_buffer(\n\u001b[0;32m    729\u001b[0m     path_or_buf,\n\u001b[0;32m    730\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m    731\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m    732\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m    733\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    734\u001b[0m )\n\u001b[0;32m    736\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[0;32m    737\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[1;32mc:\\Users\\rudic\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:384\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[0;32m    383\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[1;32m--> 384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urlopen(req_info) \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[0;32m    385\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    387\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rudic\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:289\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rudic\\anaconda3\\Lib\\urllib\\request.py:215\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[1;32mc:\\Users\\rudic\\anaconda3\\Lib\\urllib\\request.py:521\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    520\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 521\u001b[0m     response \u001b[38;5;241m=\u001b[39m meth(req, response)\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\rudic\\anaconda3\\Lib\\urllib\\request.py:630\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 630\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39merror(\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m'\u001b[39m, request, response, code, msg, hdrs)\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\rudic\\anaconda3\\Lib\\urllib\\request.py:559\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    558\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\rudic\\anaconda3\\Lib\\urllib\\request.py:492\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    491\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 492\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    494\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\rudic\\anaconda3\\Lib\\urllib\\request.py:639\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 639\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "# Approach 1: Using requests + pandas.read_html()\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Get HTML content using requests\n",
    "url = \"https://www.scrapingcourse.com/table-parsing\"\n",
    "response = requests.get(url)\n",
    "html_content = response.text\n",
    "\n",
    "# Parse tables using pandas\n",
    "tables = pd.read_html(html_content)\n",
    "print(\"Number of tables found:\", len(tables))\n",
    "print(\"\\nFirst table using requests + pandas:\")\n",
    "print(tables[0])\n",
    "\n",
    "# Approach 2: Direct URL with pandas.read_html()\n",
    "tables_direct = pd.read_html(url)\n",
    "print(\"\\nFirst table using pandas directly:\")\n",
    "print(tables_direct[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While pd.read_html() can work directly with URLs, using Requests+BeautifulSoup is still preferable for web scraping because:\n",
    "\n",
    "1. Flexibility\n",
    "   \n",
    "   - pd.read_html() only extracts HTML tables ( <table> elements)\n",
    "   - BeautifulSoup can extract any HTML element\n",
    "2. Control\n",
    "   \n",
    "   - Requests allows control over headers, cookies, sessions\n",
    "   - Can handle authentication, redirects, and timeouts\n",
    "3. Error Handling\n",
    "   \n",
    "   - Better error handling with Requests\n",
    "   - Can retry failed requests\n",
    "   - Can handle different status codes\n",
    "4. Pre-processing\n",
    "   \n",
    "   - Can modify HTML before parsing\n",
    "   - Can handle dynamic content\n",
    "   - Can clean data before parsing\n",
    "So while pd.read_html() is convenient for simple table extraction, Requests+BeautifulSoup offers more control and flexibility for complex web scraping tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
