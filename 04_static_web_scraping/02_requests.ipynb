{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Getting HTML Content**\n",
    "The Requests library is a popular Python tool that allows you to easily make HTTP requests. It is commonly used for web scraping, where you need to gather data from websites. Think of HTTP requests as asking a website to give you information, like a page of text or an image. With Requests, you can send these requests with just a few lines of code and receive responses that contain the information you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "\n",
    "\"\"\"\n",
    "Practice Exercise: Requests Basics\n",
    "\n",
    "Complete each function below by following the TODO instructions. \n",
    "Each function includes the objective of the task and the expected output.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can change the URL to any URL you like\n",
    "# Execute this cell before continue\n",
    "import requests\n",
    "\n",
    "example_url = \"https://example.com\"\n",
    "response = requests.get(example_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "200\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Understand the result of requests.get()\n",
    "\"\"\"\n",
    "# TODO: Print the response object and its type\n",
    "print(response)\n",
    "# TODO: Print the status code of the response\n",
    "print(response.status_code)\n",
    "# TODO: Print the reason phrase of the response\n",
    "print(response.reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!doctype html>\n",
      "<html>\n",
      "<head>\n",
      "    <title>Example Domain</title>\n",
      "\n",
      "    <meta charset=\"utf-8\" />\n",
      "    <m\n",
      "b'<!doctype html>\\n<html>\\n<head>\\n    <title>Example Domain</title>\\n\\n    <meta charset=\"utf-8\" />\\n    <m'\n",
      "1256\n",
      "1256\n",
      "<class 'str'>\n",
      "<class 'bytes'>\n",
      "<!doctype html>\n",
      "<html>\n",
      "<head>\n",
      "    <title>Example Domain</title>\n",
      "\n",
      "    <meta charset=\"utf-8\" />\n",
      "    <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\" />\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n",
      "    <style type=\"text/css\">\n",
      "    body {\n",
      "        background-color: #f0f0f2;\n",
      "        margin: 0;\n",
      "        padding: 0;\n",
      "        font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
      "        \n",
      "    }\n",
      "    div {\n",
      "        width: 600px;\n",
      "        margin: 5em auto;\n",
      "        padding: 2em;\n",
      "        background-color: #fdfdff;\n",
      "        border-radius: 0.5em;\n",
      "        box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\n",
      "    }\n",
      "    a:link, a:visited {\n",
      "        color: #38488f;\n",
      "        text-decoration: none;\n",
      "    }\n",
      "    @media (max-width: 700px) {\n",
      "        div {\n",
      "            margin: 0 auto;\n",
      "            width: auto;\n",
      "        }\n",
      "    }\n",
      "    </style>    \n",
      "</head>\n",
      "\n",
      "<body>\n",
      "<div>\n",
      "    <h1>Example Domain</h1>\n",
      "    <p>This domain is for use in illustrative examples in documents. You may use this\n",
      "    domain in literature without prior coordination or asking for permission.</p>\n",
      "    <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "b'<!doctype html>\\n<html>\\n<head>\\n    <title>Example Domain</title>\\n\\n    <meta charset=\"utf-8\" />\\n    <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\" />\\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\\n    <style type=\"text/css\">\\n    body {\\n        background-color: #f0f0f2;\\n        margin: 0;\\n        padding: 0;\\n        font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\\n        \\n    }\\n    div {\\n        width: 600px;\\n        margin: 5em auto;\\n        padding: 2em;\\n        background-color: #fdfdff;\\n        border-radius: 0.5em;\\n        box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\\n    }\\n    a:link, a:visited {\\n        color: #38488f;\\n        text-decoration: none;\\n    }\\n    @media (max-width: 700px) {\\n        div {\\n            margin: 0 auto;\\n            width: auto;\\n        }\\n    }\\n    </style>    \\n</head>\\n\\n<body>\\n<div>\\n    <h1>Example Domain</h1>\\n    <p>This domain is for use in illustrative examples in documents. You may use this\\n    domain in literature without prior coordination or asking for permission.</p>\\n    <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>\\n</div>\\n</body>\\n</html>\\n'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Compare the output of the response.text and response.content methods.\n",
    "\"\"\"\n",
    "# TODO: Print the first 100 characters of the response text\n",
    "print(response.text[:100])\n",
    "# TODO: Print the first 100 characters of the response content\n",
    "print(response.content[:100])\n",
    "# TODO: Print the length of the response text\n",
    "print(len(response.text))\n",
    "# TODO: Print the length of the response content\n",
    "print(len(response.content))    \n",
    "# TODO: Print the type of the response text\n",
    "print(type(response.text))\n",
    "# TODO: Print the type of the response content\n",
    "print(type(response.content))\n",
    "# TODO: Save the response text to a file\n",
    "print(response.text)\n",
    "# TODO: Save the response content to a file\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved successfully to images\\image.jpg\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Use .content to download an image file\n",
    "\"\"\"\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# image_url = \"https://via.placeholder.com/150\"\n",
    "image_url = \"https://i.etsystatic.com/19635104/r/il/887285/2591051093/il_570xN.2591051093_f2sk.jpg\"\n",
    "output_file = \"image.jpg\"\n",
    "subfolder = \"images\"\n",
    "\n",
    "# TODO: Use requests to download the image binary (image_url)    \n",
    "# You can change the image url to any image you like\n",
    "# TODO: Write the image binary to a file (output_file)\n",
    "# TODO: Locate the image file in a sub-folder\n",
    "# TODO: Print a message indicating the file has been saved\n",
    "os.makedirs(subfolder, exist_ok=True)\n",
    "response = requests.get(image_url)\n",
    "response.raise_for_status() # Check if download was successful\n",
    "\n",
    "output_path = os.path.join(subfolder, output_file)\n",
    "with open(output_path, 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "print(f\"Image saved successfully to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request 1: Status 200 - OK\n",
      "Request 2: Status 200 - OK\n",
      "Request 3: Status 200 - OK\n",
      "Request 4: Status 200 - OK\n",
      "Request 5: Status 200 - OK\n",
      "Request 6: Status 200 - OK\n",
      "Request 7: Status 200 - OK\n",
      "Request 8: Status 200 - OK\n",
      "Request 9: Status 200 - OK\n",
      "Request 10: Status 200 - OK\n",
      "Request 11: Status 200 - OK\n",
      "Request 12: Status 200 - OK\n",
      "Request 13: Status 200 - OK\n",
      "Request 14: Status 200 - OK\n",
      "Request 15: Status 200 - OK\n",
      "Request 16: Status 200 - OK\n",
      "Request 17: Status 200 - OK\n",
      "Request 18: Status 200 - OK\n",
      "Request 19: Status 200 - OK\n",
      "Request 20: Status 200 - OK\n",
      "Request 21: Status 200 - OK\n",
      "Request 22: Status 200 - OK\n",
      "Request 23: Status 200 - OK\n",
      "Request 24: Status 200 - OK\n",
      "Request 25: Status 200 - OK\n",
      "Request 26: Status 200 - OK\n",
      "Request 27: Status 200 - OK\n",
      "Request 28: Status 200 - OK\n",
      "Request 29: Status 200 - OK\n",
      "Request 30: Status 200 - OK\n",
      "Request 31: Status 200 - OK\n",
      "Request 32: Status 200 - OK\n",
      "Request 33: Status 200 - OK\n",
      "Request 34: Status 200 - OK\n",
      "Request 35: Status 200 - OK\n",
      "Request 36: Status 200 - OK\n",
      "Request 37: Status 200 - OK\n",
      "Request 38: Status 200 - OK\n",
      "Request 39: Status 200 - OK\n",
      "Request 40: Status 200 - OK\n",
      "Request 41: Status 200 - OK\n",
      "Request 42: Status 200 - OK\n",
      "Request 43: Status 200 - OK\n",
      "Request 44: Status 200 - OK\n",
      "Request 45: Status 200 - OK\n",
      "Request 46: Status 200 - OK\n",
      "Request 47: Status 200 - OK\n",
      "Request 48: Status 200 - OK\n",
      "Request 49: Status 200 - OK\n",
      "Request 50: Status 200 - OK\n",
      "Request 51: Status 200 - OK\n",
      "Request 52: Status 200 - OK\n",
      "Request 53: Status 200 - OK\n",
      "Request 54: Status 200 - OK\n",
      "Request 55: Status 200 - OK\n",
      "Request 56: Status 200 - OK\n",
      "Request 57: Status 200 - OK\n",
      "Request 58: Status 200 - OK\n",
      "Request 59: Status 200 - OK\n",
      "Request 60: Status 200 - OK\n",
      "Request 61: Status 200 - OK\n",
      "Request 62: Status 200 - OK\n",
      "Request 63: Status 200 - OK\n",
      "Request 64: Status 200 - OK\n",
      "Request 65: Status 200 - OK\n",
      "Request 66: Status 200 - OK\n",
      "Request 67: Status 200 - OK\n",
      "Request 68: Status 200 - OK\n",
      "Request 69: Status 200 - OK\n",
      "Request 70: Status 200 - OK\n",
      "Request 71: Status 200 - OK\n",
      "Request 72: Status 200 - OK\n",
      "Request 73: Status 200 - OK\n",
      "Request 74: Status 200 - OK\n",
      "Request 75: Status 200 - OK\n",
      "Request 76: Status 200 - OK\n",
      "Request 77: Status 200 - OK\n",
      "Request 78: Status 200 - OK\n",
      "Request 79: Status 200 - OK\n",
      "Request 80: Status 200 - OK\n",
      "Request 81: Status 200 - OK\n",
      "Request 82: Status 200 - OK\n",
      "Request 83: Status 200 - OK\n",
      "Request 84: Status 200 - OK\n",
      "Request 85: Status 200 - OK\n",
      "Request 86: Status 200 - OK\n",
      "Request 87: Status 200 - OK\n",
      "Request 88: Status 200 - OK\n",
      "Request 89: Status 200 - OK\n",
      "Request 90: Status 200 - OK\n",
      "Request 91: Status 200 - OK\n",
      "Request 92: Status 200 - OK\n",
      "Request 93: Status 200 - OK\n",
      "Request 94: Status 200 - OK\n",
      "Request 95: Status 200 - OK\n",
      "Request 96: Status 200 - OK\n",
      "Request 97: Status 200 - OK\n",
      "Request 98: Status 200 - OK\n",
      "Request 99: Status 200 - OK\n",
      "Request 100: Status 200 - OK\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Implement looping to see how the website response to over-requesting\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Define the URL to fetch data from, you can use example_url variable\n",
    "# TODO: Iterate over 100 times to fetch data from the URL\n",
    "# TODO: Print the status code and reason phrase of the response of each iteration\n",
    "url = \"https://i.etsystatic.com/19635104/r/il/887285/2591051093/il_570xN.2591051093_f2sk.jpg\"\n",
    "\n",
    "for i in range(100):\n",
    "    response = requests.get(url)\n",
    "    print(f\"Request {i+1}: Status {response.status_code} - {response.reason}\")\n",
    "new_url = \"https://api.github.com/users/octocat\"\n",
    "# TODO: Do the same as above but use the new_url variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: https://httpstat.us/400\n",
      "Status: 400 - Bad Request\n",
      "\n",
      "URL: https://httpstat.us/403\n",
      "Status: 403 - Forbidden\n",
      "\n",
      "URL: https://httpstat.us/404\n",
      "Status: 404 - Not Found\n",
      "\n",
      "URL: https://httpstat.us/500\n",
      "Status: 500 - Internal Server Error\n",
      "\n",
      "URL: https://httpstat.us/503\n",
      "Status: 503 - Service Unavailable\n",
      "\n",
      "URL: https://httpstat.us/504\n",
      "Status: 504 - Gateway Timeout\n",
      "\n",
      "URL: https://httpstat.us/521\n",
      "Status: 521 - Web Server Is Down\n",
      "\n",
      "URL: https://httpstat.us/522\n",
      "Status: 522 - Connection Timed out\n",
      "\n",
      "URL: https://httpstat.us/200\n",
      "Status: 200 - OK\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Understanding HTTP error codes\n",
    "\"\"\"\n",
    "urls = [\n",
    "    \"https://httpstat.us/400\", \"https://httpstat.us/403\", \"https://httpstat.us/404\",\n",
    "    \"https://httpstat.us/500\", \"https://httpstat.us/503\", \"https://httpstat.us/504\",\n",
    "    \"https://httpstat.us/521\", \"https://httpstat.us/522\", \"https://httpstat.us/200\"\n",
    "]\n",
    "\n",
    "# TODO: Loop through each URL in the list\n",
    "# TODO: Use requests to fetch the URL\n",
    "# TODO: Print the status code and its reason\n",
    "for url in urls:\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        print(f\"URL: {url}\")\n",
    "        print(f\"Status: {response.status_code} - {response.reason}\\n\")\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error accessing {url}: {e}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Making request with 5 second timeout...\n",
      "Request timed out after 5 seconds\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Objective: Implement timeout to limit waiting time for a response\n",
    "\"\"\"\n",
    "import os\n",
    "import requests\n",
    "\n",
    "adidas_url = \"https://www.adidas.de/api/products/ID9465\"\n",
    "\n",
    "# TODO: Use requests to fetch the adidas URL without timeout and see how long you can wait\n",
    "# TODO: Use requests to fetch the adidas URL with timeout equals to 5 seconds\n",
    "# TODO: Use try-except to handle the timeout error\n",
    "\n",
    "# Request without timeout\n",
    "print(\"Making request without timeout...\")\n",
    "try:\n",
    "    response = requests.get(adidas_url)\n",
    "    print(f\"Response received: {response.status_code}\")\n",
    "except requests.RequestException as e:\n",
    "    print(f\"Request failed: {e}\")\n",
    "\n",
    "# Request with 5 second timeout\n",
    "print(\"\\nMaking request with 5 second timeout...\")\n",
    "try:\n",
    "    response = requests.get(adidas_url, timeout=5)\n",
    "    print(f\"Response received: {response.status_code}\")\n",
    "except requests.Timeout:\n",
    "    print(\"Request timed out after 5 seconds\")\n",
    "except requests.RequestException as e:\n",
    "    print(f\"Request failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying URL: https://httpstat.us/200\n",
      "Success! Status: 200 - OK\n",
      "\n",
      "Trying URL: invalid_url.com\n",
      "Request Failed: HTTPConnectionPool(host='invalid_url.com', port=80): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPConnection object at 0x000001E5B257B200>: Failed to resolve 'invalid_url.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "\n",
      "Trying URL: https://httpstat.us/200\n",
      "Success! Status: 200 - OK\n",
      "\n",
      "Trying URL: https://www.adidas.de/api/products/ID9465\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Handle failed requests in the middle of a loop\n",
    "\"\"\"\n",
    "\n",
    "urls = [\n",
    "    \"https://httpstat.us/200\", \n",
    "    \"invalid_url.com\",\n",
    "    \"https://httpstat.us/200\", \n",
    "    \"https://www.adidas.de/api/products/ID9465\"\n",
    "]\n",
    "\n",
    "# TODO: Loop through each URL in the list\n",
    "# TODO: Use requests to fetch the URL\n",
    "# TODO: Handle HTTP error and print the error message\n",
    "# TODO: Handle all other exceptions (RequestException)\n",
    "\n",
    "urls = [\n",
    "    \"https://httpstat.us/200\", \n",
    "    \"invalid_url.com\",\n",
    "    \"https://httpstat.us/200\", \n",
    "    \"https://www.adidas.de/api/products/ID9465\"\n",
    "]\n",
    "\n",
    "for url in urls:\n",
    "    print(f\"\\nTrying URL: {url}\")\n",
    "    try:\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'http://' + url\n",
    "            \n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status() \n",
    "        print(f\"Success! Status: {response.status_code} - {response.reason}\")\n",
    "        \n",
    "    except requests.HTTPError as e:\n",
    "        print(f\"HTTP Error: {e}\")\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Request Failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response as text: {\"ip\":\"114.10.42.165\"}\n",
      "Response as parsed JSON: {'ip': '114.10.42.165'}\n",
      "\n",
      "Your IP address is: 114.10.42.165\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Get response in JSON format\n",
    "\"\"\"\n",
    "import requests\n",
    "\n",
    "api_url = \"https://api.ipify.org?format=json\"\n",
    "\n",
    "# TODO: Use requests to fetch your IP from the API (api_url)\n",
    "# TODO: Compare the response using both .text and .json()\n",
    "# TODO: Extract the IP address from the JSON response\n",
    "# TODO: Print your IP\n",
    "\n",
    "\n",
    "response = requests.get(api_url)\n",
    "response.raise_for_status()\n",
    "\n",
    "# Compare text vs json responses\n",
    "print(\"Response as text:\", response.text)\n",
    "print(\"Response as parsed JSON:\", response.json())\n",
    "\n",
    "# Extract and print IP\n",
    "ip_data = response.json()\n",
    "ip_address = ip_data['ip']\n",
    "print(f\"\\nYour IP address is: {ip_address}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data has been saved to posts.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Handling JSON output file\n",
    "\"\"\"\n",
    "import json\n",
    "api_url = \"https://jsonplaceholder.typicode.com/posts\"\n",
    "output_file = \"posts.json\"\n",
    "\n",
    "# TODO: Use requests.get() to fetch JSON data from the API (api_url)\n",
    "# TODO: Write the JSON response to a file (output_file)\n",
    "# TODO: Print a message indicating the file has been saved\n",
    "\n",
    "response = requests.get(api_url)\n",
    "response.raise_for_status()\n",
    "\n",
    "# Write JSON response to file\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(response.json(), f, indent=2)\n",
    "\n",
    "print(f\"JSON data has been saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server Response:\n",
      "{'args': {}, 'data': '{\"name\": \"Rudi Kurniawan\", \"age\": 40}', 'files': {}, 'form': {}, 'headers': {'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate, br, zstd', 'Content-Length': '37', 'Content-Type': 'application/json', 'Host': 'httpbin.org', 'User-Agent': 'python-requests/2.32.3', 'X-Amzn-Trace-Id': 'Root=1-67c77f39-498fea4c5bcacebf1c003850'}, 'json': {'age': 40, 'name': 'Rudi Kurniawan'}, 'origin': '114.10.42.165', 'url': 'https://httpbin.org/post'}\n",
      "\n",
      "Sent Payload:\n",
      "{'name': 'Rudi Kurniawan', 'age': 40}\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Send a POST request with payload data\n",
    "\"\"\"\n",
    "api_url = \"https://httpbin.org/post\"\n",
    "payload = {\"name\": \"Rudi Kurniawan\", \"age\": 40}\n",
    "\n",
    "# TODO: Replace name value with your name in the payload\n",
    "# TODO: Use requests.post() to send payload (payload) to the API (api_url)\n",
    "# TODO: Print the JSON response from the POST request and print back your payload data\n",
    "\n",
    "# Send POST request with payload\n",
    "response = requests.post(api_url, json=payload)\n",
    "response.raise_for_status()\n",
    "\n",
    "# Print response and payload data\n",
    "print(\"Server Response:\")\n",
    "print(response.json())\n",
    "print(\"\\nSent Payload:\")\n",
    "print(payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reflection**\n",
    "What is the difference between sending a HTTP request directly using Requests and using a browser?\n",
    "\n",
    "(answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the key differences between using Python Requests and a web browser for HTTP requests:\n",
    "\n",
    "1. Headers and User Agent\n",
    "   \n",
    "   - Browsers automatically send many headers (user-agent, accept-language, cookies, etc.)\n",
    "   - Requests sends minimal headers by default, requiring manual configuration for specific headers\n",
    "2. JavaScript Execution\n",
    "   \n",
    "   - Browsers execute JavaScript and render dynamic content\n",
    "   - Requests only receives raw HTML/data, cannot execute JavaScript\n",
    "3. Cookie Management\n",
    "   \n",
    "   - Browsers automatically manage cookies and maintain sessions\n",
    "   - Requests requires manual cookie handling using sessions or cookie jars\n",
    "4. Cache\n",
    "   \n",
    "   - Browsers maintain a cache of resources and follow cache headers\n",
    "   - Requests doesn't cache by default, each request fetches fresh data\n",
    "5. Security Features\n",
    "   \n",
    "   - Browsers handle HTTPS certificates, CORS, and other security features automatically\n",
    "   - Requests requires manual configuration for certificates and security features\n",
    "6. Resource Loading\n",
    "   \n",
    "   - Browsers automatically load related resources (images, CSS, scripts)\n",
    "   - Requests only fetches the specifically requested URL\n",
    "7. User Interface\n",
    "   \n",
    "   - Browsers provide visual feedback and rendering\n",
    "   - Requests is programmatic, requiring manual handling of responses\n",
    "These differences make browsers better for interactive web browsing, while Requests is better for automated data collection and API interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exploration**\n",
    "Now, you should be able to get HTML content using Requests and parse it using BeautifulSoup inside your program. Once your program is terminated, the data will lost. How to access the data after program is closed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways to persist the data after your program terminates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save raw HTML\n",
    "with open('webpage.html', 'w', encoding='utf-8') as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "# Save parsed content\n",
    "with open('parsed_content.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(soup.get_text())\n",
    "    \n",
    "import json\n",
    "\n",
    "# Save to json\n",
    "# Convert data to structured format\n",
    "data = {\n",
    "    'title': soup.title.text,\n",
    "    'paragraphs': [p.text for p in soup.find_all('p')]\n",
    "}\n",
    "\n",
    "# Save to JSON file\n",
    "with open('data.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, indent=2)\n",
    "    \n",
    "# Save to csv\n",
    "import csv\n",
    "\n",
    "with open('table_data.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for row in soup.find_all('tr'):\n",
    "        writer.writerow([cell.text for cell in row.find_all(['td', 'th'])])\n",
    "\n",
    "# Save to Database\n",
    "import sqlite3\n",
    "\n",
    "# Create/connect to database\n",
    "conn = sqlite3.connect('scraped_data.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create table and insert data\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS articles\n",
    "                 (title TEXT, content TEXT)''')\n",
    "cursor.execute('INSERT INTO articles VALUES (?, ?)',\n",
    "              (soup.title.text, soup.get_text()))\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each method has its advantages:\n",
    "\n",
    "- Text/HTML files: Simple, human-readable\n",
    "- JSON: Structured data, easy to parse\n",
    "- CSV: Good for tabular data\n",
    "- Database: Queryable, structured, good for large datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
