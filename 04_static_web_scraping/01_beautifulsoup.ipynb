{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Parsing HTML**\n",
    "\n",
    "BeautifulSoup is a Python library that simplifies the process of web scraping by allowing developers to extract data from HTML documents easily. It transforms complicated HTML documents into a tree of Python objects, such as tags, navigable strings, and comments. This makes it straightforward to locate and manipulate the desired data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPractice Exercise: BeautifulSoup Basics\\n\\nComplete each function below by following the TODO instructions. \\nEach function includes the objective of the task and the expected output.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs, Comment\n",
    "import json\n",
    "\n",
    "\"\"\"\n",
    "Practice Exercise: BeautifulSoup Basics\n",
    "\n",
    "Complete each function below by following the TODO instructions. \n",
    "Each function includes the objective of the task and the expected output.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of text before soup: <class 'str'>\n",
      "Type of text after soup: <class 'bs4.BeautifulSoup'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "<html>\n",
       "<body>\n",
       "<div>\n",
       "<p>Hello, world!</p>\n",
       "</div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_text_to_soup():\n",
    "    \"\"\"\n",
    "    Objective: Convert the provided text (HTML content) into a BeautifulSoup object.\n",
    "    Expected Output:\n",
    "    Type of text before soup: <class 'str'>\n",
    "    Type of text after soup: <class 'bs4.BeautifulSoup'>\n",
    "    \"\"\"\n",
    "    text = \"\"\"\n",
    "        <html>\n",
    "            <body>\n",
    "                <div>\n",
    "                    <p>Hello, world!</p>\n",
    "                </div>\n",
    "            </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "    # TODO: Use BeautifulSoup to convert text object type to soup object type\n",
    "    # TODO: Use print() to print the type of text before and after conversion\n",
    "    bs_obj = bs(text, 'html.parser')\n",
    "    print(f\"Type of text before soup: {type(text)}\")\n",
    "    print(f\"Type of text after soup: {type(bs_obj)}\")\n",
    "    return bs_obj\n",
    "\n",
    "convert_text_to_soup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of text before soup: <class 'str'>\n",
      "Type of text after soup: <class 'bs4.BeautifulSoup'>\n",
      "<html><body><div><p>Hello, world!</p></div></body></html>\n",
      "<html><body><div><p>Hello, world!</p></div></body></html>\n",
      "<html>\n",
      " <body>\n",
      "  <div>\n",
      "   <p>\n",
      "    Hello, world!\n",
      "   </p>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<html><body><div><p>Hello, world!</p></div></body></html>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def print_pretty():\n",
    "    \"\"\"\n",
    "    Objective: Compare the print output with and without BeautifulSoup.prettify() method.\n",
    "    Expected Output:\n",
    "    Type of text before soup: <class 'str'>\n",
    "    Type of text after soup: <class 'bs4.BeautifulSoup'>\n",
    "    \"\"\"\n",
    "    text = \"\"\"<html><body><div><p>Hello, world!</p></div></body></html>\"\"\"\n",
    "    # TODO: Use BeautifulSoup to convert text object type to soup object type\n",
    "    # TODO: Print text\n",
    "    # TODO: Print soup directly\n",
    "    # TODO: Print using prettify method\n",
    "    bs_obj = bs(text, 'html.parser')\n",
    "    print(f\"Type of text before soup: {type(text)}\")\n",
    "    print(f\"Type of text after soup: {type(bs_obj)}\")\n",
    "    print(text)\n",
    "    print(bs_obj)\n",
    "    print(bs_obj.prettify())\n",
    "    return bs_obj\n",
    "\n",
    "print_pretty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<body>\n",
      "<div>\n",
      "<p class=\"my-class\">Hello, my class!</p>\n",
      "<p id=\"my-id\">Hello, my id!</p>\n",
      "</div>\n",
      "</body>\n",
      "<div>\n",
      "<p class=\"my-class\">Hello, my class!</p>\n",
      "<p id=\"my-id\">Hello, my id!</p>\n",
      "</div>\n",
      "<p class=\"my-class\">Hello, my class!</p>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<p class=\"my-class\">Hello, my class!</p>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_going_down():\n",
    "    \"\"\"\n",
    "    Objective: Demonstrate how to traverse downward in the HTML structure using `.find()` method.\n",
    "    Expected Output:\n",
    "    The <body>, <div>, and <p> tags in sequence as they are traversed.\n",
    "    \"\"\"\n",
    "    html = \"\"\"\n",
    "        <html>\n",
    "            <body>\n",
    "                <div>\n",
    "                    <p class=\"my-class\">Hello, my class!</p>\n",
    "                    <p id=\"my-id\">Hello, my id!</p>\n",
    "                </div>\n",
    "            </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "    # TODO: Convert html to soup\n",
    "    # TODO: Navigate soup to get <body> and print it\n",
    "    # TODO: Navigate body to get <div> and print it\n",
    "    # TODO: Navigate div to get <p> and print it  \n",
    "    bs_obj = bs(html, 'html.parser') \n",
    "    body = bs_obj.find('body')\n",
    "    print(body)\n",
    "    div = body.find('div')\n",
    "    print(div)\n",
    "    p = div.find('p')\n",
    "    print(p)\n",
    "    return p\n",
    "\n",
    "find_going_down()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"my-class\">Hello, my class!</p>\n",
      "<p>Hello, my id!</p>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<p>Hello, my id!</p>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_next_to():\n",
    "    \"\"\"\n",
    "    Objective: Extract the text of the <p> element that comes immediately after a specific <p>.\n",
    "    Expected Output:\n",
    "    <p>Hello, my id!</p>\n",
    "    \"\"\"\n",
    "    html = \"\"\"\n",
    "        <html>\n",
    "            <body>\n",
    "                <div>\n",
    "                    <p class=\"my-class\">Hello, my class!</p>\n",
    "                    <p>Hello, my id!</p>\n",
    "                </div>\n",
    "            </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "    # TODO: Convert html to soup\n",
    "    # TODO: Use `.find()` to locate the <p> element with class=\"my-class\"\n",
    "    # TODO: Use `.find_next()` to locate the next <p> element\n",
    "    bs_obj = bs(html, 'html.parser')\n",
    "    p_class = bs_obj.find('p', class_='my-class')\n",
    "    print(p_class)\n",
    "    p_next = p_class.find_next()\n",
    "    print(p_next)\n",
    "    return p_next\n",
    "\n",
    "find_next_to()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"my-class\">Hello, my class!</p>\n",
      "<p id=\"my-id\">Hello, my id!</p>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<p class=\"my-class\">Hello, my class!</p>, <p id=\"my-id\">Hello, my id!</p>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def use_css_selectors():\n",
    "    \"\"\"\n",
    "    Objective: Locate elements using CSS selectors.\n",
    "    Expected Output:\n",
    "    <p class=\"my-class\">Hello, my class!</p>\n",
    "    <p id=\"my-id\">Hello, my id!</p>\n",
    "    \"\"\"\n",
    "    html = \"\"\"\n",
    "        <html>\n",
    "            <body>\n",
    "                <div>\n",
    "                    <p class=\"my-class\">Hello, my class!</p>\n",
    "                    <p id=\"my-id\">Hello, my id!</p>\n",
    "                </div>\n",
    "            </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "    # TODO: Convert html to soup\n",
    "    # TODO: Use `.select_one()` to locate elements using class, then print them.\n",
    "    # TODO: Use `.select_one()` to locate elements using ID selectors, then print them.\n",
    "    bs_obj = bs(html, 'html.parser')\n",
    "    p_class = bs_obj.select_one('.my-class')\n",
    "    print(p_class)\n",
    "    p_id = bs_obj.select_one('#my-id')\n",
    "    print(p_id)\n",
    "    return p_class, p_id\n",
    "\n",
    "use_css_selectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>Hello, world!</p>\n",
      "Hello, world!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello, world!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_text():\n",
    "    \"\"\"\n",
    "    Objective: Extract and print the text content of a <p> element.\n",
    "    Expected Output:\n",
    "    Hello, world!\n",
    "    \"\"\"\n",
    "    html = \"\"\"\n",
    "        <html>\n",
    "            <body>\n",
    "                <div>\n",
    "                    <p>Hello, world!</p>\n",
    "                </div>\n",
    "            </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "    # TODO: Convert html to soup\n",
    "    # TODO: Use `.find()` to locate the <p> element\n",
    "    # TODO: Extract text from the <p> element and print it\n",
    "    bs_obj = bs(html, 'html.parser')\n",
    "    p = bs_obj.find('p')\n",
    "    print(p)\n",
    "    text = p.get_text()\n",
    "    print(text)\n",
    "    return text\n",
    "\n",
    "extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"my-link\" href=\"https://www.google.com\" target=\"_blank\">Google</a>\n",
      "dict_keys(['class', 'href', 'target'])\n",
      "https://www.google.com\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'class': ['my-link'], 'href': 'https://www.google.com', 'target': '_blank'},\n",
       " 'https://www.google.com')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_attributes():\n",
    "    \"\"\"\n",
    "    Objective: Extract and print the text content of a <p> element.\n",
    "    Expected Output:\n",
    "    dict_keys(['href', 'class'])\n",
    "    https://www.google.com\n",
    "    \"\"\"\n",
    "    html = \"\"\"\n",
    "        <html>\n",
    "            <body>\n",
    "                <div>\n",
    "                    <a class=\"my-link\" href=\"https://www.google.com\" target=\"_blank\">Google</a>\n",
    "                </div>\n",
    "            </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "    # TODO: Convert html to soup\n",
    "    # TODO: Use `.find()` to locate the <a> element\n",
    "    # TODO: Print all available attributes from the <a> element\n",
    "    # TODO: Print the href attribute from the <a> element\n",
    "    bs_obj = bs(html, 'html.parser')\n",
    "    a = bs_obj.find('a')\n",
    "    print(a)\n",
    "    attributes = a.attrs\n",
    "    print(attributes.keys())\n",
    "    print(a['href'])\n",
    "    return attributes, a['href']\n",
    "\n",
    "extract_attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Item 1', 'Item 2', 'Item 3']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Item 1', 'Item 2', 'Item 3']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_text_from_list():\n",
    "    \"\"\"\n",
    "    Objective: Extract text from all <li> elements and return them as a list of strings.\n",
    "    Expected Output:\n",
    "    ['Item 1', 'Item 2', 'Item 3']\n",
    "    \"\"\"\n",
    "    html = \"\"\"\n",
    "        <ul>\n",
    "            <li>Item 1</li>\n",
    "            <li>Item 2</li>\n",
    "            <li>Item 3</li>\n",
    "        </ul>\n",
    "        \"\"\"\n",
    "    # TODO: Convert html to soup\n",
    "    # TODO: Use `.find_all()` to locate all <li> elements \n",
    "    # TODO: Iterate over the <li> elements and extract their text into a list.\n",
    "    # TODO: Print the list\n",
    "    bs_obj = bs(html, 'html.parser')\n",
    "    li_elements = bs_obj.find_all('li')\n",
    "    items = [li.get_text() for li in li_elements]\n",
    "    print(items)\n",
    "    return items\n",
    "\n",
    "extract_text_from_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'John Doe', 'age': '25'}, {'name': 'Nadia', 'age': '31'}, {'name': 'Serena', 'age': '23'}, {'name': 'Tessa', 'age': '17'}, {'name': 'Una', 'age': '23'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'John Doe', 'age': '25'},\n",
       " {'name': 'Nadia', 'age': '31'},\n",
       " {'name': 'Serena', 'age': '23'},\n",
       " {'name': 'Tessa', 'age': '17'},\n",
       " {'name': 'Una', 'age': '23'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_all_going_down():\n",
    "    \"\"\"\n",
    "    Objective: Extract text from all <p> elements and return them as a list of dictionaries.\n",
    "    Expected Output:\n",
    "    [{'name': 'John Doe', 'age': '25'}, {'name': 'Nadia', 'age': '31'}, {'name': 'Serena', 'age': '23'}, {'name': 'Tessa', 'age': '17'}, {'name': 'Una', 'age': '23'}]\n",
    "    \"\"\"\n",
    "    html = \"\"\"\n",
    "        <section>\n",
    "            <div class=\"user-info\">\n",
    "                <p class=\"my-name\">John Doe</p>\n",
    "                <p class=\"my-age\">25</p>\n",
    "            </div>\n",
    "            <div class=\"user-info\">\n",
    "                <p class=\"my-name\">Nadia</p>\n",
    "                <p class=\"my-age\">31</p>\n",
    "            </div>\n",
    "            <div class=\"user-info\">\n",
    "                <p class=\"my-name\">Serena</p>\n",
    "                <p class=\"my-age\">23</p>\n",
    "            </div>\n",
    "            <div class=\"user-info\">\n",
    "                <p class=\"my-name\">Tessa</p>\n",
    "                <p class=\"my-age\">17</p>\n",
    "            </div>\n",
    "            <div class=\"user-info\">\n",
    "                <p class=\"my-name\">Una</p>\n",
    "                <p class=\"my-age\">23</p>\n",
    "            </div>\n",
    "        </section>\"\"\"\n",
    "    # TODO: Convert html to soup\n",
    "    # TODO: Use `.find_all()` to locate all <p> elements\n",
    "    # TODO: Iterate over the <p> elements and extract their text into a list of dictionaries\n",
    "    # TODO: Print the list of dictionaries\n",
    "    bs_obj = bs(html, 'html.parser')\n",
    "    p_elements = bs_obj.find_all('p')\n",
    "    user_info = []\n",
    "    for i in range(0, len(p_elements), 2):\n",
    "        user = {\n",
    "            'name': p_elements[i].get_text(),\n",
    "            'age': p_elements[i + 1].get_text()\n",
    "        }\n",
    "        user_info.append(user)\n",
    "    print(user_info)\n",
    "    return user_info\n",
    "\n",
    "find_all_going_down()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Alice', 'age': '30'}, {'name': 'Bob', 'age': '25'}]\n",
      "[{'name': 'Alice', 'age': '30'}, {'name': 'Bob', 'age': '25'}]\n"
     ]
    }
   ],
   "source": [
    "def extract_tables():\n",
    "    \"\"\"\n",
    "    Objective: Extract data from an HTML table and return it as a list of dictionaries.\n",
    "    Expected Output:\n",
    "    [{'name': 'Alice', 'age': '30'}, {'name': 'Bob', 'age': '25'}]\n",
    "    \"\"\"\n",
    "    html = \"\"\"\n",
    "    <table>\n",
    "        <thead>\n",
    "            <tr>\n",
    "                <th>Name</th>\n",
    "                <th>Age</th>\n",
    "            </tr>\n",
    "        </thead>\n",
    "        <tbody>\n",
    "            <tr>\n",
    "                <td>Alice</td>\n",
    "                <td>30</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>Bob</td>\n",
    "                <td>25</td>\n",
    "            </tr>\n",
    "        </tbody>\n",
    "    </table>\n",
    "    \"\"\"\n",
    "    # TODO: Convert html to soup\n",
    "    # TODO: Extract <tr> elements from <tbody>\n",
    "    # TODO: Iterate over the <td> elements, to construct dictionaries for each row.\n",
    "    # TODO: Append each dictionary to a list\n",
    "    # TODO: Print the list\n",
    "    bs_obj = bs(html, 'html.parser')\n",
    "    rows = bs_obj.find('tbody').find_all('tr')\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        data.append({\n",
    "            'name': cols[0].get_text(),\n",
    "            'age': cols[1].get_text()\n",
    "        })\n",
    "    print(data)\n",
    "    # return data\n",
    "    \n",
    "    # Challenges: Can you extract it directly from the <tr> elements?\n",
    "    all_rows = bs_obj.select('tbody tr')\n",
    "    data_direct = []\n",
    "    for row in all_rows:\n",
    "        tds = row.find_all('td')\n",
    "        data_direct.append({\n",
    "            'name': tds[0].get_text(),\n",
    "            'age': tds[1].get_text()\n",
    "        })\n",
    "    print(data_direct)   \n",
    "\n",
    "extract_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 123, 'name': 'Alice'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 123, 'name': 'Alice'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_scripts():\n",
    "    \"\"\"\n",
    "    Objective: Extract JSON-like data embedded in a <script> tag and return it as a Python dictionary.\n",
    "    Expected Output:\n",
    "    {\"id\": 123, \"name\": \"Alice\"}\n",
    "    \"\"\"\n",
    "    html = \"\"\"\n",
    "        <script>\n",
    "            var userInfo = { \"id\": 123, \"name\": \"Alice\" };\n",
    "        </script>\n",
    "        \"\"\"\n",
    "\n",
    "    # TODO: Convert html to soup\n",
    "    # TODO: Extract the JSON-like content from the <script> tag\n",
    "    # TODO: Remove the \"var userInfo = \" and \";\" from the JSON-like content\n",
    "    # TODO: Convert the JSON-like content to a Python dictionary\n",
    "    # TODO: Print the dictionary\n",
    "    bs_obj = bs(html, 'html.parser')\n",
    "    script = bs_obj.find('script').string\n",
    "    json_data = script.replace('var userInfo = ', '').replace(';', '')\n",
    "    data_dict = json.loads(json_data)\n",
    "    print(data_dict)\n",
    "    return data_dict\n",
    "\n",
    "extract_scripts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " User ID: 67890 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' User ID: 67890 '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_comments():\n",
    "    \"\"\"\n",
    "    Objective: Extract a comment from the HTML and return it as a string.\n",
    "    Expected Output:\n",
    "    ' User ID: 67890 '\n",
    "    \"\"\"\n",
    "    html = \"\"\"\n",
    "        <!-- User ID: 67890 -->\n",
    "        <div class=\"user-info\">Name: John Doe</div>\n",
    "        \"\"\"\n",
    "\n",
    "    # TODO: Convert html to soup\n",
    "    # TODO: Use BeautifulSoup to locate and extract the comment.\n",
    "    # TODO: Print the comment\n",
    "    bs_obj = bs(html, 'html.parser')\n",
    "    #tidak ada informasi komentar di dalam tag html diatas. apakah yang dimaksud seperti ini?\n",
    "    comment = bs_obj.find(string=lambda text: isinstance(text, Comment))\n",
    "    print(comment)\n",
    "    return comment\n",
    "\n",
    "extract_comments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Item 1', 'Item 2', 'Item 3']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Item 1', 'Item 2', 'Item 3']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_dynamic_classes():\n",
    "    \"\"\"\n",
    "    Objective: Extract text content from all <div> elements with class names starting with 'content-'.\n",
    "    Expected Output:\n",
    "    ['Item 1', 'Item 2', 'Item 3']\n",
    "    \"\"\"\n",
    "    html = \"\"\"\n",
    "        <div class=\"content-1\">Item 1</div>\n",
    "        <div class=\"content-2\">Item 2</div>\n",
    "        <div class=\"content-3\">Item 3</div>\n",
    "        \"\"\"\n",
    "    \n",
    "    # TODO: Convert html to soup\n",
    "    # TODO: Use `.find_all()` with a custom filter to locate the elements\n",
    "    # TODO: Iterate over the elements and extract text from the specified <div> elements.\n",
    "    # TODO: Print the list\n",
    "    bs_obj = bs(html, 'html.parser')\n",
    "    div_elements = bs_obj.find_all('div', class_=lambda x: x and x.startswith('content-'))\n",
    "    items = [div.get_text() for div in div_elements]\n",
    "    print(items)\n",
    "    return items\n",
    "\n",
    "extract_dynamic_classes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reflection**\n",
    "Which one method in BeautifulSoup you prefer? .find() or .select_one() ?\n",
    "\n",
    "(answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER HERE\n",
    "\n",
    "tergantung kebutuhan, tapi jika memang memilih dan tidak ada faktor2x lain saya lebih prefer .find karna bisa langsung mengambil yang pertama dan lebih ringkas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exploration**\n",
    "Automate the process of getting HTML content by using Requests library. Read the official documentations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
