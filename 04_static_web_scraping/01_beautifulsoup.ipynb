{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Parsing HTML**\n",
    "\n",
    "BeautifulSoup is a Python library that simplifies the process of web scraping by allowing developers to extract data from HTML documents easily. It transforms complicated HTML documents into a tree of Python objects, such as tags, navigable strings, and comments. This makes it straightforward to locate and manipulate the desired data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPractice Exercise: BeautifulSoup Basics\\n\\nComplete each function below by following the TODO instructions. \\nEach function includes the objective of the task and the expected output.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs, Comment\n",
    "import json\n",
    "\n",
    "\"\"\"\n",
    "Practice Exercise: BeautifulSoup Basics\n",
    "\n",
    "Complete each function below by following the TODO instructions. \n",
    "Each function includes the objective of the task and the expected output.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of text before soup: <class 'str'>\n",
      "Type of text after soup: <class 'bs4.BeautifulSoup'>\n"
     ]
    }
   ],
   "source": [
    "def convert_text_to_soup():\n",
    "    \"\"\"\n",
    "    Objective: Convert the provided text (HTML content) into a BeautifulSoup object.\n",
    "    Expected Output:\n",
    "    Type of text before soup: <class 'str'>\n",
    "    Type of text after soup: <class 'bs4.BeautifulSoup'>\n",
    "    \"\"\"\n",
    "    text = \"\"\"\n",
    "        <html>\n",
    "            <body>\n",
    "                <div>\n",
    "                    <p>Hello, world!</p>\n",
    "                </div>\n",
    "            </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "    # TODO: Use BeautifulSoup to convert text object type to soup object type\n",
    "\n",
    "    print(f\"Type of text before soup: {type(text)}\")\n",
    "    \n",
    "    text = bs(text, \"html.parser\")\n",
    "\n",
    "    print(f\"Type of text after soup: {type(text)}\")\n",
    "\n",
    "    # TODO: Use print() to print the type of text before and after conversion\n",
    "\n",
    "\n",
    "    print(f\"Type of text before soup: {type(text)}\")\n",
    "    \n",
    "    text = bs(text, \"html.parser\")\n",
    "\n",
    "    print(f\"Type of text after soup: {type(text)}\")\n",
    "    \n",
    "convert_text_to_soup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html><body><div><p>Hello, world!</p></div></body></html>\n",
      "<class 'bs4.BeautifulSoup'>\n",
      "<html>\n",
      " <body>\n",
      "  <div>\n",
      "   <p>\n",
      "    Hello, world!\n",
      "   </p>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_pretty():\n",
    "    \"\"\"\n",
    "    Objective: Compare the print output with and without BeautifulSoup.prettify() method.\n",
    "    Expected Output:\n",
    "    Type of text before soup: <class 'str'>\n",
    "    Type of text after soup: <class 'bs4.BeautifulSoup'>\n",
    "    \"\"\"\n",
    "    text = \"\"\"<html><body><div><p>Hello, world!</p></div></body></html>\"\"\"\n",
    "    # TODO: Use BeautifulSoup to convert text object type to soup object type\n",
    "    text = bs(text, \"html.parser\")\n",
    "\n",
    "    # TODO: Print text\n",
    "    print(text)\n",
    "\n",
    "    # TODO: Print soup directly\n",
    "    print(bs)\n",
    "\n",
    "    # TODO: Print using prettify method\n",
    "    print(text.prettify())\n",
    "\n",
    "\n",
    "print_pretty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<body>\n",
      "<div>\n",
      "<p class=\"my-class\">Hello, my class!</p>\n",
      "<p id=\"my-id\">Hello, my id!</p>\n",
      "</div>\n",
      "</body>\n",
      "<div>\n",
      "<p class=\"my-class\">Hello, my class!</p>\n",
      "<p id=\"my-id\">Hello, my id!</p>\n",
      "</div>\n",
      "<p class=\"my-class\">Hello, my class!</p>\n"
     ]
    }
   ],
   "source": [
    "def find_going_down():\n",
    "    \"\"\"\n",
    "    Objective: Demonstrate how to traverse downward in the HTML structure using `.find()` method.\n",
    "    Expected Output:\n",
    "    The <body>, <div>, and <p> tags in sequence as they are traversed.\n",
    "    \"\"\"\n",
    "    html = \"\"\"\n",
    "        <html>\n",
    "            <body>\n",
    "                <div>\n",
    "                    <p class=\"my-class\">Hello, my class!</p>\n",
    "                    <p id=\"my-id\">Hello, my id!</p>\n",
    "                </div>\n",
    "            </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "    # TODO: Convert html to soup\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    # TODO: Navigate soup to get <body> and print it\n",
    "    body_tag = soup.body\n",
    "\n",
    "    print(body_tag)\n",
    "    # print(body_tag.prettify())\n",
    "\n",
    "    # TODO: Navigate body to get <div> and print it\n",
    "    div_tag = soup.body.div\n",
    "\n",
    "    print(div_tag)\n",
    "    # print(div_tag.prettify())\n",
    "\n",
    "    # TODO: Navigate div to get <p> and print it   \n",
    "    p_tag = soup.body.div.p\n",
    "\n",
    "    print(p_tag)\n",
    "    # print(p_tag.prettify())\n",
    "\n",
    "find_going_down()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"my-class\">Hello, my class!</p>\n",
      "<p>Hello, my id!</p>\n"
     ]
    }
   ],
   "source": [
    "def find_next_to():\n",
    "    \"\"\"\n",
    "    Objective: Extract the text of the <p> element that comes immediately after a specific <p>.\n",
    "    Expected Output:\n",
    "    <p>Hello, my id!</p>\n",
    "    \"\"\"\n",
    "    html = \"\"\"\n",
    "        <html>\n",
    "            <body>\n",
    "                <div>\n",
    "                    <p class=\"my-class\">Hello, my class!</p>\n",
    "                    <p>Hello, my id!</p>\n",
    "                </div>\n",
    "            </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "    # TODO: Convert html to soup\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    # TODO: Use `.find()` to locate the <p> element with class=\"my-class\"\n",
    "    p_my_class = soup.find(\"p\", { \"class\": \"my-class\"})\n",
    "    print(p_my_class)\n",
    "\n",
    "    # TODO: Use `.find_next()` to locate the next <p> element\n",
    "    next_p = p_my_class.find_next(\"p\")\n",
    "    print(next_p)\n",
    "\n",
    "find_next_to()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"my-class\">Hello, my class!</p>\n",
      "<p id=\"my-id\">Hello, my id!</p>\n"
     ]
    }
   ],
   "source": [
    "def use_css_selectors():\n",
    "    \"\"\"\n",
    "    Objective: Locate elements using CSS selectors.\n",
    "    Expected Output:\n",
    "    <p class=\"my-class\">Hello, my class!</p>\n",
    "    <p id=\"my-id\">Hello, my id!</p>\n",
    "    \"\"\"\n",
    "    html = \"\"\"\n",
    "        <html>\n",
    "            <body>\n",
    "                <div>\n",
    "                    <p class=\"my-class\">Hello, my class!</p>\n",
    "                    <p id=\"my-id\">Hello, my id!</p>\n",
    "                </div>\n",
    "            </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "    # TODO: Convert html to soup\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    # TODO: Use `.select_one()` to locate elements using class, then print them.\n",
    "    p_my_class = soup.select_one(\".my-class\")\n",
    "    print(p_my_class)\n",
    "\n",
    "    # TODO: Use `.select_one()` to locate elements using ID selectors, then print them.\n",
    "    p_my_id = soup.select_one(\"#my-id\")\n",
    "    print(p_my_id)\n",
    "\n",
    "use_css_selectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, world!\n"
     ]
    }
   ],
   "source": [
    "def extract_text():\n",
    "    \"\"\"\n",
    "    Objective: Extract and print the text content of a <p> element.\n",
    "    Expected Output:\n",
    "    Hello, world!\n",
    "    \"\"\"\n",
    "    html = \"\"\"\n",
    "        <html>\n",
    "            <body>\n",
    "                <div>\n",
    "                    <p>Hello, world!</p>\n",
    "                </div>\n",
    "            </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "    # TODO: Convert html to soup\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    # TODO: Use `.find()` to locate the <p> element\n",
    "    p_tag = soup.find(\"p\")\n",
    "\n",
    "    # TODO: Extract text from the <p> element and print it\n",
    "    print(p_tag.text)\n",
    "\n",
    "extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['class', 'href', 'target'])\n",
      "dict_values([['my-link'], 'https://www.google.com', '_blank'])\n",
      "{'class': ['my-link'], 'href': 'https://www.google.com', 'target': '_blank'}\n",
      "https://www.google.com\n"
     ]
    }
   ],
   "source": [
    "def extract_attributes():\n",
    "    \"\"\"\n",
    "    Objective: Extract and print the text content of a <p> element.\n",
    "    Expected Output:\n",
    "    dict_keys(['href', 'class'])\n",
    "    https://www.google.com\n",
    "    \"\"\"\n",
    "    html = \"\"\"\n",
    "        <html>\n",
    "            <body>\n",
    "                <div>\n",
    "                    <a class=\"my-link\" href=\"https://www.google.com\" target=\"_blank\">Google</a>\n",
    "                </div>\n",
    "            </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "    # TODO: Convert html to soup\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    # TODO: Use `.find()` to locate the <a> element\n",
    "    a = soup.find(\"a\")\n",
    "\n",
    "    # TODO: Print all available attributes from the <a> element\n",
    "    print(a.attrs.keys())\n",
    "    print(a.attrs.values())\n",
    "    print(a.attrs)\n",
    "\n",
    "    # TODO: Print the href attribute from the <a> element\n",
    "    print(a.attrs.get(\"href\"))\n",
    "\n",
    "extract_attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Item 1', 'Item 2', 'Item 3']\n",
      "Item 1\n",
      "Item 2\n",
      "Item 3\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_list():\n",
    "    \"\"\"\n",
    "    Objective: Extract text from all <li> elements and return them as a list of strings.\n",
    "    Expected Output:\n",
    "    ['Item 1', 'Item 2', 'Item 3']\n",
    "    \"\"\"\n",
    "    html = \"\"\"\n",
    "        <ul>\n",
    "            <li>Item 1</li>\n",
    "            <li>Item 2</li>\n",
    "            <li>Item 3</li>\n",
    "        </ul>\n",
    "        \"\"\"\n",
    "    # TODO: Convert html to soup\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    # TODO: Use `.find_all()` to locate all <li> elements \n",
    "    li_tags = soup.find_all(\"li\")\n",
    "\n",
    "    # TODO: Iterate over the <li> elements and extract their text into a list.\n",
    "    text_list = [li.text for li in li_tags]\n",
    "    print(text_list)\n",
    "\n",
    "    # TODO: Print the list\n",
    "    for txt in text_list:\n",
    "        print(txt)\n",
    "\n",
    "extract_text_from_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'John Doe', 'age': 'John Doe'}, {'name': 'Nadia', 'age': 'Nadia'}, {'name': 'Serena', 'age': 'Serena'}, {'name': 'Tessa', 'age': 'Tessa'}, {'name': 'Una', 'age': 'Una'}]\n",
      "{'name': 'John Doe', 'age': 'John Doe'}\n",
      "{'name': 'Nadia', 'age': 'Nadia'}\n",
      "{'name': 'Serena', 'age': 'Serena'}\n",
      "{'name': 'Tessa', 'age': 'Tessa'}\n",
      "{'name': 'Una', 'age': 'Una'}\n"
     ]
    }
   ],
   "source": [
    "def find_all_going_down():\n",
    "    \"\"\"\n",
    "    Objective: Extract text from all <p> elements and return them as a list of dictionaries.\n",
    "    Expected Output:\n",
    "    [{'name': 'John Doe', 'age': '25'}, {'name': 'Nadia', 'age': '31'}, {'name': 'Serena', 'age': '23'}, {'name': 'Tessa', 'age': '17'}, {'name': 'Una', 'age': '23'}]\n",
    "    \"\"\"\n",
    "    html = \"\"\"\n",
    "        <section>\n",
    "            <div class=\"user-info\">\n",
    "                <p class=\"my-name\">John Doe</p>\n",
    "                <p class=\"my-age\">25</p>\n",
    "            </div>\n",
    "            <div class=\"user-info\">\n",
    "                <p class=\"my-name\">Nadia</p>\n",
    "                <p class=\"my-age\">31</p>\n",
    "            </div>\n",
    "            <div class=\"user-info\">\n",
    "                <p class=\"my-name\">Serena</p>\n",
    "                <p class=\"my-age\">23</p>\n",
    "            </div>\n",
    "            <div class=\"user-info\">\n",
    "                <p class=\"my-name\">Tessa</p>\n",
    "                <p class=\"my-age\">17</p>\n",
    "            </div>\n",
    "            <div class=\"user-info\">\n",
    "                <p class=\"my-name\">Una</p>\n",
    "                <p class=\"my-age\">23</p>\n",
    "            </div>\n",
    "        </section>\"\"\"\n",
    "    # TODO: Convert html to soup\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    # TODO: Use `.find_all()` to locate all <p> elements\n",
    "    p_tags = soup.find_all(\"p\")\n",
    "\n",
    "    # TODO: Iterate over the <p> elements and extract their text into a list of dictionaries\n",
    "    divs = soup.find_all(\"div\")\n",
    "\n",
    "    persons = []\n",
    "    for div in divs:\n",
    "        p1 = div.find(\"p\").text\n",
    "        p2 = div.find_next(\"p\").text\n",
    "\n",
    "        persons.append({\"name\": p1, \"age\": p2})\n",
    "\n",
    "    print(persons)\n",
    "\n",
    "    # TODO: Print the list of dictionaries\n",
    "    for person in persons:\n",
    "        print(person)\n",
    "\n",
    "find_all_going_down()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Alice - 30\n",
      "Bob - 25\n",
      "[{'name': 'Alice', 'age': '30'}, {'name': 'Bob', 'age': '25'}]\n",
      "{'name': 'Alice', 'age': '30'}\n",
      "{'name': 'Bob', 'age': '25'}\n"
     ]
    }
   ],
   "source": [
    "def extract_tables():\n",
    "    \"\"\"\n",
    "    Objective: Extract data from an HTML table and return it as a list of dictionaries.\n",
    "    Expected Output:\n",
    "    [{'name': 'Alice', 'age': '30'}, {'name': 'Bob', 'age': '25'}]\n",
    "    \"\"\"\n",
    "    html = \"\"\"\n",
    "    <table>\n",
    "        <thead>\n",
    "            <tr>\n",
    "                <th>Name</th>\n",
    "                <th>Age</th>\n",
    "            </tr>\n",
    "        </thead>\n",
    "        <tbody>\n",
    "            <tr>\n",
    "                <td>Alice</td>\n",
    "                <td>30</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>Bob</td>\n",
    "                <td>25</td>\n",
    "            </tr>\n",
    "        </tbody>\n",
    "    </table>\n",
    "    \"\"\"\n",
    "    # TODO: Convert html to soup\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    # TODO: Extract <tr> elements from <tbody>\n",
    "    tr_tags = soup.find_all(\"tr\")\n",
    "    # print(tr_tags)\n",
    "\n",
    "    # TODO: Iterate over the <td> elements, to construct dictionaries for each row.\n",
    "\n",
    "    for tr in list(tr_tags):\n",
    "        td_tags = tr.find_all(\"td\")\n",
    "        print( f\"{td_tags[0].text} - {td_tags[1].text}\" if len(td_tags) == 2 else \"\")\n",
    "\n",
    "\n",
    "\n",
    "    # TODO: Append each dictionary to a list\n",
    "    my_dictionary = []\n",
    "    for tr in list(tr_tags):\n",
    "        td_tags = tr.find_all(\"td\")\n",
    "        if len(td_tags) == 2:\n",
    "            my_dictionary.append({\"name\": td_tags[0].text, \"age\": td_tags[1].text})\n",
    "\n",
    "    print(my_dictionary)\n",
    "\n",
    "    # TODO: Print the list\n",
    "    for person in my_dictionary:\n",
    "        print(person)\n",
    "    \n",
    "    # Challenges: Can you extract it directly from the <tr> elements?\n",
    "\n",
    "extract_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<script>\n",
      " var userInfo = { \"id\": 123, \"name\": \"Alice\" };\n",
      "</script>\n",
      "\n",
      "\n",
      "            var userInfo = { \"id\": 123, \"name\": \"Alice\" };\n",
      "        \n",
      "28\n",
      "{ \"id\": 123, \"name\": \"Alice\" }\n",
      "        \n",
      "{'id': 123, 'name': 'Alice'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def extract_scripts():\n",
    "    \"\"\"\n",
    "    Objective: Extract JSON-like data embedded in a <script> tag and return it as a Python dictionary.\n",
    "    Expected Output:\n",
    "    {\"id\": 123, \"name\": \"Alice\"}\n",
    "    \"\"\"\n",
    "    html = \"\"\"\n",
    "        <script>\n",
    "            var userInfo = { \"id\": 123, \"name\": \"Alice\" };\n",
    "        </script>\n",
    "        \"\"\"\n",
    "\n",
    "    # TODO: Convert html to soup\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    # TODO: Extract the JSON-like content from the <script> tag\n",
    "    script = soup.script\n",
    "\n",
    "    print(script.prettify())\n",
    "\n",
    "    script_value = script.string\n",
    "\n",
    "    print(script_value)\n",
    "\n",
    "    index_of_open_curly_brace = script_value.index(\"{\")\n",
    "\n",
    "    print(index_of_open_curly_brace)\n",
    "    \n",
    "    # TODO: Remove the \"var userInfo = \" and \";\" from the JSON-like content\n",
    "    json_like_value = script_value[index_of_open_curly_brace:].replace(\";\", \"\")\n",
    "    print(json_like_value)\n",
    "    \n",
    "    # TODO: Convert the JSON-like content to a Python dictionary\n",
    "    python_dict = json.loads(json_like_value)\n",
    "    \n",
    "    # TODO: Print the dictionary\n",
    "    print(python_dict)\n",
    "\n",
    "extract_scripts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " User ID: 67890 \n"
     ]
    }
   ],
   "source": [
    "def extract_comments():\n",
    "    \"\"\"\n",
    "    Objective: Extract a comment from the HTML and return it as a string.\n",
    "    Expected Output:\n",
    "    ' User ID: 67890 '\n",
    "    \"\"\"\n",
    "    html = \"\"\"\n",
    "        <!-- User ID: 67890 -->\n",
    "        <div class=\"user-info\">Name: John Doe</div>\n",
    "        \"\"\"\n",
    "\n",
    "    # TODO: Convert html to soup\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    # TODO: Use BeautifulSoup to locate and extract the comment.\n",
    "    soup_string = soup.find_all(string=True)\n",
    "\n",
    "    comments = []\n",
    "\n",
    "    for s in soup_string:\n",
    "        if isinstance(s, Comment):\n",
    "            comments.append(s)\n",
    "\n",
    "\n",
    "    # TODO: Print the comment\n",
    "    for comment in comments:\n",
    "        print(comment)\n",
    "\n",
    "extract_comments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Item 1', 'Item 2', 'Item 3']\n"
     ]
    }
   ],
   "source": [
    "def extract_dynamic_classes():\n",
    "    \"\"\"\n",
    "    Objective: Extract text content from all <div> elements with class names starting with 'content-'.\n",
    "    Expected Output:\n",
    "    ['Item 1', 'Item 2', 'Item 3']\n",
    "    \"\"\"\n",
    "    html = \"\"\"\n",
    "        <div class=\"content-1\">Item 1</div>\n",
    "        <div class=\"content-2\">Item 2</div>\n",
    "        <div class=\"content-3\">Item 3</div>\n",
    "        \"\"\"\n",
    "    \n",
    "    # TODO: Convert html to soup\n",
    "    soup = bs(html, \"html.parser\",)\n",
    "\n",
    "    # TODO: Use `.find_all()` with a custom filter to locate the elements\n",
    "    divs = soup.find_all(\"div\", {\"class\": [ f\"content-{i}\" for i in range(4) ]})\n",
    "\n",
    "    # TODO: Iterate over the elements and extract text from the specified <div> elements.\n",
    "    div_text = list()\n",
    "\n",
    "    for div in divs:\n",
    "        div_text.append(div.text.strip())\n",
    "\n",
    "    # TODO: Print the list\n",
    "    print(div_text)\n",
    "\n",
    "\n",
    "extract_dynamic_classes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reflection**\n",
    "Which one method in BeautifulSoup you prefer? .find() or .select_one() ?\n",
    "\n",
    "i dont think where is better betwen .find() or .select_one() but i prefer use .find()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exploration**\n",
    "Automate the process of getting HTML content by using Requests library. Read the official documentations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
