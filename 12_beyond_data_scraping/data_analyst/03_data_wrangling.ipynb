{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Wrangling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is Data Wrangling?\n",
    "Data wrangling (also known as data munging) is the process of cleaning, organizing, and transforming raw data into a format that is easier to analyze.\n",
    "\n",
    "Think of it like preparing ingredients before cooking — cutting, cleaning, and measuring everything so it’s ready to be used.\n",
    "\n",
    "#### Data Wrangling Process\n",
    "1. Gathering Data\n",
    "2. Assessing Data\n",
    "3. Cleaning Data\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Execute this cell before continue\n",
    "\"\"\" \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gathering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reading various data types using Pandas\n",
    "\"\"\" \n",
    "\n",
    "students_df = pd.read_csv(\"Data Wrangling Dataset/students.csv\")\n",
    "students_df\n",
    "\n",
    "# TODO: Explore pandas input/output API references here https://pandas.pydata.org/docs/reference/io.html\n",
    "# TODO: Load the student grades from a JSON file in the same folder store as grades_df\n",
    "# TODO: Extract the first table from an HTML file containing attendance data store as attendance_df\n",
    "# TODO: Connect to an SQLite database file and read the \"enrollment\" table into a DataFrame store as enrollment_df\n",
    "# Hint: Use the sqlite3 module to connect, and pandas to run a SQL SELECT query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before continue, please take 5 minutes reading to https://pandas.pydata.org/docs/user_guide/merging.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Combining Multiple Data: Join\n",
    "\"\"\" \n",
    "print(\"Student data before join:\")\n",
    "print(students_df)\n",
    "print(\"============================================================\")\n",
    "\n",
    "print(\"Additional data before join:\")\n",
    "print(grades_df)\n",
    "print(\"============================================================\")\n",
    "\n",
    "# We need to set the index to 'student_id' before joining\n",
    "students_df_reindexed = students_df.set_index(\"student_id\")\n",
    "grades_df_reindexed = grades_df.set_index(\"student_id\")\n",
    "\n",
    "joined_df = students_df_reindexed.join(grades_df_reindexed)\n",
    "print(joined_df)\n",
    "\n",
    "# TODO: Join students.csv and students2.csv using pandas join().\n",
    "# Hint: Set the index to 'student_id' before joining and add suffixes \"_left\" and \"_right\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Combining Multiple Data: Concatenate\n",
    "\"\"\"\n",
    "\n",
    "print(\"Student data before concatenate:\")\n",
    "print(students_df)\n",
    "print(\"============================================================\")\n",
    "\n",
    "print(\"Grades data before concatenate:\")\n",
    "print(grades_df)\n",
    "print(\"============================================================\")\n",
    "\n",
    "print(\"Student data after concatenate:\")\n",
    "concatenated_df = pd.concat([students_df, grades_df])\n",
    "print(concatenated_df)\n",
    "\n",
    "# TODO: Try change the axis to 1\n",
    "# TODO: Concatenate data from students.csv and students2.csv using pandas concat()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Combining Multiple Data: Merge\n",
    "\"\"\" \n",
    "print(\"Student data before merge:\")\n",
    "print(students_df)\n",
    "print(\"============================================================\")\n",
    "\n",
    "print(\"Grades data before merge:\")\n",
    "print(grades_df)\n",
    "print(\"============================================================\")\n",
    "\n",
    "print(\"Student data after merge:\")\n",
    "merged_df = pd.merge(students_df, grades_df)\n",
    "print(merged_df)\n",
    "\n",
    "# TODO: Merge data from students.csv and students2.csv using pandas merge().\n",
    "# Expected Output:\n",
    "#   student_id   full_name         gender   major               semester   course   grade   attendance_percent\n",
    "# 0  101         Ali Ahmad         Male     Computer Science    NaN        NaN      NaN     NaN\n",
    "# 1  102         Siti Nurhaliza    Female   Information Systems NaN        NaN      NaN     NaN\n",
    "# 2  103         John Doe          Male     Data Science        NaN        NaN      NaN     NaN\n",
    "# 3  104         Aisha Yusuf       Female   Computer Science    NaN        NaN      NaN     NaN\n",
    "# 4  105         Muhammad Rizki    Male     Information Systems 2023A      Math     90.0    92.0\n",
    "# 5  106         Nur Aini          Female   Data Science        2023A      Math     78.0    87.0\n",
    "# 6  107         Kevin Lim         Male     Computer Science    2023A      Math     82.0    93.0\n",
    "# 7  108         Melati Dewi       Female   Data Science        2023A      Math     95.0    89.0\n",
    "# 8  109         Arif Rahman       Male     Information Systems 2023A      Math     87.0    84.0\n",
    "# 9  110         Putri Lestari     Female   Computer Science    2023A      Math     89.0    90.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Class Activity: Gathering Data\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Gather data from E-Commerce Public Dataset\n",
    "# TODO: Read data from orders_item_dataset.csv\n",
    "# TODO: Add product_category_name in english to orders_item_dataset\n",
    "# Hint: Use the products_dataset.csv and product_category_name_translation.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing & Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Execute this cell before continue\n",
    "\"\"\"\n",
    "\n",
    "dirty_data = pd.DataFrame({\n",
    "    'student_id': [101, 102, 103, 104, 105, 106, 106, 107, 108],\n",
    "    'full_name': [\n",
    "        'Ali Ahmad', 'Siti Nurhaliza', 'John Doe', 'Aisha Yusuf',\n",
    "        'Muhammad Rizki', 'Nur Aini', 'Nur Aini', 'Kevin Lim', None\n",
    "    ],\n",
    "    'gender': [\n",
    "        'Male', 'Female', 'Unknown', 'Female',\n",
    "        'Male', 'Female', 'Female', 'Male', None\n",
    "    ],\n",
    "    'age': [20, 21, 22, 20, 21, 20, 20, 200, 21],\n",
    "    'major': [\n",
    "        'Computer Science', 'Data Science', 'Data Science',\n",
    "        'Computer Science', None, 'Data Science', 'Data Science',\n",
    "        'Computer Science', 'Data Science'\n",
    "    ],\n",
    "    'grade': [88, 90, 100, 80, 87, 92, 92, 76, 81],\n",
    "    'attendance_percent': [95, 97, 100, 89, 88, None, None, 90, 94],\n",
    "    'final_score': [\n",
    "        83.7, 85.4, 94.9, 87.2, 82.8, \n",
    "        87, 87, 71.8, 77.8\n",
    "    ],\n",
    "    'study_hours': [3, 3, 3, 3, 1, 2, 2, 1, 2]\n",
    "})\n",
    "\n",
    "dirty_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assessing data: Duplicate data\n",
    "\"\"\"\n",
    "\n",
    "# Identify duplicate data\n",
    "dirty_data.duplicated().sum()\n",
    "\n",
    "# Drop duplicate data\n",
    "clean_data = dirty_data.drop_duplicates()\n",
    "clean_data.duplicated().sum()\n",
    "clean_data\n",
    "\n",
    "# Quiz:\n",
    "# 106\tNur Aini\tFemale\t20\n",
    "# 106\tNur Aini\tFemale\t21\n",
    "# Is it duplicate data?\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assessing data: Missing value\n",
    "\"\"\"\n",
    "\n",
    "# Identify missing value\n",
    "clean_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cleaning data: Drop missing value\n",
    "\"\"\"\n",
    "\n",
    "# df.dropna()\t                --> Drop rows with at least one missing values\n",
    "# df.dropna(how=\"all\")\t        --> Drop rows with all missing values\n",
    "# df.dropna(axis=1)\t            --> Drop columns with any missing values\n",
    "# df.dropna(subset=[\"column1\"])\t--> Drop rows where column1 has a missing value\n",
    "# df.dropna(thresh=5)           --> Drop rows with fewer than 5 non-NaN values\n",
    "\n",
    "# TODO: Drop the missing values that have 2 or more missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cleaning data: Fill missing value for categorical data\n",
    "\"\"\"\n",
    "\n",
    "# Find the mode\n",
    "major_mode = clean_data[\"major\"].mode()[0]\n",
    "\n",
    "# Fill missing value using the mode\n",
    "clean_data[\"major\"].fillna(major_mode, inplace=True)\n",
    "# clean_data[\"major\"] = clean_data[\"major\"].fillna(major_mode)\n",
    "clean_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cleaning data: Fill missing value using interpolation\n",
    "\"\"\"\n",
    "\n",
    "clean_data[\"attendance_percent\"] = clean_data[\"attendance_percent\"].interpolate(method=\"linear\")\n",
    "clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assessing data: Invalid data type\n",
    "\"\"\"\n",
    "\n",
    "# Check data type\n",
    "print(\"Before:\")\n",
    "print(clean_data.dtypes)\n",
    "\n",
    "# Convert data type\n",
    "clean_data[\"age\"] = pd.to_numeric(clean_data[\"age\"])\n",
    "\n",
    "print(\"After:\")\n",
    "clean_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assessing data: Invalid value\n",
    "\"\"\"\n",
    "\n",
    "# Check unique value\n",
    "for col in clean_data.columns:\n",
    "    print(col)\n",
    "    print(clean_data[col].unique())\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Check which data is invalid\n",
    "# clean_data[clean_data[\"gender\"] == \"Unknown\"]\n",
    "\n",
    "# How you prefer to handle it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assessing data: Corelation\n",
    "\"\"\"\n",
    "\n",
    "clean_data.corr(numeric_only=True)\n",
    "\n",
    "# TODO: Identify highly correlated features\n",
    "# TODO: Drop one of them using the drop() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assessing data: Outlier\n",
    "\"\"\"\n",
    "\n",
    "# Easy way to detect outlier\n",
    "sns.boxplot(data=clean_data.select_dtypes(include=[np.number]))\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Boxplot of Numeric Columns\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cleaning data: Outlier\n",
    "\"\"\"\n",
    "\n",
    "# Identify outlier using z-score\n",
    "# z = (x - mean) / std\n",
    "# z < -3 or z > 3\n",
    "\n",
    "zscores = stats.zscore(clean_data[\"age\"])\n",
    "zscores\n",
    "\n",
    "# Drop the outlier\n",
    "# clean_data = clean_data[zscores <= 2]\n",
    "# clean_data\n",
    "\n",
    "# TODO: Identify outlier in grade using IQR\n",
    "# TODO: Drop the outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assessing data: Skewness\n",
    "\"\"\"\n",
    "\n",
    "clean_data.hist(figsize=(12, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assessing data: Skewness\n",
    "\"\"\"\n",
    "\n",
    "for col in clean_data.columns:\n",
    "    if clean_data[col].dtypes != \"object\":\n",
    "        print(col)\n",
    "        print(stats.skew(clean_data[col]))\n",
    "        print(\" \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cleaning data: Transformation\n",
    "\"\"\"\n",
    "\n",
    "x = clean_data['study_hours']\n",
    "\n",
    "print(stats.skew(x))\n",
    "\n",
    "clean_data['log_transformed'] = np.log1p(x)  # log(x + 1)\n",
    "print(stats.skew(clean_data['log_transformed']))\n",
    "\n",
    "clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Assessing data: Statistical summary\n",
    "\"\"\"\n",
    "\n",
    "dirty_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Class Activity: Data Wrangling\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Perform data wrangling on the dataset class activity folder inside Data Wrangling Dataset folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reflection**\n",
    "If you encounter a lot of missing values, how do you handle them?\n",
    "\n",
    "(answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exploration**\n",
    "Next, we will learn how to gain deeper insights from data through Exploratory Data Analysis (EDA). Explore EDA notebooks on Kaggle to see practical examples. Remember, as you work with more diverse datasets, your skills will continue to sharpen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
